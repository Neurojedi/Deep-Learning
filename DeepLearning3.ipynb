{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b841ab31",
   "metadata": {},
   "source": [
    "# Deep Learning 3 - Time to exercise with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2cd6c0",
   "metadata": {},
   "source": [
    "In the previous notebooks, I focused more on the ideas and theories behind this deep neural network. My aim is in this notebook to use Keras to practice the neural networks that I have implemented previously. I will start with Fashion MNIST dataset and I don't have a particular plan about the exercises that I will try but we'll see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f57b02bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d75017",
   "metadata": {},
   "source": [
    "## Hello World of Deep Learning Fashion MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443a91a3",
   "metadata": {},
   "source": [
    "Firstly, let's load our dataset and split it into train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6eb2bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6ad613c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_train = X_train_full[:5000] / 255., X_train_full[5000:] / 255.\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "X_test = X_test / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7873cea",
   "metadata": {},
   "source": [
    "I'm planning to use two different models on that dataset. In the first one, I will be using Sequential API and in the second one I will use Functional API. I aim to have %90 accuracy on validation set in both of the models. I will not use any hyperparameters tuning and regularization in these models because I would like to use them after I made a notebook about the implementation of these initialization, regularization and optimization techniques from scratch as I did in ANDREW NG's course."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558a9e35",
   "metadata": {},
   "source": [
    "### Sequential Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badfc1ef",
   "metadata": {},
   "source": [
    "Firstly, I want to see whether or not the target variable is skewed. If It was I would use `class_weight` argument while calling the `fit()` function which would give a larger priority (actually weight) to  underrepresented classes and lower to overrepresented ones. So we would get a higher weight while computing the cost function and this would help us to get a better classifier for all the labels. It may be also good to use `sample_weight` argument in these cases which gives more priority to some samples. There is a nice stackoverflow discussion about that the difference between sample_weight and class_weight [link](https://stackoverflow.com/questions/32492550/what-is-the-difference-between-sample-weight-and-class-weight-options-in-scikit)\n",
    "\n",
    "Addition1: we can also add sample_weight to validation_data while compiling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3c1204ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gorke\\anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='count'>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de20c2f",
   "metadata": {},
   "source": [
    "Okay now let's start constructing our model. I will start with a flatten layer, I guess I have talked about the function `Flatten()`  in my previous notebooks but to revise it, It converts each input into a one-dimensional array. It basically does `.reshape(-1,1)`. I will also set the `input_shape()`. Then in the following layers I simply used ReLU activation function and in the last node since we have 10 different outputs, I will use softmax activation function. Documentation for activation functions: [link](https://keras.io/initializers/.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a1bbbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "model.add(keras.layers.Dense(400, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(260, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(140, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(90, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3fad75d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3f3cf6",
   "metadata": {},
   "source": [
    "In my previous notebook I initialized the weights randomly in addition to initializing the bias as 0. In fact the `Dense()` function does this automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32506b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdn_lyr1 = model.layers[1]\n",
    "weights, biases = hdn_lyr1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b72f6139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0514607 ,  0.01438598, -0.04673972, ...,  0.04065529,\n",
       "        -0.0423982 ,  0.02460463],\n",
       "       [ 0.02134651,  0.01446612,  0.01129872, ..., -0.01284081,\n",
       "         0.00035759,  0.06763688],\n",
       "       [-0.03797506,  0.0047066 , -0.06346311, ...,  0.05471922,\n",
       "         0.05463848, -0.0258562 ],\n",
       "       ...,\n",
       "       [-0.02959318,  0.06238516, -0.03147805, ...,  0.03985156,\n",
       "        -0.02314321, -0.04266967],\n",
       "       [ 0.01027863,  0.05750225, -0.05942551, ...,  0.01131304,\n",
       "         0.02868841,  0.00826363],\n",
       "       [ 0.06365559, -0.03826068, -0.04590683, ..., -0.05463227,\n",
       "         0.03345894, -0.07021318]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d4e22bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aba43fe",
   "metadata": {},
   "source": [
    "The difference here is that in the previous notebook I didn't set the `input_shape` while structuring my model. The weight shape is actually depends on the `input_shape`, that's why, If we don't set input_shape as above the algorithm will wait until we compile our model to get the input_shape as well as weight_shape. Delete the input_shape argument above and you will not be able to get the weights values until you compile the model. Initialization is an important step to break symmetry and I will revise it again in the following notebooks. Documentation for initializers : [link](https://keras.io/initializers/.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "602fb819",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.sparse_categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.SGD(),# default learning_rate is 0.01\n",
    "              metrics=[keras.metrics.sparse_categorical_accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316c9210",
   "metadata": {},
   "source": [
    "Here we will have sparse labels. For every instance we will have array that shows probability of being one of the cloths which will look something like this [0, 0.3, 0, 0, 0, 0,2 ,0.9 ,0 ,0 ]. In other words, when we have more than one two labels we can use ` loss=\"sparse_categorical_crossentropy\"`. If there was one target we could also use categorical_crossentropy. Documentation:\n",
    "1. Cost Functions: [link](https://keras.io/losses)\n",
    "2. Optimizers: [link](https://keras.io/optimizers)\n",
    "3. Metrics: [link](https://keras.io/metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1426481a",
   "metadata": {},
   "source": [
    "Here I will use three Callbacks. In fact, I was gonna write my own Callback but I feel a bit lazy for it today. Therefore, I will use the three main callbacks here.\n",
    "1. **Checkpoint:** This call back saves the model at the end of each epoch. Here I also used `save_best_only()=True` argument which makes the function to save the checkpoint when its performance on validation data is the best so far. Thanks to this callback even if the model starts overfitting after some epoch we will still have the best model.\n",
    "2. **Early_stopping:** I won't give into much details of early_stopping since I also introduced this in my machine learning notebooks. `restore_best_weights` is similar to `save_best_only` It saves the weights from the epoch with best values during training. In the end of the training the model will use these weights. I thought this parameter should be true by default but It's not probably the reason is It may be costly for training sometimes. A discussion about that can be found on github [link](https://github.com/keras-team/keras/issues/11371)\n",
    "3. **Tensorboard:** Tensorboard is an awesome visualization api in tensorflow which is sort of similar to our history plot in which we see how the performance changed during the training. Tensorboard, however, provides us much more information.  It has some other arguments that I really like such as `update_freq` which is batch by default and `write_images` which is also false by default. Check the arguments, the link is below.\n",
    "\n",
    "For other callbacks: [link](https://keras.io/api/callbacks/)\n",
    "\n",
    "For customm callbacks there is a very good documentation here: [link](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/Callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93d8ac3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "  1/108 [..............................] - ETA: 0s - loss: 2.2699 - sparse_categorical_accuracy: 0.1309WARNING:tensorflow:From C:\\Users\\gorke\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "  2/108 [..............................] - ETA: 4s - loss: 2.2662 - sparse_categorical_accuracy: 0.1357WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0135s vs `on_train_batch_end` time: 0.0646s). Check your callbacks.\n",
      "108/108 [==============================] - 2s 23ms/step - loss: 1.8026 - sparse_categorical_accuracy: 0.4485 - val_loss: 1.3398 - val_sparse_categorical_accuracy: 0.6094\n",
      "Epoch 2/400\n",
      "108/108 [==============================] - 2s 18ms/step - loss: 1.1116 - sparse_categorical_accuracy: 0.6654 - val_loss: 0.9314 - val_sparse_categorical_accuracy: 0.7056\n",
      "Epoch 3/400\n",
      "108/108 [==============================] - 2s 17ms/step - loss: 0.8591 - sparse_categorical_accuracy: 0.7161 - val_loss: 0.7836 - val_sparse_categorical_accuracy: 0.7372\n",
      "Epoch 4/400\n",
      "108/108 [==============================] - 2s 15ms/step - loss: 0.7510 - sparse_categorical_accuracy: 0.7500 - val_loss: 0.7004 - val_sparse_categorical_accuracy: 0.7688\n",
      "Epoch 5/400\n",
      "108/108 [==============================] - 2s 16ms/step - loss: 0.6866 - sparse_categorical_accuracy: 0.7721 - val_loss: 0.6846 - val_sparse_categorical_accuracy: 0.7692\n",
      "Epoch 6/400\n",
      "108/108 [==============================] - 2s 16ms/step - loss: 0.6398 - sparse_categorical_accuracy: 0.7852 - val_loss: 0.6055 - val_sparse_categorical_accuracy: 0.8024\n",
      "Epoch 7/400\n",
      "108/108 [==============================] - 2s 16ms/step - loss: 0.6070 - sparse_categorical_accuracy: 0.7942 - val_loss: 0.5737 - val_sparse_categorical_accuracy: 0.8110\n",
      "Epoch 8/400\n",
      "108/108 [==============================] - 2s 16ms/step - loss: 0.5759 - sparse_categorical_accuracy: 0.8043 - val_loss: 0.5670 - val_sparse_categorical_accuracy: 0.8034\n",
      "Epoch 9/400\n",
      "108/108 [==============================] - 2s 16ms/step - loss: 0.5564 - sparse_categorical_accuracy: 0.8090 - val_loss: 0.5680 - val_sparse_categorical_accuracy: 0.7926\n",
      "Epoch 10/400\n",
      "108/108 [==============================] - 2s 18ms/step - loss: 0.5388 - sparse_categorical_accuracy: 0.8136 - val_loss: 0.5683 - val_sparse_categorical_accuracy: 0.8048\n",
      "Epoch 11/400\n",
      "108/108 [==============================] - 2s 20ms/step - loss: 0.5270 - sparse_categorical_accuracy: 0.8163 - val_loss: 0.5035 - val_sparse_categorical_accuracy: 0.8256\n",
      "Epoch 12/400\n",
      "108/108 [==============================] - 2s 21ms/step - loss: 0.5133 - sparse_categorical_accuracy: 0.8202 - val_loss: 0.4967 - val_sparse_categorical_accuracy: 0.8332\n",
      "Epoch 13/400\n",
      "108/108 [==============================] - 2s 19ms/step - loss: 0.5039 - sparse_categorical_accuracy: 0.8221 - val_loss: 0.5167 - val_sparse_categorical_accuracy: 0.8142\n",
      "Epoch 14/400\n",
      "108/108 [==============================] - 2s 20ms/step - loss: 0.4958 - sparse_categorical_accuracy: 0.8254 - val_loss: 0.5214 - val_sparse_categorical_accuracy: 0.8140\n",
      "Epoch 15/400\n",
      "108/108 [==============================] - 2s 17ms/step - loss: 0.4837 - sparse_categorical_accuracy: 0.8303 - val_loss: 0.4746 - val_sparse_categorical_accuracy: 0.8390\n",
      "Epoch 16/400\n",
      "108/108 [==============================] - 2s 23ms/step - loss: 0.4795 - sparse_categorical_accuracy: 0.8303 - val_loss: 0.4993 - val_sparse_categorical_accuracy: 0.8168\n",
      "Epoch 17/400\n",
      "108/108 [==============================] - 2s 17ms/step - loss: 0.4726 - sparse_categorical_accuracy: 0.8335 - val_loss: 0.4695 - val_sparse_categorical_accuracy: 0.8412\n",
      "Epoch 18/400\n",
      "108/108 [==============================] - 3s 24ms/step - loss: 0.4638 - sparse_categorical_accuracy: 0.8357 - val_loss: 0.4699 - val_sparse_categorical_accuracy: 0.8324\n",
      "Epoch 19/400\n",
      "108/108 [==============================] - 2s 17ms/step - loss: 0.4592 - sparse_categorical_accuracy: 0.8383 - val_loss: 0.4411 - val_sparse_categorical_accuracy: 0.8496\n",
      "Epoch 20/400\n",
      "108/108 [==============================] - 2s 18ms/step - loss: 0.4505 - sparse_categorical_accuracy: 0.8413 - val_loss: 0.4350 - val_sparse_categorical_accuracy: 0.8506\n",
      "Epoch 21/400\n",
      "108/108 [==============================] - 2s 21ms/step - loss: 0.4486 - sparse_categorical_accuracy: 0.8411 - val_loss: 0.4529 - val_sparse_categorical_accuracy: 0.8452\n",
      "Epoch 22/400\n",
      "108/108 [==============================] - 2s 20ms/step - loss: 0.4456 - sparse_categorical_accuracy: 0.8430 - val_loss: 0.4344 - val_sparse_categorical_accuracy: 0.8510\n",
      "Epoch 23/400\n",
      "108/108 [==============================] - 2s 17ms/step - loss: 0.4394 - sparse_categorical_accuracy: 0.8466 - val_loss: 0.4307 - val_sparse_categorical_accuracy: 0.8506\n",
      "Epoch 24/400\n",
      "108/108 [==============================] - 2s 17ms/step - loss: 0.4367 - sparse_categorical_accuracy: 0.8451 - val_loss: 0.4288 - val_sparse_categorical_accuracy: 0.8504\n",
      "Epoch 25/400\n",
      "108/108 [==============================] - 2s 16ms/step - loss: 0.4283 - sparse_categorical_accuracy: 0.8485 - val_loss: 0.4275 - val_sparse_categorical_accuracy: 0.8506\n",
      "Epoch 26/400\n",
      "108/108 [==============================] - 2s 20ms/step - loss: 0.4302 - sparse_categorical_accuracy: 0.8476 - val_loss: 0.4232 - val_sparse_categorical_accuracy: 0.8528\n",
      "Epoch 27/400\n",
      "108/108 [==============================] - 2s 20ms/step - loss: 0.4225 - sparse_categorical_accuracy: 0.8507 - val_loss: 0.4352 - val_sparse_categorical_accuracy: 0.8448\n",
      "Epoch 28/400\n",
      "108/108 [==============================] - 2s 18ms/step - loss: 0.4229 - sparse_categorical_accuracy: 0.8508 - val_loss: 0.4334 - val_sparse_categorical_accuracy: 0.8420\n",
      "Epoch 29/400\n",
      "108/108 [==============================] - 2s 20ms/step - loss: 0.4158 - sparse_categorical_accuracy: 0.8527 - val_loss: 0.4211 - val_sparse_categorical_accuracy: 0.8544\n",
      "Epoch 30/400\n",
      "108/108 [==============================] - 2s 18ms/step - loss: 0.4146 - sparse_categorical_accuracy: 0.8533 - val_loss: 0.4075 - val_sparse_categorical_accuracy: 0.8588\n",
      "Epoch 31/400\n",
      "108/108 [==============================] - 2s 16ms/step - loss: 0.4119 - sparse_categorical_accuracy: 0.8551 - val_loss: 0.4302 - val_sparse_categorical_accuracy: 0.8444\n",
      "Epoch 32/400\n",
      "108/108 [==============================] - 2s 16ms/step - loss: 0.4087 - sparse_categorical_accuracy: 0.8556 - val_loss: 0.4287 - val_sparse_categorical_accuracy: 0.8502\n",
      "Epoch 33/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.4081 - sparse_categorical_accuracy: 0.8566 - val_loss: 0.4070 - val_sparse_categorical_accuracy: 0.8582\n",
      "Epoch 34/400\n",
      "108/108 [==============================] - 2s 15ms/step - loss: 0.4050 - sparse_categorical_accuracy: 0.8563 - val_loss: 0.4014 - val_sparse_categorical_accuracy: 0.8568\n",
      "Epoch 35/400\n",
      "108/108 [==============================] - 2s 15ms/step - loss: 0.3992 - sparse_categorical_accuracy: 0.8588 - val_loss: 0.4466 - val_sparse_categorical_accuracy: 0.8468\n",
      "Epoch 36/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.3989 - sparse_categorical_accuracy: 0.8585 - val_loss: 0.4470 - val_sparse_categorical_accuracy: 0.8440\n",
      "Epoch 37/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.3970 - sparse_categorical_accuracy: 0.8598 - val_loss: 0.4147 - val_sparse_categorical_accuracy: 0.8510\n",
      "Epoch 38/400\n",
      "108/108 [==============================] - 2s 16ms/step - loss: 0.3933 - sparse_categorical_accuracy: 0.8616 - val_loss: 0.4077 - val_sparse_categorical_accuracy: 0.8554\n",
      "Epoch 39/400\n",
      "108/108 [==============================] - 2s 15ms/step - loss: 0.3895 - sparse_categorical_accuracy: 0.8635 - val_loss: 0.4009 - val_sparse_categorical_accuracy: 0.8568\n",
      "Epoch 40/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.3869 - sparse_categorical_accuracy: 0.8641 - val_loss: 0.3908 - val_sparse_categorical_accuracy: 0.8594\n",
      "Epoch 41/400\n",
      "108/108 [==============================] - 2s 14ms/step - loss: 0.3832 - sparse_categorical_accuracy: 0.8640 - val_loss: 0.4227 - val_sparse_categorical_accuracy: 0.8450\n",
      "Epoch 42/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.3814 - sparse_categorical_accuracy: 0.8654 - val_loss: 0.3886 - val_sparse_categorical_accuracy: 0.8650\n",
      "Epoch 43/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.3802 - sparse_categorical_accuracy: 0.8652 - val_loss: 0.4021 - val_sparse_categorical_accuracy: 0.8592\n",
      "Epoch 44/400\n",
      "108/108 [==============================] - 1s 14ms/step - loss: 0.3795 - sparse_categorical_accuracy: 0.8661 - val_loss: 0.4083 - val_sparse_categorical_accuracy: 0.8546\n",
      "Epoch 45/400\n",
      "108/108 [==============================] - 2s 14ms/step - loss: 0.3759 - sparse_categorical_accuracy: 0.8673 - val_loss: 0.4315 - val_sparse_categorical_accuracy: 0.8516\n",
      "Epoch 46/400\n",
      "108/108 [==============================] - 2s 15ms/step - loss: 0.3751 - sparse_categorical_accuracy: 0.8675 - val_loss: 0.4009 - val_sparse_categorical_accuracy: 0.8548\n",
      "Epoch 47/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.3725 - sparse_categorical_accuracy: 0.8679 - val_loss: 0.4207 - val_sparse_categorical_accuracy: 0.8548\n",
      "Epoch 48/400\n",
      "108/108 [==============================] - 2s 14ms/step - loss: 0.3713 - sparse_categorical_accuracy: 0.8699 - val_loss: 0.3850 - val_sparse_categorical_accuracy: 0.8668\n",
      "Epoch 49/400\n",
      "108/108 [==============================] - 1s 14ms/step - loss: 0.3680 - sparse_categorical_accuracy: 0.8709 - val_loss: 0.4022 - val_sparse_categorical_accuracy: 0.8600\n",
      "Epoch 50/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.3639 - sparse_categorical_accuracy: 0.8719 - val_loss: 0.3793 - val_sparse_categorical_accuracy: 0.8658\n",
      "Epoch 51/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.3628 - sparse_categorical_accuracy: 0.8716 - val_loss: 0.3692 - val_sparse_categorical_accuracy: 0.8660\n",
      "Epoch 52/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.3607 - sparse_categorical_accuracy: 0.8734 - val_loss: 0.3750 - val_sparse_categorical_accuracy: 0.8684\n",
      "Epoch 53/400\n",
      "108/108 [==============================] - 1s 14ms/step - loss: 0.3639 - sparse_categorical_accuracy: 0.8704 - val_loss: 0.3936 - val_sparse_categorical_accuracy: 0.8668\n",
      "Epoch 54/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.3593 - sparse_categorical_accuracy: 0.8723 - val_loss: 0.4281 - val_sparse_categorical_accuracy: 0.8528\n",
      "Epoch 55/400\n",
      "108/108 [==============================] - 2s 15ms/step - loss: 0.3625 - sparse_categorical_accuracy: 0.8717 - val_loss: 0.3812 - val_sparse_categorical_accuracy: 0.8624\n",
      "Epoch 56/400\n",
      "108/108 [==============================] - 2s 17ms/step - loss: 0.3515 - sparse_categorical_accuracy: 0.8769 - val_loss: 0.3739 - val_sparse_categorical_accuracy: 0.8690\n",
      "Epoch 57/400\n",
      "108/108 [==============================] - 1s 14ms/step - loss: 0.3532 - sparse_categorical_accuracy: 0.8751 - val_loss: 0.3785 - val_sparse_categorical_accuracy: 0.8678\n",
      "Epoch 58/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.3536 - sparse_categorical_accuracy: 0.8751 - val_loss: 0.3677 - val_sparse_categorical_accuracy: 0.8684\n",
      "Epoch 59/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.3481 - sparse_categorical_accuracy: 0.8772 - val_loss: 0.3784 - val_sparse_categorical_accuracy: 0.8664\n",
      "Epoch 60/400\n",
      "108/108 [==============================] - 1s 12ms/step - loss: 0.3460 - sparse_categorical_accuracy: 0.8778 - val_loss: 0.3603 - val_sparse_categorical_accuracy: 0.8712\n",
      "Epoch 61/400\n",
      "108/108 [==============================] - 1s 14ms/step - loss: 0.3482 - sparse_categorical_accuracy: 0.8772 - val_loss: 0.3642 - val_sparse_categorical_accuracy: 0.8706\n",
      "Epoch 62/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.3448 - sparse_categorical_accuracy: 0.8778 - val_loss: 0.3731 - val_sparse_categorical_accuracy: 0.8692\n",
      "Epoch 63/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.3432 - sparse_categorical_accuracy: 0.8784 - val_loss: 0.3727 - val_sparse_categorical_accuracy: 0.8672\n",
      "Epoch 64/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.3425 - sparse_categorical_accuracy: 0.8796 - val_loss: 0.3611 - val_sparse_categorical_accuracy: 0.8706\n",
      "Epoch 65/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.3407 - sparse_categorical_accuracy: 0.8792 - val_loss: 0.3593 - val_sparse_categorical_accuracy: 0.8706\n",
      "Epoch 66/400\n",
      "108/108 [==============================] - 2s 15ms/step - loss: 0.3394 - sparse_categorical_accuracy: 0.8805 - val_loss: 0.3691 - val_sparse_categorical_accuracy: 0.8676\n",
      "Epoch 67/400\n",
      "108/108 [==============================] - 2s 14ms/step - loss: 0.3368 - sparse_categorical_accuracy: 0.8802 - val_loss: 0.3803 - val_sparse_categorical_accuracy: 0.8690\n",
      "Epoch 68/400\n",
      "108/108 [==============================] - 2s 15ms/step - loss: 0.3363 - sparse_categorical_accuracy: 0.8809 - val_loss: 0.4058 - val_sparse_categorical_accuracy: 0.8598\n",
      "Epoch 69/400\n",
      "108/108 [==============================] - 2s 14ms/step - loss: 0.3352 - sparse_categorical_accuracy: 0.8822 - val_loss: 0.3593 - val_sparse_categorical_accuracy: 0.8700\n",
      "Epoch 70/400\n",
      "108/108 [==============================] - 1s 14ms/step - loss: 0.3331 - sparse_categorical_accuracy: 0.8829 - val_loss: 0.3774 - val_sparse_categorical_accuracy: 0.8678\n",
      "Epoch 71/400\n",
      "108/108 [==============================] - 2s 14ms/step - loss: 0.3362 - sparse_categorical_accuracy: 0.8801 - val_loss: 0.3555 - val_sparse_categorical_accuracy: 0.8756\n",
      "Epoch 72/400\n",
      "108/108 [==============================] - 1s 14ms/step - loss: 0.3300 - sparse_categorical_accuracy: 0.8834 - val_loss: 0.3513 - val_sparse_categorical_accuracy: 0.8766\n",
      "Epoch 73/400\n",
      "108/108 [==============================] - 1s 14ms/step - loss: 0.3271 - sparse_categorical_accuracy: 0.8840 - val_loss: 0.3455 - val_sparse_categorical_accuracy: 0.8784\n",
      "Epoch 74/400\n",
      "108/108 [==============================] - 2s 14ms/step - loss: 0.3252 - sparse_categorical_accuracy: 0.8851 - val_loss: 0.4028 - val_sparse_categorical_accuracy: 0.8626\n",
      "Epoch 75/400\n",
      "108/108 [==============================] - 2s 15ms/step - loss: 0.3297 - sparse_categorical_accuracy: 0.8826 - val_loss: 0.3785 - val_sparse_categorical_accuracy: 0.8646\n",
      "Epoch 76/400\n",
      "108/108 [==============================] - 2s 15ms/step - loss: 0.3228 - sparse_categorical_accuracy: 0.8854 - val_loss: 0.3482 - val_sparse_categorical_accuracy: 0.8754\n",
      "Epoch 77/400\n",
      "108/108 [==============================] - 2s 17ms/step - loss: 0.3256 - sparse_categorical_accuracy: 0.8847 - val_loss: 0.3459 - val_sparse_categorical_accuracy: 0.8784\n",
      "Epoch 78/400\n",
      "108/108 [==============================] - 2s 17ms/step - loss: 0.3228 - sparse_categorical_accuracy: 0.8851 - val_loss: 0.3443 - val_sparse_categorical_accuracy: 0.8762\n",
      "Epoch 79/400\n",
      "108/108 [==============================] - 2s 14ms/step - loss: 0.3222 - sparse_categorical_accuracy: 0.8852 - val_loss: 0.3399 - val_sparse_categorical_accuracy: 0.8786\n",
      "Epoch 80/400\n",
      "108/108 [==============================] - 2s 15ms/step - loss: 0.3185 - sparse_categorical_accuracy: 0.8871 - val_loss: 0.3743 - val_sparse_categorical_accuracy: 0.8644\n",
      "Epoch 81/400\n",
      "108/108 [==============================] - 2s 15ms/step - loss: 0.3203 - sparse_categorical_accuracy: 0.8862 - val_loss: 0.3415 - val_sparse_categorical_accuracy: 0.8776\n",
      "Epoch 82/400\n",
      "108/108 [==============================] - 2s 15ms/step - loss: 0.3174 - sparse_categorical_accuracy: 0.8869 - val_loss: 0.3548 - val_sparse_categorical_accuracy: 0.8696\n",
      "Epoch 83/400\n",
      "108/108 [==============================] - 2s 15ms/step - loss: 0.3191 - sparse_categorical_accuracy: 0.8864 - val_loss: 0.3398 - val_sparse_categorical_accuracy: 0.8792\n",
      "Epoch 84/400\n",
      "108/108 [==============================] - 1s 14ms/step - loss: 0.3129 - sparse_categorical_accuracy: 0.8891 - val_loss: 0.3513 - val_sparse_categorical_accuracy: 0.8752\n",
      "Epoch 85/400\n",
      "108/108 [==============================] - 1s 14ms/step - loss: 0.3127 - sparse_categorical_accuracy: 0.8885 - val_loss: 0.3386 - val_sparse_categorical_accuracy: 0.8778\n",
      "Epoch 86/400\n",
      "108/108 [==============================] - 2s 16ms/step - loss: 0.3116 - sparse_categorical_accuracy: 0.8894 - val_loss: 0.3431 - val_sparse_categorical_accuracy: 0.8780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/400\n",
      "108/108 [==============================] - 3s 26ms/step - loss: 0.3105 - sparse_categorical_accuracy: 0.8886 - val_loss: 0.3486 - val_sparse_categorical_accuracy: 0.8772\n",
      "Epoch 88/400\n",
      "108/108 [==============================] - 2s 20ms/step - loss: 0.3093 - sparse_categorical_accuracy: 0.8900 - val_loss: 0.3412 - val_sparse_categorical_accuracy: 0.8764\n",
      "Epoch 89/400\n",
      "108/108 [==============================] - 2s 19ms/step - loss: 0.3086 - sparse_categorical_accuracy: 0.8897 - val_loss: 0.3383 - val_sparse_categorical_accuracy: 0.8792\n",
      "Epoch 90/400\n",
      "108/108 [==============================] - 3s 23ms/step - loss: 0.3098 - sparse_categorical_accuracy: 0.8891 - val_loss: 0.3344 - val_sparse_categorical_accuracy: 0.8816\n",
      "Epoch 91/400\n",
      "108/108 [==============================] - 2s 21ms/step - loss: 0.3068 - sparse_categorical_accuracy: 0.8919 - val_loss: 0.3349 - val_sparse_categorical_accuracy: 0.8814\n",
      "Epoch 92/400\n",
      "108/108 [==============================] - 2s 23ms/step - loss: 0.3038 - sparse_categorical_accuracy: 0.8907 - val_loss: 0.3403 - val_sparse_categorical_accuracy: 0.8784\n",
      "Epoch 93/400\n",
      "108/108 [==============================] - 2s 20ms/step - loss: 0.3043 - sparse_categorical_accuracy: 0.8907 - val_loss: 0.3485 - val_sparse_categorical_accuracy: 0.8724\n",
      "Epoch 94/400\n",
      "108/108 [==============================] - 2s 18ms/step - loss: 0.3046 - sparse_categorical_accuracy: 0.8918 - val_loss: 0.3489 - val_sparse_categorical_accuracy: 0.8744\n",
      "Epoch 95/400\n",
      "108/108 [==============================] - 2s 18ms/step - loss: 0.3006 - sparse_categorical_accuracy: 0.8926 - val_loss: 0.3408 - val_sparse_categorical_accuracy: 0.8776\n",
      "Epoch 96/400\n",
      "108/108 [==============================] - 2s 17ms/step - loss: 0.3027 - sparse_categorical_accuracy: 0.8913 - val_loss: 0.3362 - val_sparse_categorical_accuracy: 0.8796\n",
      "Epoch 97/400\n",
      "108/108 [==============================] - 2s 16ms/step - loss: 0.2987 - sparse_categorical_accuracy: 0.8929 - val_loss: 0.3430 - val_sparse_categorical_accuracy: 0.8798\n",
      "Epoch 98/400\n",
      "108/108 [==============================] - 2s 17ms/step - loss: 0.2966 - sparse_categorical_accuracy: 0.8946 - val_loss: 0.3287 - val_sparse_categorical_accuracy: 0.8844\n",
      "Epoch 99/400\n",
      "108/108 [==============================] - 2s 15ms/step - loss: 0.2955 - sparse_categorical_accuracy: 0.8945 - val_loss: 0.3255 - val_sparse_categorical_accuracy: 0.8828\n",
      "Epoch 100/400\n",
      "108/108 [==============================] - 2s 15ms/step - loss: 0.2931 - sparse_categorical_accuracy: 0.8949 - val_loss: 0.3550 - val_sparse_categorical_accuracy: 0.8732\n",
      "Epoch 101/400\n",
      "108/108 [==============================] - 2s 18ms/step - loss: 0.2961 - sparse_categorical_accuracy: 0.8939 - val_loss: 0.3356 - val_sparse_categorical_accuracy: 0.8800\n",
      "Epoch 102/400\n",
      "108/108 [==============================] - 3s 26ms/step - loss: 0.2931 - sparse_categorical_accuracy: 0.8950 - val_loss: 0.3546 - val_sparse_categorical_accuracy: 0.8748\n",
      "Epoch 103/400\n",
      "108/108 [==============================] - 2s 17ms/step - loss: 0.2948 - sparse_categorical_accuracy: 0.8950 - val_loss: 0.3319 - val_sparse_categorical_accuracy: 0.8818\n",
      "Epoch 104/400\n",
      "108/108 [==============================] - 2s 16ms/step - loss: 0.2931 - sparse_categorical_accuracy: 0.8951 - val_loss: 0.3308 - val_sparse_categorical_accuracy: 0.8836\n",
      "Epoch 105/400\n",
      "108/108 [==============================] - 2s 19ms/step - loss: 0.2895 - sparse_categorical_accuracy: 0.8967 - val_loss: 0.3309 - val_sparse_categorical_accuracy: 0.8828\n",
      "Epoch 106/400\n",
      "108/108 [==============================] - 3s 30ms/step - loss: 0.2901 - sparse_categorical_accuracy: 0.8967 - val_loss: 0.3286 - val_sparse_categorical_accuracy: 0.8846\n",
      "Epoch 107/400\n",
      "108/108 [==============================] - 3s 25ms/step - loss: 0.2881 - sparse_categorical_accuracy: 0.8964 - val_loss: 0.3255 - val_sparse_categorical_accuracy: 0.8848\n",
      "Epoch 108/400\n",
      "108/108 [==============================] - 3s 24ms/step - loss: 0.2911 - sparse_categorical_accuracy: 0.8962 - val_loss: 0.3303 - val_sparse_categorical_accuracy: 0.8788\n",
      "Epoch 109/400\n",
      "108/108 [==============================] - 2s 23ms/step - loss: 0.2885 - sparse_categorical_accuracy: 0.8977 - val_loss: 0.3418 - val_sparse_categorical_accuracy: 0.8802\n",
      "Epoch 110/400\n",
      "108/108 [==============================] - 2s 22ms/step - loss: 0.2850 - sparse_categorical_accuracy: 0.8979 - val_loss: 0.3333 - val_sparse_categorical_accuracy: 0.8754\n",
      "Epoch 111/400\n",
      "108/108 [==============================] - 2s 21ms/step - loss: 0.2860 - sparse_categorical_accuracy: 0.8973 - val_loss: 0.3294 - val_sparse_categorical_accuracy: 0.8824\n",
      "Epoch 112/400\n",
      "108/108 [==============================] - 2s 21ms/step - loss: 0.2810 - sparse_categorical_accuracy: 0.8993 - val_loss: 0.3394 - val_sparse_categorical_accuracy: 0.8796\n",
      "Epoch 113/400\n",
      "108/108 [==============================] - 2s 22ms/step - loss: 0.2807 - sparse_categorical_accuracy: 0.8991 - val_loss: 0.3347 - val_sparse_categorical_accuracy: 0.8782\n",
      "Epoch 114/400\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.2815 - sparse_categorical_accuracy: 0.8991- ETA: 0s - loss: 0.2805 - sparse_categorical_accuracy: 0 - 2s 23ms/step - loss: 0.2815 - sparse_categorical_accuracy: 0.8991 - val_loss: 0.3390 - val_sparse_categorical_accuracy: 0.8762\n",
      "Epoch 115/400\n",
      "108/108 [==============================] - 2s 22ms/step - loss: 0.2822 - sparse_categorical_accuracy: 0.8989 - val_loss: 0.3255 - val_sparse_categorical_accuracy: 0.8844\n",
      "Epoch 116/400\n",
      "108/108 [==============================] - 3s 23ms/step - loss: 0.2780 - sparse_categorical_accuracy: 0.9008 - val_loss: 0.3192 - val_sparse_categorical_accuracy: 0.8858\n",
      "Epoch 117/400\n",
      "108/108 [==============================] - 2s 22ms/step - loss: 0.2793 - sparse_categorical_accuracy: 0.9002 - val_loss: 0.3558 - val_sparse_categorical_accuracy: 0.8696\n",
      "Epoch 118/400\n",
      "108/108 [==============================] - 2s 22ms/step - loss: 0.2770 - sparse_categorical_accuracy: 0.9009 - val_loss: 0.3230 - val_sparse_categorical_accuracy: 0.8852\n",
      "Epoch 119/400\n",
      "108/108 [==============================] - 2s 19ms/step - loss: 0.2757 - sparse_categorical_accuracy: 0.9018 - val_loss: 0.3275 - val_sparse_categorical_accuracy: 0.8810\n",
      "Epoch 120/400\n",
      "108/108 [==============================] - 2s 21ms/step - loss: 0.2755 - sparse_categorical_accuracy: 0.9012 - val_loss: 0.3277 - val_sparse_categorical_accuracy: 0.8802\n",
      "Epoch 121/400\n",
      "108/108 [==============================] - 2s 21ms/step - loss: 0.2738 - sparse_categorical_accuracy: 0.9016 - val_loss: 0.3189 - val_sparse_categorical_accuracy: 0.8848\n",
      "Epoch 122/400\n",
      "108/108 [==============================] - 2s 17ms/step - loss: 0.2734 - sparse_categorical_accuracy: 0.9023 - val_loss: 0.3963 - val_sparse_categorical_accuracy: 0.8518\n",
      "Epoch 123/400\n",
      "108/108 [==============================] - 2s 17ms/step - loss: 0.2725 - sparse_categorical_accuracy: 0.9028 - val_loss: 0.3468 - val_sparse_categorical_accuracy: 0.8730\n",
      "Epoch 124/400\n",
      "108/108 [==============================] - 2s 21ms/step - loss: 0.2710 - sparse_categorical_accuracy: 0.9035 - val_loss: 0.3297 - val_sparse_categorical_accuracy: 0.8808\n",
      "Epoch 125/400\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.2694 - sparse_categorical_accuracy: 0.9041 - val_loss: 0.3180 - val_sparse_categorical_accuracy: 0.8858\n",
      "Epoch 126/400\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.2682 - sparse_categorical_accuracy: 0.9039 - val_loss: 0.3246 - val_sparse_categorical_accuracy: 0.8844loss: 0.2689 - sparse_categorical_accuracy: 0.90\n",
      "Epoch 127/400\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.2681 - sparse_categorical_accuracy: 0.9037 - val_loss: 0.3197 - val_sparse_categorical_accuracy: 0.8850\n",
      "Epoch 128/400\n",
      "108/108 [==============================] - 3s 26ms/step - loss: 0.2660 - sparse_categorical_accuracy: 0.9037 - val_loss: 0.3198 - val_sparse_categorical_accuracy: 0.8856\n",
      "Epoch 129/400\n",
      "108/108 [==============================] - 3s 26ms/step - loss: 0.2660 - sparse_categorical_accuracy: 0.9039 - val_loss: 0.3301 - val_sparse_categorical_accuracy: 0.8830\n",
      "Epoch 130/400\n",
      "108/108 [==============================] - 3s 26ms/step - loss: 0.2660 - sparse_categorical_accuracy: 0.9051 - val_loss: 0.3304 - val_sparse_categorical_accuracy: 0.8836\n",
      "Epoch 131/400\n",
      "108/108 [==============================] - 3s 26ms/step - loss: 0.2643 - sparse_categorical_accuracy: 0.9050 - val_loss: 0.3119 - val_sparse_categorical_accuracy: 0.8882\n",
      "Epoch 132/400\n",
      "108/108 [==============================] - 3s 24ms/step - loss: 0.2630 - sparse_categorical_accuracy: 0.9063 - val_loss: 0.3883 - val_sparse_categorical_accuracy: 0.8582\n",
      "Epoch 133/400\n",
      "108/108 [==============================] - 3s 24ms/step - loss: 0.2669 - sparse_categorical_accuracy: 0.9031 - val_loss: 0.3345 - val_sparse_categorical_accuracy: 0.8744\n",
      "Epoch 134/400\n",
      "108/108 [==============================] - 2s 18ms/step - loss: 0.2665 - sparse_categorical_accuracy: 0.9047 - val_loss: 0.3269 - val_sparse_categorical_accuracy: 0.8830\n",
      "Epoch 135/400\n",
      "108/108 [==============================] - 3s 25ms/step - loss: 0.2623 - sparse_categorical_accuracy: 0.9065 - val_loss: 0.3489 - val_sparse_categorical_accuracy: 0.8720\n",
      "Epoch 136/400\n",
      "108/108 [==============================] - 2s 21ms/step - loss: 0.2597 - sparse_categorical_accuracy: 0.9074 - val_loss: 0.3238 - val_sparse_categorical_accuracy: 0.8868\n",
      "Epoch 137/400\n",
      "108/108 [==============================] - 2s 17ms/step - loss: 0.2608 - sparse_categorical_accuracy: 0.9065 - val_loss: 0.3251 - val_sparse_categorical_accuracy: 0.8820\n",
      "Epoch 138/400\n",
      "108/108 [==============================] - 2s 16ms/step - loss: 0.2588 - sparse_categorical_accuracy: 0.9071 - val_loss: 0.3139 - val_sparse_categorical_accuracy: 0.8856\n",
      "Epoch 139/400\n",
      "108/108 [==============================] - 2s 17ms/step - loss: 0.2573 - sparse_categorical_accuracy: 0.9081 - val_loss: 0.3588 - val_sparse_categorical_accuracy: 0.8668\n",
      "Epoch 140/400\n",
      "108/108 [==============================] - 2s 17ms/step - loss: 0.2585 - sparse_categorical_accuracy: 0.9072 - val_loss: 0.3420 - val_sparse_categorical_accuracy: 0.8756\n",
      "Epoch 141/400\n",
      "108/108 [==============================] - 3s 25ms/step - loss: 0.2602 - sparse_categorical_accuracy: 0.9068 - val_loss: 0.3131 - val_sparse_categorical_accuracy: 0.8876\n",
      "Epoch 142/400\n",
      "108/108 [==============================] - 3s 26ms/step - loss: 0.2549 - sparse_categorical_accuracy: 0.9094 - val_loss: 0.3188 - val_sparse_categorical_accuracy: 0.8840\n",
      "Epoch 143/400\n",
      "108/108 [==============================] - 3s 30ms/step - loss: 0.2543 - sparse_categorical_accuracy: 0.9077 - val_loss: 0.3058 - val_sparse_categorical_accuracy: 0.8886\n",
      "Epoch 144/400\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.2556 - sparse_categorical_accuracy: 0.9085 - val_loss: 0.3070 - val_sparse_categorical_accuracy: 0.8896\n",
      "Epoch 145/400\n",
      "108/108 [==============================] - 4s 33ms/step - loss: 0.2535 - sparse_categorical_accuracy: 0.9086 - val_loss: 0.3196 - val_sparse_categorical_accuracy: 0.8860\n",
      "Epoch 146/400\n",
      "108/108 [==============================] - 4s 36ms/step - loss: 0.2505 - sparse_categorical_accuracy: 0.9101 - val_loss: 0.3149 - val_sparse_categorical_accuracy: 0.8894\n",
      "Epoch 147/400\n",
      "108/108 [==============================] - 4s 33ms/step - loss: 0.2508 - sparse_categorical_accuracy: 0.9101 - val_loss: 0.3159 - val_sparse_categorical_accuracy: 0.8820\n",
      "Epoch 148/400\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 0.2528 - sparse_categorical_accuracy: 0.9088 - val_loss: 0.3375 - val_sparse_categorical_accuracy: 0.8814\n",
      "Epoch 149/400\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.2487 - sparse_categorical_accuracy: 0.9115 - val_loss: 0.3113 - val_sparse_categorical_accuracy: 0.8888\n",
      "Epoch 150/400\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.2475 - sparse_categorical_accuracy: 0.9111 - val_loss: 0.3126 - val_sparse_categorical_accuracy: 0.8880ss: 0.2445 - sparse_categor\n",
      "Epoch 151/400\n",
      "108/108 [==============================] - 3s 24ms/step - loss: 0.2455 - sparse_categorical_accuracy: 0.9129 - val_loss: 0.3212 - val_sparse_categorical_accuracy: 0.8848\n",
      "Epoch 152/400\n",
      "108/108 [==============================] - 3s 25ms/step - loss: 0.2471 - sparse_categorical_accuracy: 0.9113 - val_loss: 0.3067 - val_sparse_categorical_accuracy: 0.8894\n",
      "Epoch 153/400\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 0.2451 - sparse_categorical_accuracy: 0.9117 - val_loss: 0.3133 - val_sparse_categorical_accuracy: 0.8836\n",
      "Epoch 154/400\n",
      "108/108 [==============================] - 3s 25ms/step - loss: 0.2476 - sparse_categorical_accuracy: 0.9111 - val_loss: 0.3092 - val_sparse_categorical_accuracy: 0.8890\n",
      "Epoch 155/400\n",
      "108/108 [==============================] - 3s 25ms/step - loss: 0.2436 - sparse_categorical_accuracy: 0.9126 - val_loss: 0.3050 - val_sparse_categorical_accuracy: 0.8900\n",
      "Epoch 156/400\n",
      "108/108 [==============================] - 3s 24ms/step - loss: 0.2426 - sparse_categorical_accuracy: 0.9135 - val_loss: 0.3125 - val_sparse_categorical_accuracy: 0.8868\n",
      "Epoch 157/400\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.2399 - sparse_categorical_accuracy: 0.9144 - val_loss: 0.3101 - val_sparse_categorical_accuracy: 0.8862\n",
      "Epoch 158/400\n",
      "108/108 [==============================] - 3s 26ms/step - loss: 0.2426 - sparse_categorical_accuracy: 0.9127 - val_loss: 0.3104 - val_sparse_categorical_accuracy: 0.8896\n",
      "Epoch 159/400\n",
      "108/108 [==============================] - 3s 26ms/step - loss: 0.2430 - sparse_categorical_accuracy: 0.9132 - val_loss: 0.3047 - val_sparse_categorical_accuracy: 0.8904\n",
      "Epoch 160/400\n",
      "108/108 [==============================] - 2s 23ms/step - loss: 0.2416 - sparse_categorical_accuracy: 0.9130 - val_loss: 0.3190 - val_sparse_categorical_accuracy: 0.8860\n",
      "Epoch 161/400\n",
      "108/108 [==============================] - 3s 24ms/step - loss: 0.2381 - sparse_categorical_accuracy: 0.9145 - val_loss: 0.3138 - val_sparse_categorical_accuracy: 0.8838\n",
      "Epoch 162/400\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.2389 - sparse_categorical_accuracy: 0.9150 - val_loss: 0.3175 - val_sparse_categorical_accuracy: 0.8842\n",
      "Epoch 163/400\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 0.2386 - sparse_categorical_accuracy: 0.9142 - val_loss: 0.3442 - val_sparse_categorical_accuracy: 0.8726\n",
      "Epoch 164/400\n",
      "108/108 [==============================] - 2s 21ms/step - loss: 0.2398 - sparse_categorical_accuracy: 0.9129 - val_loss: 0.3223 - val_sparse_categorical_accuracy: 0.8846\n",
      "Epoch 165/400\n",
      "108/108 [==============================] - 2s 19ms/step - loss: 0.2378 - sparse_categorical_accuracy: 0.9147 - val_loss: 0.3022 - val_sparse_categorical_accuracy: 0.8930\n",
      "Epoch 166/400\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.2391 - sparse_categorical_accuracy: 0.9145 - val_loss: 0.3047 - val_sparse_categorical_accuracy: 0.8898\n",
      "Epoch 167/400\n",
      "108/108 [==============================] - 3s 30ms/step - loss: 0.2357 - sparse_categorical_accuracy: 0.9154 - val_loss: 0.3004 - val_sparse_categorical_accuracy: 0.8916\n",
      "Epoch 168/400\n",
      "108/108 [==============================] - 3s 26ms/step - loss: 0.2346 - sparse_categorical_accuracy: 0.9160 - val_loss: 0.3281 - val_sparse_categorical_accuracy: 0.8828\n",
      "Epoch 169/400\n",
      "108/108 [==============================] - 3s 25ms/step - loss: 0.2360 - sparse_categorical_accuracy: 0.9153 - val_loss: 0.3492 - val_sparse_categorical_accuracy: 0.8712\n",
      "Epoch 170/400\n",
      "108/108 [==============================] - 3s 23ms/step - loss: 0.2322 - sparse_categorical_accuracy: 0.9169 - val_loss: 0.3580 - val_sparse_categorical_accuracy: 0.8694\n",
      "Epoch 171/400\n",
      "108/108 [==============================] - 2s 21ms/step - loss: 0.2318 - sparse_categorical_accuracy: 0.9164 - val_loss: 0.3019 - val_sparse_categorical_accuracy: 0.8926\n",
      "Epoch 172/400\n",
      "108/108 [==============================] - 2s 21ms/step - loss: 0.2322 - sparse_categorical_accuracy: 0.9166 - val_loss: 0.3424 - val_sparse_categorical_accuracy: 0.8794\n",
      "Epoch 173/400\n",
      "108/108 [==============================] - 2s 22ms/step - loss: 0.2291 - sparse_categorical_accuracy: 0.9189 - val_loss: 0.3073 - val_sparse_categorical_accuracy: 0.8882\n",
      "Epoch 174/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 [==============================] - 2s 21ms/step - loss: 0.2312 - sparse_categorical_accuracy: 0.9168 - val_loss: 0.3039 - val_sparse_categorical_accuracy: 0.8898\n",
      "Epoch 175/400\n",
      "108/108 [==============================] - 2s 18ms/step - loss: 0.2294 - sparse_categorical_accuracy: 0.9174 - val_loss: 0.3264 - val_sparse_categorical_accuracy: 0.8824\n",
      "Epoch 176/400\n",
      "108/108 [==============================] - 2s 22ms/step - loss: 0.2281 - sparse_categorical_accuracy: 0.9172 - val_loss: 0.3107 - val_sparse_categorical_accuracy: 0.8908\n",
      "Epoch 177/400\n",
      "108/108 [==============================] - 3s 23ms/step - loss: 0.2282 - sparse_categorical_accuracy: 0.9182 - val_loss: 0.3061 - val_sparse_categorical_accuracy: 0.8884 - loss: 0.2294 - sparse_categorical_a\n",
      "Epoch 178/400\n",
      "108/108 [==============================] - 2s 22ms/step - loss: 0.2230 - sparse_categorical_accuracy: 0.9208 - val_loss: 0.3250 - val_sparse_categorical_accuracy: 0.8850\n",
      "Epoch 179/400\n",
      "108/108 [==============================] - 2s 21ms/step - loss: 0.2313 - sparse_categorical_accuracy: 0.9163 - val_loss: 0.2995 - val_sparse_categorical_accuracy: 0.8946\n",
      "Epoch 180/400\n",
      "108/108 [==============================] - 2s 21ms/step - loss: 0.2227 - sparse_categorical_accuracy: 0.9205 - val_loss: 0.3063 - val_sparse_categorical_accuracy: 0.8870\n",
      "Epoch 181/400\n",
      "108/108 [==============================] - 2s 20ms/step - loss: 0.2245 - sparse_categorical_accuracy: 0.9188 - val_loss: 0.3146 - val_sparse_categorical_accuracy: 0.8864\n",
      "Epoch 182/400\n",
      "108/108 [==============================] - 2s 22ms/step - loss: 0.2268 - sparse_categorical_accuracy: 0.9187 - val_loss: 0.3441 - val_sparse_categorical_accuracy: 0.8740\n",
      "Epoch 183/400\n",
      "108/108 [==============================] - 2s 23ms/step - loss: 0.2213 - sparse_categorical_accuracy: 0.9207 - val_loss: 0.3003 - val_sparse_categorical_accuracy: 0.8942\n",
      "Epoch 184/400\n",
      "108/108 [==============================] - 2s 21ms/step - loss: 0.2230 - sparse_categorical_accuracy: 0.9206 - val_loss: 0.3678 - val_sparse_categorical_accuracy: 0.8634\n",
      "Epoch 185/400\n",
      "108/108 [==============================] - 2s 21ms/step - loss: 0.2209 - sparse_categorical_accuracy: 0.9207 - val_loss: 0.2963 - val_sparse_categorical_accuracy: 0.8906\n",
      "Epoch 186/400\n",
      "108/108 [==============================] - 2s 20ms/step - loss: 0.2191 - sparse_categorical_accuracy: 0.9214 - val_loss: 0.3377 - val_sparse_categorical_accuracy: 0.8820\n",
      "Epoch 187/400\n",
      "108/108 [==============================] - 2s 21ms/step - loss: 0.2209 - sparse_categorical_accuracy: 0.9209 - val_loss: 0.3073 - val_sparse_categorical_accuracy: 0.8900\n",
      "Epoch 188/400\n",
      "108/108 [==============================] - 2s 23ms/step - loss: 0.2220 - sparse_categorical_accuracy: 0.9212 - val_loss: 0.2947 - val_sparse_categorical_accuracy: 0.8924\n",
      "Epoch 189/400\n",
      "108/108 [==============================] - 2s 23ms/step - loss: 0.2225 - sparse_categorical_accuracy: 0.9196 - val_loss: 0.3086 - val_sparse_categorical_accuracy: 0.8888\n",
      "Epoch 190/400\n",
      "108/108 [==============================] - 2s 21ms/step - loss: 0.2146 - sparse_categorical_accuracy: 0.9243 - val_loss: 0.3050 - val_sparse_categorical_accuracy: 0.8874\n",
      "Epoch 191/400\n",
      "108/108 [==============================] - 2s 17ms/step - loss: 0.2218 - sparse_categorical_accuracy: 0.9207 - val_loss: 0.3058 - val_sparse_categorical_accuracy: 0.8888\n",
      "Epoch 192/400\n",
      "108/108 [==============================] - 2s 16ms/step - loss: 0.2180 - sparse_categorical_accuracy: 0.9218 - val_loss: 0.3024 - val_sparse_categorical_accuracy: 0.8926\n",
      "Epoch 193/400\n",
      "108/108 [==============================] - 2s 20ms/step - loss: 0.2180 - sparse_categorical_accuracy: 0.9219 - val_loss: 0.3225 - val_sparse_categorical_accuracy: 0.8836\n",
      "Epoch 194/400\n",
      "108/108 [==============================] - 2s 20ms/step - loss: 0.2135 - sparse_categorical_accuracy: 0.9235 - val_loss: 0.3265 - val_sparse_categorical_accuracy: 0.8784\n",
      "Epoch 195/400\n",
      "108/108 [==============================] - 2s 20ms/step - loss: 0.2165 - sparse_categorical_accuracy: 0.9213 - val_loss: 0.3020 - val_sparse_categorical_accuracy: 0.8922\n",
      "Epoch 196/400\n",
      "108/108 [==============================] - 2s 20ms/step - loss: 0.2126 - sparse_categorical_accuracy: 0.9234 - val_loss: 0.3017 - val_sparse_categorical_accuracy: 0.8934\n",
      "Epoch 197/400\n",
      "108/108 [==============================] - 2s 20ms/step - loss: 0.2133 - sparse_categorical_accuracy: 0.9234 - val_loss: 0.2971 - val_sparse_categorical_accuracy: 0.8910\n",
      "Epoch 198/400\n",
      "108/108 [==============================] - 2s 21ms/step - loss: 0.2160 - sparse_categorical_accuracy: 0.9225 - val_loss: 0.3474 - val_sparse_categorical_accuracy: 0.8824\n",
      "Epoch 199/400\n",
      "108/108 [==============================] - 2s 21ms/step - loss: 0.2109 - sparse_categorical_accuracy: 0.9241 - val_loss: 0.3369 - val_sparse_categorical_accuracy: 0.8830\n",
      "Epoch 200/400\n",
      "108/108 [==============================] - 2s 20ms/step - loss: 0.2108 - sparse_categorical_accuracy: 0.9245 - val_loss: 0.3014 - val_sparse_categorical_accuracy: 0.8934\n",
      "Epoch 201/400\n",
      "108/108 [==============================] - 2s 22ms/step - loss: 0.2109 - sparse_categorical_accuracy: 0.9245 - val_loss: 0.3856 - val_sparse_categorical_accuracy: 0.8658\n",
      "Epoch 202/400\n",
      "108/108 [==============================] - 2s 22ms/step - loss: 0.2077 - sparse_categorical_accuracy: 0.9255 - val_loss: 0.2939 - val_sparse_categorical_accuracy: 0.8942\n",
      "Epoch 203/400\n",
      "108/108 [==============================] - 2s 19ms/step - loss: 0.2088 - sparse_categorical_accuracy: 0.9262 - val_loss: 0.3072 - val_sparse_categorical_accuracy: 0.8880\n",
      "Epoch 204/400\n",
      "108/108 [==============================] - 2s 18ms/step - loss: 0.2101 - sparse_categorical_accuracy: 0.9238 - val_loss: 0.3186 - val_sparse_categorical_accuracy: 0.8892\n",
      "Epoch 205/400\n",
      "108/108 [==============================] - 2s 17ms/step - loss: 0.2059 - sparse_categorical_accuracy: 0.9260 - val_loss: 0.3003 - val_sparse_categorical_accuracy: 0.8918\n",
      "Epoch 206/400\n",
      "108/108 [==============================] - 2s 16ms/step - loss: 0.2071 - sparse_categorical_accuracy: 0.9254 - val_loss: 0.2997 - val_sparse_categorical_accuracy: 0.8946\n",
      "Epoch 207/400\n",
      "108/108 [==============================] - 2s 15ms/step - loss: 0.2094 - sparse_categorical_accuracy: 0.9254 - val_loss: 0.3389 - val_sparse_categorical_accuracy: 0.8824\n",
      "Epoch 208/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.2080 - sparse_categorical_accuracy: 0.9247 - val_loss: 0.3251 - val_sparse_categorical_accuracy: 0.8818\n",
      "Epoch 209/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.2044 - sparse_categorical_accuracy: 0.9268 - val_loss: 0.3023 - val_sparse_categorical_accuracy: 0.8934\n",
      "Epoch 210/400\n",
      "108/108 [==============================] - 2s 14ms/step - loss: 0.2017 - sparse_categorical_accuracy: 0.9281 - val_loss: 0.2961 - val_sparse_categorical_accuracy: 0.8920\n",
      "Epoch 211/400\n",
      "108/108 [==============================] - 1s 14ms/step - loss: 0.2007 - sparse_categorical_accuracy: 0.9285 - val_loss: 0.3066 - val_sparse_categorical_accuracy: 0.8904\n",
      "Epoch 212/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.2041 - sparse_categorical_accuracy: 0.9279 - val_loss: 0.3196 - val_sparse_categorical_accuracy: 0.8874\n",
      "Epoch 213/400\n",
      "108/108 [==============================] - 2s 15ms/step - loss: 0.2027 - sparse_categorical_accuracy: 0.9277 - val_loss: 0.3247 - val_sparse_categorical_accuracy: 0.8848\n",
      "Epoch 214/400\n",
      "108/108 [==============================] - 2s 15ms/step - loss: 0.2028 - sparse_categorical_accuracy: 0.9268 - val_loss: 0.3040 - val_sparse_categorical_accuracy: 0.8926\n",
      "Epoch 215/400\n",
      "108/108 [==============================] - 2s 14ms/step - loss: 0.1981 - sparse_categorical_accuracy: 0.9300 - val_loss: 0.2965 - val_sparse_categorical_accuracy: 0.8938\n",
      "Epoch 216/400\n",
      "108/108 [==============================] - 1s 14ms/step - loss: 0.1991 - sparse_categorical_accuracy: 0.9284 - val_loss: 0.3001 - val_sparse_categorical_accuracy: 0.8958\n",
      "Epoch 217/400\n",
      "108/108 [==============================] - 2s 14ms/step - loss: 0.2092 - sparse_categorical_accuracy: 0.9247 - val_loss: 0.3045 - val_sparse_categorical_accuracy: 0.8918\n",
      "Epoch 218/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.2002 - sparse_categorical_accuracy: 0.9289 - val_loss: 0.3123 - val_sparse_categorical_accuracy: 0.8864\n",
      "Epoch 219/400\n",
      "108/108 [==============================] - 2s 14ms/step - loss: 0.1963 - sparse_categorical_accuracy: 0.9299 - val_loss: 0.3012 - val_sparse_categorical_accuracy: 0.8928\n",
      "Epoch 220/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1967 - sparse_categorical_accuracy: 0.9286 - val_loss: 0.3180 - val_sparse_categorical_accuracy: 0.8828\n",
      "Epoch 221/400\n",
      "108/108 [==============================] - 1s 12ms/step - loss: 0.2022 - sparse_categorical_accuracy: 0.9273 - val_loss: 0.3014 - val_sparse_categorical_accuracy: 0.8924\n",
      "Epoch 222/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1953 - sparse_categorical_accuracy: 0.9304 - val_loss: 0.3252 - val_sparse_categorical_accuracy: 0.8838\n",
      "Epoch 223/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1986 - sparse_categorical_accuracy: 0.9278 - val_loss: 0.3483 - val_sparse_categorical_accuracy: 0.8784\n",
      "Epoch 224/400\n",
      "108/108 [==============================] - 2s 14ms/step - loss: 0.1963 - sparse_categorical_accuracy: 0.9301 - val_loss: 0.3164 - val_sparse_categorical_accuracy: 0.8874\n",
      "Epoch 225/400\n",
      "108/108 [==============================] - 2s 14ms/step - loss: 0.1900 - sparse_categorical_accuracy: 0.9332 - val_loss: 0.3116 - val_sparse_categorical_accuracy: 0.8918\n",
      "Epoch 226/400\n",
      "108/108 [==============================] - 1s 14ms/step - loss: 0.1975 - sparse_categorical_accuracy: 0.9293 - val_loss: 0.3040 - val_sparse_categorical_accuracy: 0.8904\n",
      "Epoch 227/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1922 - sparse_categorical_accuracy: 0.9315 - val_loss: 0.3054 - val_sparse_categorical_accuracy: 0.8910\n",
      "Epoch 228/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1954 - sparse_categorical_accuracy: 0.9301 - val_loss: 0.2977 - val_sparse_categorical_accuracy: 0.8954\n",
      "Epoch 229/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1911 - sparse_categorical_accuracy: 0.9329 - val_loss: 0.3124 - val_sparse_categorical_accuracy: 0.8886\n",
      "Epoch 230/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1907 - sparse_categorical_accuracy: 0.9321 - val_loss: 0.3008 - val_sparse_categorical_accuracy: 0.8920\n",
      "Epoch 231/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1907 - sparse_categorical_accuracy: 0.9326 - val_loss: 0.3185 - val_sparse_categorical_accuracy: 0.8876\n",
      "Epoch 232/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1922 - sparse_categorical_accuracy: 0.9303 - val_loss: 0.3863 - val_sparse_categorical_accuracy: 0.8630\n",
      "Epoch 233/400\n",
      "108/108 [==============================] - 2s 14ms/step - loss: 0.1889 - sparse_categorical_accuracy: 0.9327 - val_loss: 0.3235 - val_sparse_categorical_accuracy: 0.8860\n",
      "Epoch 234/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1912 - sparse_categorical_accuracy: 0.9314 - val_loss: 0.3279 - val_sparse_categorical_accuracy: 0.8860\n",
      "Epoch 235/400\n",
      "108/108 [==============================] - 1s 14ms/step - loss: 0.1876 - sparse_categorical_accuracy: 0.9328 - val_loss: 0.3458 - val_sparse_categorical_accuracy: 0.8804\n",
      "Epoch 236/400\n",
      "108/108 [==============================] - 1s 14ms/step - loss: 0.1873 - sparse_categorical_accuracy: 0.9335 - val_loss: 0.2967 - val_sparse_categorical_accuracy: 0.8954\n",
      "Epoch 237/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1876 - sparse_categorical_accuracy: 0.9331 - val_loss: 0.3590 - val_sparse_categorical_accuracy: 0.8826\n",
      "Epoch 238/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1842 - sparse_categorical_accuracy: 0.9349 - val_loss: 0.3102 - val_sparse_categorical_accuracy: 0.8938\n",
      "Epoch 239/400\n",
      "108/108 [==============================] - 1s 12ms/step - loss: 0.1889 - sparse_categorical_accuracy: 0.9314 - val_loss: 0.3219 - val_sparse_categorical_accuracy: 0.8864\n",
      "Epoch 240/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1864 - sparse_categorical_accuracy: 0.9334 - val_loss: 0.3642 - val_sparse_categorical_accuracy: 0.8690\n",
      "Epoch 241/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1894 - sparse_categorical_accuracy: 0.9319 - val_loss: 0.3231 - val_sparse_categorical_accuracy: 0.8838\n",
      "Epoch 242/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1852 - sparse_categorical_accuracy: 0.9342 - val_loss: 0.3096 - val_sparse_categorical_accuracy: 0.8918\n",
      "Epoch 243/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1841 - sparse_categorical_accuracy: 0.9343 - val_loss: 0.2946 - val_sparse_categorical_accuracy: 0.8954\n",
      "Epoch 244/400\n",
      "108/108 [==============================] - 1s 14ms/step - loss: 0.1839 - sparse_categorical_accuracy: 0.9341 - val_loss: 0.3101 - val_sparse_categorical_accuracy: 0.8928\n",
      "Epoch 245/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1784 - sparse_categorical_accuracy: 0.9376 - val_loss: 0.3078 - val_sparse_categorical_accuracy: 0.8902\n",
      "Epoch 246/400\n",
      "108/108 [==============================] - 1s 14ms/step - loss: 0.1792 - sparse_categorical_accuracy: 0.9357 - val_loss: 0.3140 - val_sparse_categorical_accuracy: 0.8898\n",
      "Epoch 247/400\n",
      "108/108 [==============================] - 2s 14ms/step - loss: 0.1823 - sparse_categorical_accuracy: 0.9364 - val_loss: 0.2905 - val_sparse_categorical_accuracy: 0.8984\n",
      "Epoch 248/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1802 - sparse_categorical_accuracy: 0.9356 - val_loss: 0.3229 - val_sparse_categorical_accuracy: 0.8890\n",
      "Epoch 249/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1779 - sparse_categorical_accuracy: 0.9365 - val_loss: 0.3087 - val_sparse_categorical_accuracy: 0.8908\n",
      "Epoch 250/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1796 - sparse_categorical_accuracy: 0.9362 - val_loss: 0.3047 - val_sparse_categorical_accuracy: 0.8946\n",
      "Epoch 251/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1765 - sparse_categorical_accuracy: 0.9380 - val_loss: 0.3124 - val_sparse_categorical_accuracy: 0.8926\n",
      "Epoch 252/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1772 - sparse_categorical_accuracy: 0.9364 - val_loss: 0.3307 - val_sparse_categorical_accuracy: 0.8850\n",
      "Epoch 253/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1808 - sparse_categorical_accuracy: 0.9359 - val_loss: 0.3441 - val_sparse_categorical_accuracy: 0.8788\n",
      "Epoch 254/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1764 - sparse_categorical_accuracy: 0.9373 - val_loss: 0.3029 - val_sparse_categorical_accuracy: 0.8942\n",
      "Epoch 255/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1732 - sparse_categorical_accuracy: 0.9384 - val_loss: 0.3229 - val_sparse_categorical_accuracy: 0.8880\n",
      "Epoch 256/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1757 - sparse_categorical_accuracy: 0.9386 - val_loss: 0.3101 - val_sparse_categorical_accuracy: 0.8886\n",
      "Epoch 257/400\n",
      "108/108 [==============================] - 2s 14ms/step - loss: 0.1731 - sparse_categorical_accuracy: 0.9390 - val_loss: 0.3076 - val_sparse_categorical_accuracy: 0.8960\n",
      "Epoch 258/400\n",
      "108/108 [==============================] - 2s 14ms/step - loss: 0.1742 - sparse_categorical_accuracy: 0.9385 - val_loss: 0.3312 - val_sparse_categorical_accuracy: 0.8866\n",
      "Epoch 259/400\n",
      "108/108 [==============================] - 1s 14ms/step - loss: 0.1686 - sparse_categorical_accuracy: 0.9401 - val_loss: 0.3414 - val_sparse_categorical_accuracy: 0.8822\n",
      "Epoch 260/400\n",
      "108/108 [==============================] - 1s 14ms/step - loss: 0.1767 - sparse_categorical_accuracy: 0.9372 - val_loss: 0.2997 - val_sparse_categorical_accuracy: 0.8930\n",
      "Epoch 261/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1740 - sparse_categorical_accuracy: 0.9379 - val_loss: 0.3042 - val_sparse_categorical_accuracy: 0.8932\n",
      "Epoch 262/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1700 - sparse_categorical_accuracy: 0.9401 - val_loss: 0.3203 - val_sparse_categorical_accuracy: 0.8900\n",
      "Epoch 263/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1675 - sparse_categorical_accuracy: 0.9404 - val_loss: 0.3013 - val_sparse_categorical_accuracy: 0.8946\n",
      "Epoch 264/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1684 - sparse_categorical_accuracy: 0.9395 - val_loss: 0.2991 - val_sparse_categorical_accuracy: 0.8944\n",
      "Epoch 265/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1754 - sparse_categorical_accuracy: 0.9372 - val_loss: 0.3393 - val_sparse_categorical_accuracy: 0.8792\n",
      "Epoch 266/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1722 - sparse_categorical_accuracy: 0.9393 - val_loss: 0.2946 - val_sparse_categorical_accuracy: 0.8968\n",
      "Epoch 267/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1644 - sparse_categorical_accuracy: 0.9423 - val_loss: 0.3057 - val_sparse_categorical_accuracy: 0.8892\n",
      "Epoch 268/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1711 - sparse_categorical_accuracy: 0.9395 - val_loss: 0.3022 - val_sparse_categorical_accuracy: 0.8964\n",
      "Epoch 269/400\n",
      "108/108 [==============================] - 2s 14ms/step - loss: 0.1625 - sparse_categorical_accuracy: 0.9430 - val_loss: 0.3108 - val_sparse_categorical_accuracy: 0.8912\n",
      "Epoch 270/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1650 - sparse_categorical_accuracy: 0.9413 - val_loss: 0.3477 - val_sparse_categorical_accuracy: 0.8814\n",
      "Epoch 271/400\n",
      "108/108 [==============================] - 1s 12ms/step - loss: 0.1693 - sparse_categorical_accuracy: 0.9399 - val_loss: 0.3825 - val_sparse_categorical_accuracy: 0.8716\n",
      "Epoch 272/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1673 - sparse_categorical_accuracy: 0.9409 - val_loss: 0.3415 - val_sparse_categorical_accuracy: 0.8844\n",
      "Epoch 273/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1660 - sparse_categorical_accuracy: 0.9414 - val_loss: 0.3138 - val_sparse_categorical_accuracy: 0.8898\n",
      "Epoch 274/400\n",
      "108/108 [==============================] - 1s 12ms/step - loss: 0.1600 - sparse_categorical_accuracy: 0.9444 - val_loss: 0.3268 - val_sparse_categorical_accuracy: 0.8874\n",
      "Epoch 275/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1639 - sparse_categorical_accuracy: 0.9427 - val_loss: 0.4655 - val_sparse_categorical_accuracy: 0.8568\n",
      "Epoch 276/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1596 - sparse_categorical_accuracy: 0.9432 - val_loss: 0.4129 - val_sparse_categorical_accuracy: 0.8612\n",
      "Epoch 277/400\n",
      "108/108 [==============================] - 1s 12ms/step - loss: 0.1671 - sparse_categorical_accuracy: 0.9407 - val_loss: 0.3210 - val_sparse_categorical_accuracy: 0.8888\n",
      "Epoch 278/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1596 - sparse_categorical_accuracy: 0.9445 - val_loss: 0.3001 - val_sparse_categorical_accuracy: 0.8954\n",
      "Epoch 279/400\n",
      "108/108 [==============================] - 1s 14ms/step - loss: 0.1593 - sparse_categorical_accuracy: 0.9437 - val_loss: 0.3062 - val_sparse_categorical_accuracy: 0.8920\n",
      "Epoch 280/400\n",
      "108/108 [==============================] - 2s 14ms/step - loss: 0.1627 - sparse_categorical_accuracy: 0.9428 - val_loss: 0.3112 - val_sparse_categorical_accuracy: 0.8946\n",
      "Epoch 281/400\n",
      "108/108 [==============================] - 1s 14ms/step - loss: 0.1602 - sparse_categorical_accuracy: 0.9433 - val_loss: 0.3177 - val_sparse_categorical_accuracy: 0.8924\n",
      "Epoch 282/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1605 - sparse_categorical_accuracy: 0.9433 - val_loss: 0.3072 - val_sparse_categorical_accuracy: 0.8930\n",
      "Epoch 283/400\n",
      "108/108 [==============================] - 1s 14ms/step - loss: 0.1574 - sparse_categorical_accuracy: 0.9446 - val_loss: 0.3031 - val_sparse_categorical_accuracy: 0.8966\n",
      "Epoch 284/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1604 - sparse_categorical_accuracy: 0.9435 - val_loss: 0.3944 - val_sparse_categorical_accuracy: 0.8750\n",
      "Epoch 285/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1602 - sparse_categorical_accuracy: 0.9427 - val_loss: 0.3151 - val_sparse_categorical_accuracy: 0.8880\n",
      "Epoch 286/400\n",
      "108/108 [==============================] - 1s 14ms/step - loss: 0.1490 - sparse_categorical_accuracy: 0.9485 - val_loss: 0.3175 - val_sparse_categorical_accuracy: 0.8900\n",
      "Epoch 287/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1601 - sparse_categorical_accuracy: 0.9445 - val_loss: 0.3014 - val_sparse_categorical_accuracy: 0.8952\n",
      "Epoch 288/400\n",
      "108/108 [==============================] - 1s 12ms/step - loss: 0.1570 - sparse_categorical_accuracy: 0.9449 - val_loss: 0.3165 - val_sparse_categorical_accuracy: 0.8904\n",
      "Epoch 289/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1571 - sparse_categorical_accuracy: 0.9458 - val_loss: 0.3260 - val_sparse_categorical_accuracy: 0.8858\n",
      "Epoch 290/400\n",
      "108/108 [==============================] - 1s 14ms/step - loss: 0.1497 - sparse_categorical_accuracy: 0.9475 - val_loss: 0.3237 - val_sparse_categorical_accuracy: 0.8896\n",
      "Epoch 291/400\n",
      "108/108 [==============================] - 2s 14ms/step - loss: 0.1540 - sparse_categorical_accuracy: 0.9458 - val_loss: 0.3500 - val_sparse_categorical_accuracy: 0.8834\n",
      "Epoch 292/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1545 - sparse_categorical_accuracy: 0.9453 - val_loss: 0.3248 - val_sparse_categorical_accuracy: 0.8854\n",
      "Epoch 293/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1539 - sparse_categorical_accuracy: 0.9459 - val_loss: 0.3327 - val_sparse_categorical_accuracy: 0.8862\n",
      "Epoch 294/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1527 - sparse_categorical_accuracy: 0.9465 - val_loss: 0.3891 - val_sparse_categorical_accuracy: 0.8766\n",
      "Epoch 295/400\n",
      "108/108 [==============================] - 1s 12ms/step - loss: 0.1542 - sparse_categorical_accuracy: 0.9457 - val_loss: 0.3045 - val_sparse_categorical_accuracy: 0.8938\n",
      "Epoch 296/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1449 - sparse_categorical_accuracy: 0.9491 - val_loss: 0.3853 - val_sparse_categorical_accuracy: 0.8754\n",
      "Epoch 297/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1499 - sparse_categorical_accuracy: 0.9486 - val_loss: 0.3083 - val_sparse_categorical_accuracy: 0.8944\n",
      "Epoch 298/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1460 - sparse_categorical_accuracy: 0.9482 - val_loss: 0.3069 - val_sparse_categorical_accuracy: 0.8946\n",
      "Epoch 299/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1480 - sparse_categorical_accuracy: 0.9481 - val_loss: 0.3424 - val_sparse_categorical_accuracy: 0.8866\n",
      "Epoch 300/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1501 - sparse_categorical_accuracy: 0.9475 - val_loss: 0.3058 - val_sparse_categorical_accuracy: 0.8948\n",
      "Epoch 301/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1483 - sparse_categorical_accuracy: 0.9484 - val_loss: 0.3200 - val_sparse_categorical_accuracy: 0.8932\n",
      "Epoch 302/400\n",
      "108/108 [==============================] - 2s 15ms/step - loss: 0.1463 - sparse_categorical_accuracy: 0.9491 - val_loss: 0.3004 - val_sparse_categorical_accuracy: 0.8998\n",
      "Epoch 303/400\n",
      "108/108 [==============================] - 2s 15ms/step - loss: 0.1434 - sparse_categorical_accuracy: 0.9495 - val_loss: 0.3161 - val_sparse_categorical_accuracy: 0.8926\n",
      "Epoch 304/400\n",
      "108/108 [==============================] - 1s 14ms/step - loss: 0.1475 - sparse_categorical_accuracy: 0.9480 - val_loss: 0.3149 - val_sparse_categorical_accuracy: 0.8950\n",
      "Epoch 305/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1417 - sparse_categorical_accuracy: 0.9505 - val_loss: 0.3006 - val_sparse_categorical_accuracy: 0.8998\n",
      "Epoch 306/400\n",
      "108/108 [==============================] - 1s 12ms/step - loss: 0.1382 - sparse_categorical_accuracy: 0.9525 - val_loss: 0.3089 - val_sparse_categorical_accuracy: 0.8954\n",
      "Epoch 307/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1447 - sparse_categorical_accuracy: 0.9497 - val_loss: 0.3090 - val_sparse_categorical_accuracy: 0.8916\n",
      "Epoch 308/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1438 - sparse_categorical_accuracy: 0.9493 - val_loss: 0.3091 - val_sparse_categorical_accuracy: 0.8964\n",
      "Epoch 309/400\n",
      "108/108 [==============================] - 1s 12ms/step - loss: 0.1434 - sparse_categorical_accuracy: 0.9499 - val_loss: 0.3128 - val_sparse_categorical_accuracy: 0.8968\n",
      "Epoch 310/400\n",
      "108/108 [==============================] - 1s 12ms/step - loss: 0.1439 - sparse_categorical_accuracy: 0.9485 - val_loss: 0.2987 - val_sparse_categorical_accuracy: 0.8984\n",
      "Epoch 311/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1361 - sparse_categorical_accuracy: 0.9530 - val_loss: 0.3137 - val_sparse_categorical_accuracy: 0.8946\n",
      "Epoch 312/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1470 - sparse_categorical_accuracy: 0.9487 - val_loss: 0.3071 - val_sparse_categorical_accuracy: 0.8958\n",
      "Epoch 313/400\n",
      "108/108 [==============================] - 1s 14ms/step - loss: 0.1404 - sparse_categorical_accuracy: 0.9509 - val_loss: 0.3232 - val_sparse_categorical_accuracy: 0.8924\n",
      "Epoch 314/400\n",
      "108/108 [==============================] - 2s 14ms/step - loss: 0.1347 - sparse_categorical_accuracy: 0.9532 - val_loss: 0.3233 - val_sparse_categorical_accuracy: 0.8932\n",
      "Epoch 315/400\n",
      "108/108 [==============================] - 1s 14ms/step - loss: 0.1437 - sparse_categorical_accuracy: 0.9502 - val_loss: 0.3040 - val_sparse_categorical_accuracy: 0.8954\n",
      "Epoch 316/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1508 - sparse_categorical_accuracy: 0.9462 - val_loss: 0.3455 - val_sparse_categorical_accuracy: 0.8896\n",
      "Epoch 317/400\n",
      "108/108 [==============================] - 1s 12ms/step - loss: 0.1408 - sparse_categorical_accuracy: 0.9510 - val_loss: 0.3043 - val_sparse_categorical_accuracy: 0.8950\n",
      "Epoch 318/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1436 - sparse_categorical_accuracy: 0.9491 - val_loss: 0.3154 - val_sparse_categorical_accuracy: 0.8940\n",
      "Epoch 319/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1354 - sparse_categorical_accuracy: 0.9534 - val_loss: 0.3498 - val_sparse_categorical_accuracy: 0.8856\n",
      "Epoch 320/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1395 - sparse_categorical_accuracy: 0.9512 - val_loss: 0.3223 - val_sparse_categorical_accuracy: 0.8932\n",
      "Epoch 321/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1370 - sparse_categorical_accuracy: 0.9519 - val_loss: 0.3469 - val_sparse_categorical_accuracy: 0.8896\n",
      "Epoch 322/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1401 - sparse_categorical_accuracy: 0.9519 - val_loss: 0.3054 - val_sparse_categorical_accuracy: 0.8962\n",
      "Epoch 323/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1337 - sparse_categorical_accuracy: 0.9537 - val_loss: 0.5061 - val_sparse_categorical_accuracy: 0.8460\n",
      "Epoch 324/400\n",
      "108/108 [==============================] - 1s 14ms/step - loss: 0.1342 - sparse_categorical_accuracy: 0.9535 - val_loss: 0.3615 - val_sparse_categorical_accuracy: 0.8836\n",
      "Epoch 325/400\n",
      "108/108 [==============================] - 2s 14ms/step - loss: 0.1316 - sparse_categorical_accuracy: 0.9545 - val_loss: 0.3364 - val_sparse_categorical_accuracy: 0.8888\n",
      "Epoch 326/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1302 - sparse_categorical_accuracy: 0.9561 - val_loss: 0.3714 - val_sparse_categorical_accuracy: 0.8756\n",
      "Epoch 327/400\n",
      "108/108 [==============================] - 1s 12ms/step - loss: 0.1309 - sparse_categorical_accuracy: 0.9539 - val_loss: 0.3127 - val_sparse_categorical_accuracy: 0.8942\n",
      "Epoch 328/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1385 - sparse_categorical_accuracy: 0.9519 - val_loss: 0.3477 - val_sparse_categorical_accuracy: 0.8856\n",
      "Epoch 329/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1224 - sparse_categorical_accuracy: 0.9586 - val_loss: 0.3176 - val_sparse_categorical_accuracy: 0.8936\n",
      "Epoch 330/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1539 - sparse_categorical_accuracy: 0.9496 - val_loss: 0.3235 - val_sparse_categorical_accuracy: 0.8922\n",
      "Epoch 331/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1260 - sparse_categorical_accuracy: 0.9566 - val_loss: 0.3357 - val_sparse_categorical_accuracy: 0.8884\n",
      "Epoch 332/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1327 - sparse_categorical_accuracy: 0.9542 - val_loss: 0.3154 - val_sparse_categorical_accuracy: 0.8946\n",
      "Epoch 333/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1230 - sparse_categorical_accuracy: 0.9588 - val_loss: 0.3560 - val_sparse_categorical_accuracy: 0.8822\n",
      "Epoch 334/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1264 - sparse_categorical_accuracy: 0.9561 - val_loss: 0.3213 - val_sparse_categorical_accuracy: 0.8970\n",
      "Epoch 335/400\n",
      "108/108 [==============================] - 2s 14ms/step - loss: 0.1219 - sparse_categorical_accuracy: 0.9585 - val_loss: 0.3282 - val_sparse_categorical_accuracy: 0.8880\n",
      "Epoch 336/400\n",
      "108/108 [==============================] - 2s 14ms/step - loss: 0.1319 - sparse_categorical_accuracy: 0.9537 - val_loss: 0.3486 - val_sparse_categorical_accuracy: 0.8830\n",
      "Epoch 337/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1315 - sparse_categorical_accuracy: 0.9540 - val_loss: 0.3136 - val_sparse_categorical_accuracy: 0.8960\n",
      "Epoch 338/400\n",
      "108/108 [==============================] - 1s 12ms/step - loss: 0.1222 - sparse_categorical_accuracy: 0.9589 - val_loss: 0.3160 - val_sparse_categorical_accuracy: 0.8930\n",
      "Epoch 339/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1229 - sparse_categorical_accuracy: 0.9574 - val_loss: 0.3663 - val_sparse_categorical_accuracy: 0.8812\n",
      "Epoch 340/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1229 - sparse_categorical_accuracy: 0.9581 - val_loss: 0.3313 - val_sparse_categorical_accuracy: 0.8924\n",
      "Epoch 341/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1321 - sparse_categorical_accuracy: 0.9540 - val_loss: 0.4166 - val_sparse_categorical_accuracy: 0.8674\n",
      "Epoch 342/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1253 - sparse_categorical_accuracy: 0.9569 - val_loss: 0.3680 - val_sparse_categorical_accuracy: 0.8868\n",
      "Epoch 343/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1222 - sparse_categorical_accuracy: 0.9583 - val_loss: 0.3278 - val_sparse_categorical_accuracy: 0.8926\n",
      "Epoch 344/400\n",
      "108/108 [==============================] - 2s 14ms/step - loss: 0.1238 - sparse_categorical_accuracy: 0.9572 - val_loss: 0.3134 - val_sparse_categorical_accuracy: 0.8948\n",
      "Epoch 345/400\n",
      "108/108 [==============================] - 1s 12ms/step - loss: 0.1268 - sparse_categorical_accuracy: 0.9567 - val_loss: 0.3500 - val_sparse_categorical_accuracy: 0.8876\n",
      "Epoch 346/400\n",
      "108/108 [==============================] - 1s 14ms/step - loss: 0.1207 - sparse_categorical_accuracy: 0.9591 - val_loss: 0.3703 - val_sparse_categorical_accuracy: 0.8812\n",
      "Epoch 347/400\n",
      "108/108 [==============================] - 2s 14ms/step - loss: 0.1487 - sparse_categorical_accuracy: 0.9504 - val_loss: 0.3242 - val_sparse_categorical_accuracy: 0.8930\n",
      "Epoch 348/400\n",
      "108/108 [==============================] - 2s 14ms/step - loss: 0.1172 - sparse_categorical_accuracy: 0.9597 - val_loss: 0.4517 - val_sparse_categorical_accuracy: 0.8658\n",
      "Epoch 349/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1206 - sparse_categorical_accuracy: 0.9583 - val_loss: 0.3300 - val_sparse_categorical_accuracy: 0.8940\n",
      "Epoch 350/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1159 - sparse_categorical_accuracy: 0.9604 - val_loss: 0.3280 - val_sparse_categorical_accuracy: 0.8926\n",
      "Epoch 351/400\n",
      "108/108 [==============================] - 1s 12ms/step - loss: 0.1139 - sparse_categorical_accuracy: 0.9612 - val_loss: 0.3279 - val_sparse_categorical_accuracy: 0.8946\n",
      "Epoch 352/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1236 - sparse_categorical_accuracy: 0.9575 - val_loss: 0.3204 - val_sparse_categorical_accuracy: 0.8958\n",
      "Epoch 353/400\n",
      "108/108 [==============================] - 1s 14ms/step - loss: 0.1195 - sparse_categorical_accuracy: 0.9591 - val_loss: 0.3123 - val_sparse_categorical_accuracy: 0.8960\n",
      "Epoch 354/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1110 - sparse_categorical_accuracy: 0.9624 - val_loss: 0.3915 - val_sparse_categorical_accuracy: 0.8786\n",
      "Epoch 355/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1229 - sparse_categorical_accuracy: 0.9568 - val_loss: 0.3452 - val_sparse_categorical_accuracy: 0.8882\n",
      "Epoch 356/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1123 - sparse_categorical_accuracy: 0.9623 - val_loss: 0.4276 - val_sparse_categorical_accuracy: 0.8764\n",
      "Epoch 357/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1218 - sparse_categorical_accuracy: 0.9589 - val_loss: 0.3225 - val_sparse_categorical_accuracy: 0.8948\n",
      "Epoch 358/400\n",
      "108/108 [==============================] - 2s 14ms/step - loss: 0.1206 - sparse_categorical_accuracy: 0.9582 - val_loss: 0.3613 - val_sparse_categorical_accuracy: 0.8804\n",
      "Epoch 359/400\n",
      "108/108 [==============================] - 1s 14ms/step - loss: 0.1138 - sparse_categorical_accuracy: 0.9608 - val_loss: 0.3558 - val_sparse_categorical_accuracy: 0.8850\n",
      "Epoch 360/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1110 - sparse_categorical_accuracy: 0.9629 - val_loss: 0.3429 - val_sparse_categorical_accuracy: 0.8886\n",
      "Epoch 361/400\n",
      "108/108 [==============================] - 1s 12ms/step - loss: 0.1157 - sparse_categorical_accuracy: 0.9603 - val_loss: 0.4614 - val_sparse_categorical_accuracy: 0.8686\n",
      "Epoch 362/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1190 - sparse_categorical_accuracy: 0.9597 - val_loss: 0.3292 - val_sparse_categorical_accuracy: 0.8932\n",
      "Epoch 363/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1122 - sparse_categorical_accuracy: 0.9617 - val_loss: 0.3780 - val_sparse_categorical_accuracy: 0.8824\n",
      "Epoch 364/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1127 - sparse_categorical_accuracy: 0.9617 - val_loss: 0.3796 - val_sparse_categorical_accuracy: 0.8800\n",
      "Epoch 365/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1064 - sparse_categorical_accuracy: 0.9636 - val_loss: 0.3462 - val_sparse_categorical_accuracy: 0.8896\n",
      "Epoch 366/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1100 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.4203 - val_sparse_categorical_accuracy: 0.8682\n",
      "Epoch 367/400\n",
      "108/108 [==============================] - 1s 14ms/step - loss: 0.1142 - sparse_categorical_accuracy: 0.9608 - val_loss: 0.3770 - val_sparse_categorical_accuracy: 0.8874\n",
      "Epoch 368/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1125 - sparse_categorical_accuracy: 0.9622 - val_loss: 0.3175 - val_sparse_categorical_accuracy: 0.8950\n",
      "Epoch 369/400\n",
      "108/108 [==============================] - 2s 15ms/step - loss: 0.1490 - sparse_categorical_accuracy: 0.9550 - val_loss: 0.3123 - val_sparse_categorical_accuracy: 0.8976\n",
      "Epoch 370/400\n",
      "108/108 [==============================] - 1s 14ms/step - loss: 0.1064 - sparse_categorical_accuracy: 0.9649 - val_loss: 0.3103 - val_sparse_categorical_accuracy: 0.9012\n",
      "Epoch 371/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1132 - sparse_categorical_accuracy: 0.9614 - val_loss: 0.4225 - val_sparse_categorical_accuracy: 0.8768\n",
      "Epoch 372/400\n",
      "108/108 [==============================] - 1s 12ms/step - loss: 0.1134 - sparse_categorical_accuracy: 0.9611 - val_loss: 0.3199 - val_sparse_categorical_accuracy: 0.8984\n",
      "Epoch 373/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1155 - sparse_categorical_accuracy: 0.9607 - val_loss: 0.3147 - val_sparse_categorical_accuracy: 0.8988\n",
      "Epoch 374/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1009 - sparse_categorical_accuracy: 0.9672 - val_loss: 0.3623 - val_sparse_categorical_accuracy: 0.8892\n",
      "Epoch 375/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1016 - sparse_categorical_accuracy: 0.9662 - val_loss: 0.4041 - val_sparse_categorical_accuracy: 0.8718\n",
      "Epoch 376/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1046 - sparse_categorical_accuracy: 0.9659 - val_loss: 0.3157 - val_sparse_categorical_accuracy: 0.8972\n",
      "Epoch 377/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.1093 - sparse_categorical_accuracy: 0.9622 - val_loss: 0.3590 - val_sparse_categorical_accuracy: 0.8904\n",
      "Epoch 378/400\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.0992 - sparse_categorical_accuracy: 0.9671 - val_loss: 0.3257 - val_sparse_categorical_accuracy: 0.8964\n",
      "Epoch 379/400\n",
      "108/108 [==============================] - 2s 14ms/step - loss: 0.1092 - sparse_categorical_accuracy: 0.9631 - val_loss: 0.3271 - val_sparse_categorical_accuracy: 0.8994\n",
      "Epoch 380/400\n",
      "108/108 [==============================] - 2s 15ms/step - loss: 0.1265 - sparse_categorical_accuracy: 0.9613 - val_loss: 0.3494 - val_sparse_categorical_accuracy: 0.8964\n",
      "Epoch 381/400\n",
      "108/108 [==============================] - 2s 14ms/step - loss: 0.1059 - sparse_categorical_accuracy: 0.9643 - val_loss: 0.3257 - val_sparse_categorical_accuracy: 0.8974\n",
      "Epoch 382/400\n",
      "108/108 [==============================] - 2s 15ms/step - loss: 0.0944 - sparse_categorical_accuracy: 0.9695 - val_loss: 0.3273 - val_sparse_categorical_accuracy: 0.8928\n",
      "Epoch 383/400\n",
      "108/108 [==============================] - 2s 16ms/step - loss: 0.0998 - sparse_categorical_accuracy: 0.9668 - val_loss: 0.3256 - val_sparse_categorical_accuracy: 0.8972\n",
      "Epoch 384/400\n",
      "108/108 [==============================] - 2s 20ms/step - loss: 0.1045 - sparse_categorical_accuracy: 0.9642 - val_loss: 0.3227 - val_sparse_categorical_accuracy: 0.8962\n",
      "Epoch 385/400\n",
      "108/108 [==============================] - 2s 17ms/step - loss: 0.0971 - sparse_categorical_accuracy: 0.9685 - val_loss: 0.3520 - val_sparse_categorical_accuracy: 0.8866\n",
      "Epoch 386/400\n",
      "108/108 [==============================] - 4s 34ms/step - loss: 0.1010 - sparse_categorical_accuracy: 0.9672 - val_loss: 0.3219 - val_sparse_categorical_accuracy: 0.9006\n",
      "Epoch 387/400\n",
      "108/108 [==============================] - 3s 24ms/step - loss: 0.0978 - sparse_categorical_accuracy: 0.9669 - val_loss: 0.3609 - val_sparse_categorical_accuracy: 0.8862\n",
      "Epoch 388/400\n",
      "108/108 [==============================] - 3s 26ms/step - loss: 0.1027 - sparse_categorical_accuracy: 0.9658 - val_loss: 0.3218 - val_sparse_categorical_accuracy: 0.8960\n",
      "Epoch 389/400\n",
      "108/108 [==============================] - 3s 26ms/step - loss: 0.0982 - sparse_categorical_accuracy: 0.9671 - val_loss: 0.4060 - val_sparse_categorical_accuracy: 0.8808\n",
      "Epoch 390/400\n",
      "108/108 [==============================] - 2s 23ms/step - loss: 0.1091 - sparse_categorical_accuracy: 0.9621 - val_loss: 0.3247 - val_sparse_categorical_accuracy: 0.8960\n",
      "Epoch 391/400\n",
      "108/108 [==============================] - 3s 23ms/step - loss: 0.1063 - sparse_categorical_accuracy: 0.9652 - val_loss: 0.3451 - val_sparse_categorical_accuracy: 0.8932\n",
      "Epoch 392/400\n",
      "108/108 [==============================] - 2s 20ms/step - loss: 0.0978 - sparse_categorical_accuracy: 0.9672 - val_loss: 0.3448 - val_sparse_categorical_accuracy: 0.8934\n",
      "Epoch 393/400\n",
      "108/108 [==============================] - 2s 16ms/step - loss: 0.0970 - sparse_categorical_accuracy: 0.9677 - val_loss: 0.3326 - val_sparse_categorical_accuracy: 0.8928\n",
      "Epoch 394/400\n",
      "108/108 [==============================] - 2s 19ms/step - loss: 0.0951 - sparse_categorical_accuracy: 0.9686 - val_loss: 0.3630 - val_sparse_categorical_accuracy: 0.8842\n",
      "Epoch 395/400\n",
      "108/108 [==============================] - 2s 15ms/step - loss: 0.0953 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.4827 - val_sparse_categorical_accuracy: 0.8618\n",
      "Epoch 396/400\n",
      "108/108 [==============================] - 2s 14ms/step - loss: 0.1216 - sparse_categorical_accuracy: 0.9596 - val_loss: 0.3247 - val_sparse_categorical_accuracy: 0.8990\n",
      "Epoch 397/400\n",
      "108/108 [==============================] - 1s 12ms/step - loss: 0.0916 - sparse_categorical_accuracy: 0.9703 - val_loss: 0.3410 - val_sparse_categorical_accuracy: 0.8938\n",
      "Epoch 398/400\n",
      "108/108 [==============================] - 2s 17ms/step - loss: 0.0907 - sparse_categorical_accuracy: 0.9705 - val_loss: 0.4717 - val_sparse_categorical_accuracy: 0.8696\n",
      "Epoch 399/400\n",
      "108/108 [==============================] - 2s 21ms/step - loss: 0.0948 - sparse_categorical_accuracy: 0.9693 - val_loss: 0.3274 - val_sparse_categorical_accuracy: 0.8970\n",
      "Epoch 400/400\n",
      "108/108 [==============================] - 2s 16ms/step - loss: 0.0965 - sparse_categorical_accuracy: 0.9671 - val_loss: 0.3384 - val_sparse_categorical_accuracy: 0.8926\n"
     ]
    }
   ],
   "source": [
    "checkpoint = keras.callbacks.ModelCheckpoint(\"my_mnist_model.h5\", save_best_only=True)\n",
    "early_stopping = keras.callbacks.EarlyStopping(patience=200,restore_best_weights=True)\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir=\"./my_logs\")\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=400,batch_size=512,\n",
    "                    validation_data=(X_valid, y_valid),callbacks=[checkpoint, early_stopping,tensorboard])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af432591",
   "metadata": {},
   "source": [
    "Here I directly passed the `validation_data` since we already splitted our dataset. However, we can also use `validation_split` argument to use a ratio of our training data for validation. For instance, validation_split=0.1 tells Keras to use the last 10% of the data for validation. Note: It doesn't shuffle the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199bdfeb",
   "metadata": {},
   "source": [
    "Let's also evaluate model performance on test set. Documentation for `evaluate()` [link](https://www.tensorflow.org/api_docs/python/tf/keras/Model#evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0920df27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3962 - sparse_categorical_accuracy: 0.8831\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.39618635177612305, 0.8830999732017517]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2c2234",
   "metadata": {},
   "source": [
    "Let's look at how performance changed during the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b10a890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 11888), started 3 days, 7:27:55 ago. (Use '!kill 11888' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-946c30eceb1cd960\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-946c30eceb1cd960\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./my_logs --port=6006"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47fef02",
   "metadata": {},
   "source": [
    "Even if I have used tensorboard, let's also show our classical performance plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12414cd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe091488",
   "metadata": {},
   "source": [
    "Okay one thing that I didn't show before is using the `predict()` function. Firstly, I will use predict function on one instance then show that instance with `imshow()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80f99d69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "        0.999]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X_test[:1] # getting the first row\n",
    "y_proba = model.predict(X_new)\n",
    "y_proba.round(3) # To get rid of scientific notation, I will use round() function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d99655",
   "metadata": {},
   "source": [
    "Now the model provided us a sparse array which contains the probabilities of each class. I will convert these values to one-hot vector labels. There are a couple of ways of doing that, the one I generally is using `keras.utils.to_categorical() ` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f232dc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.to_categorical(np.argmax(y_proba.round(3), axis=1), 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7159e6d7",
   "metadata": {},
   "source": [
    "The algorithm assign the class to ankle boat which the 10th class in our target. Let's use `imshow()` function to show the instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e19cc45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "for index, image in enumerate(X_new):\n",
    "    plt.imshow(image, cmap=\"binary\", interpolation=\"nearest\")\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f330dae5",
   "metadata": {},
   "source": [
    "Instead of one-hot encoding we could also directly see the class by using the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ec8a3639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9], dtype=int64)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.argmax(model.predict(X_new), axis=-1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9ff2fa",
   "metadata": {},
   "source": [
    "# Functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4034a13",
   "metadata": {},
   "source": [
    "Okay now let's implement Wide and Deep Model architecture. This one was a very interesting architecture for me when I first read about. I am actually a molecular biology student who is interested in neuroscience, therefore, I have a genuine interest for network architectures. I was thinking of using this neural network with regression (It was originally used for recommender system) but I thought I can also use it with Fashion MNIST, let's start.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92470a98",
   "metadata": {},
   "source": [
    "One of the general idea behind this model is to have different inputs. We will connect some of our input directly to output layers. You can find more about the architecture in the paper. By the way, the paper is really easy to read, I recommend everybody to read it. [The paper](https://arxiv.org/abs/1606.07792)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8ea317",
   "metadata": {},
   "source": [
    "Additional Note 2: The name Functional API actually comes from the thing that we used the layers here like functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7435c89c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.8170 - sparse_categorical_accuracy: 0.7416 - val_loss: 0.6039 - val_sparse_categorical_accuracy: 0.8046\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.5671 - sparse_categorical_accuracy: 0.8124 - val_loss: 0.5189 - val_sparse_categorical_accuracy: 0.8298\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.5074 - sparse_categorical_accuracy: 0.8289 - val_loss: 0.4812 - val_sparse_categorical_accuracy: 0.8396\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4735 - sparse_categorical_accuracy: 0.8386 - val_loss: 0.4523 - val_sparse_categorical_accuracy: 0.8518\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.4515 - sparse_categorical_accuracy: 0.8449 - val_loss: 0.4331 - val_sparse_categorical_accuracy: 0.8594\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4332 - sparse_categorical_accuracy: 0.8488 - val_loss: 0.4195 - val_sparse_categorical_accuracy: 0.8610\n",
      "Epoch 7/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4197 - sparse_categorical_accuracy: 0.8543 - val_loss: 0.4188 - val_sparse_categorical_accuracy: 0.8534\n",
      "Epoch 8/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4079 - sparse_categorical_accuracy: 0.8585 - val_loss: 0.4002 - val_sparse_categorical_accuracy: 0.8668\n",
      "Epoch 9/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3971 - sparse_categorical_accuracy: 0.8621 - val_loss: 0.3925 - val_sparse_categorical_accuracy: 0.8670\n",
      "Epoch 10/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3877 - sparse_categorical_accuracy: 0.8659 - val_loss: 0.3937 - val_sparse_categorical_accuracy: 0.8634\n",
      "Epoch 11/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3791 - sparse_categorical_accuracy: 0.8684 - val_loss: 0.3829 - val_sparse_categorical_accuracy: 0.8692\n",
      "Epoch 12/100\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.3711 - sparse_categorical_accuracy: 0.8706 - val_loss: 0.3798 - val_sparse_categorical_accuracy: 0.8694\n",
      "Epoch 13/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3634 - sparse_categorical_accuracy: 0.8733 - val_loss: 0.3677 - val_sparse_categorical_accuracy: 0.8728\n",
      "Epoch 14/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3577 - sparse_categorical_accuracy: 0.8758 - val_loss: 0.3715 - val_sparse_categorical_accuracy: 0.8692\n",
      "Epoch 15/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3504 - sparse_categorical_accuracy: 0.8781 - val_loss: 0.3623 - val_sparse_categorical_accuracy: 0.8776\n",
      "Epoch 16/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3448 - sparse_categorical_accuracy: 0.8796 - val_loss: 0.3558 - val_sparse_categorical_accuracy: 0.8748\n",
      "Epoch 17/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3385 - sparse_categorical_accuracy: 0.8818 - val_loss: 0.3490 - val_sparse_categorical_accuracy: 0.8760\n",
      "Epoch 18/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3319 - sparse_categorical_accuracy: 0.8834 - val_loss: 0.3684 - val_sparse_categorical_accuracy: 0.8702\n",
      "Epoch 19/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3273 - sparse_categorical_accuracy: 0.8844 - val_loss: 0.3475 - val_sparse_categorical_accuracy: 0.8766\n",
      "Epoch 20/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3219 - sparse_categorical_accuracy: 0.8863 - val_loss: 0.3382 - val_sparse_categorical_accuracy: 0.8822\n",
      "Epoch 21/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3156 - sparse_categorical_accuracy: 0.8891 - val_loss: 0.3376 - val_sparse_categorical_accuracy: 0.8820\n",
      "Epoch 22/100\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.3110 - sparse_categorical_accuracy: 0.8897 - val_loss: 0.3420 - val_sparse_categorical_accuracy: 0.8804\n",
      "Epoch 23/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3068 - sparse_categorical_accuracy: 0.8914 - val_loss: 0.3348 - val_sparse_categorical_accuracy: 0.8834\n",
      "Epoch 24/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3019 - sparse_categorical_accuracy: 0.8925 - val_loss: 0.3284 - val_sparse_categorical_accuracy: 0.8852\n",
      "Epoch 25/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2971 - sparse_categorical_accuracy: 0.8948 - val_loss: 0.3258 - val_sparse_categorical_accuracy: 0.8864\n",
      "Epoch 26/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2924 - sparse_categorical_accuracy: 0.8958 - val_loss: 0.3510 - val_sparse_categorical_accuracy: 0.8736\n",
      "Epoch 27/100\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.2884 - sparse_categorical_accuracy: 0.8972 - val_loss: 0.3264 - val_sparse_categorical_accuracy: 0.8844\n",
      "Epoch 28/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2844 - sparse_categorical_accuracy: 0.8981 - val_loss: 0.3246 - val_sparse_categorical_accuracy: 0.8874\n",
      "Epoch 29/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2802 - sparse_categorical_accuracy: 0.8997 - val_loss: 0.3241 - val_sparse_categorical_accuracy: 0.8858\n",
      "Epoch 30/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2762 - sparse_categorical_accuracy: 0.9014 - val_loss: 0.3254 - val_sparse_categorical_accuracy: 0.8872\n",
      "Epoch 31/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2720 - sparse_categorical_accuracy: 0.9030 - val_loss: 0.3343 - val_sparse_categorical_accuracy: 0.8820\n",
      "Epoch 32/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2681 - sparse_categorical_accuracy: 0.9031 - val_loss: 0.3383 - val_sparse_categorical_accuracy: 0.8808\n",
      "Epoch 33/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2653 - sparse_categorical_accuracy: 0.9055 - val_loss: 0.3305 - val_sparse_categorical_accuracy: 0.8858\n",
      "Epoch 34/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2606 - sparse_categorical_accuracy: 0.9067 - val_loss: 0.3255 - val_sparse_categorical_accuracy: 0.8840\n",
      "Epoch 35/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2578 - sparse_categorical_accuracy: 0.9076 - val_loss: 0.3183 - val_sparse_categorical_accuracy: 0.8882\n",
      "Epoch 36/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2546 - sparse_categorical_accuracy: 0.9094 - val_loss: 0.3072 - val_sparse_categorical_accuracy: 0.8916\n",
      "Epoch 37/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2510 - sparse_categorical_accuracy: 0.9096 - val_loss: 0.3180 - val_sparse_categorical_accuracy: 0.8868\n",
      "Epoch 38/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2476 - sparse_categorical_accuracy: 0.9114 - val_loss: 0.3112 - val_sparse_categorical_accuracy: 0.8922\n",
      "Epoch 39/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2450 - sparse_categorical_accuracy: 0.9123 - val_loss: 0.3284 - val_sparse_categorical_accuracy: 0.8856\n",
      "Epoch 40/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2426 - sparse_categorical_accuracy: 0.9137 - val_loss: 0.3077 - val_sparse_categorical_accuracy: 0.8932\n",
      "Epoch 41/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2392 - sparse_categorical_accuracy: 0.9146 - val_loss: 0.3128 - val_sparse_categorical_accuracy: 0.8920\n",
      "Epoch 42/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2358 - sparse_categorical_accuracy: 0.9157 - val_loss: 0.3166 - val_sparse_categorical_accuracy: 0.8878\n",
      "Epoch 43/100\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.2332 - sparse_categorical_accuracy: 0.9165 - val_loss: 0.3134 - val_sparse_categorical_accuracy: 0.8876\n",
      "Epoch 44/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2307 - sparse_categorical_accuracy: 0.9177 - val_loss: 0.3272 - val_sparse_categorical_accuracy: 0.8826\n",
      "Epoch 45/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2286 - sparse_categorical_accuracy: 0.9182 - val_loss: 0.3062 - val_sparse_categorical_accuracy: 0.8960\n",
      "Epoch 46/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2257 - sparse_categorical_accuracy: 0.9193 - val_loss: 0.3066 - val_sparse_categorical_accuracy: 0.8942\n",
      "Epoch 47/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2213 - sparse_categorical_accuracy: 0.9216 - val_loss: 0.3179 - val_sparse_categorical_accuracy: 0.8878\n",
      "Epoch 48/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2191 - sparse_categorical_accuracy: 0.9215 - val_loss: 0.3102 - val_sparse_categorical_accuracy: 0.8956\n",
      "Epoch 49/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2171 - sparse_categorical_accuracy: 0.9221 - val_loss: 0.3283 - val_sparse_categorical_accuracy: 0.8868\n",
      "Epoch 50/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2130 - sparse_categorical_accuracy: 0.9228 - val_loss: 0.3102 - val_sparse_categorical_accuracy: 0.8902\n",
      "Epoch 51/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2124 - sparse_categorical_accuracy: 0.9241 - val_loss: 0.3062 - val_sparse_categorical_accuracy: 0.8940\n",
      "Epoch 52/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2095 - sparse_categorical_accuracy: 0.9252 - val_loss: 0.3174 - val_sparse_categorical_accuracy: 0.8902\n",
      "Epoch 53/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2079 - sparse_categorical_accuracy: 0.9246 - val_loss: 0.3053 - val_sparse_categorical_accuracy: 0.8976\n",
      "Epoch 54/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2048 - sparse_categorical_accuracy: 0.9268 - val_loss: 0.3087 - val_sparse_categorical_accuracy: 0.8912\n",
      "Epoch 55/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2033 - sparse_categorical_accuracy: 0.9277 - val_loss: 0.3128 - val_sparse_categorical_accuracy: 0.8930\n",
      "Epoch 56/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1993 - sparse_categorical_accuracy: 0.9280 - val_loss: 0.3092 - val_sparse_categorical_accuracy: 0.8946\n",
      "Epoch 57/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1976 - sparse_categorical_accuracy: 0.9293 - val_loss: 0.3048 - val_sparse_categorical_accuracy: 0.8952\n",
      "Epoch 58/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1958 - sparse_categorical_accuracy: 0.9295 - val_loss: 0.3098 - val_sparse_categorical_accuracy: 0.8930\n",
      "Epoch 59/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1936 - sparse_categorical_accuracy: 0.9307 - val_loss: 0.3288 - val_sparse_categorical_accuracy: 0.89023s - loss: 0.1892 \n",
      "Epoch 60/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1911 - sparse_categorical_accuracy: 0.9319 - val_loss: 0.3041 - val_sparse_categorical_accuracy: 0.8988 - sparse_categorical_accuracy: - ETA: 0s - loss: 0.1922 - sparse_categorical_accuracy: 0.931 - ETA: 0s - loss: 0.1925 - sparse_categorica\n",
      "Epoch 61/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1891 - sparse_categorical_accuracy: 0.9322 - val_loss: 0.3089 - val_sparse_categorical_accuracy: 0.8958\n",
      "Epoch 62/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1866 - sparse_categorical_accuracy: 0.9332 - val_loss: 0.3248 - val_sparse_categorical_accuracy: 0.8876\n",
      "Epoch 63/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1852 - sparse_categorical_accuracy: 0.9337 - val_loss: 0.3343 - val_sparse_categorical_accuracy: 0.8846\n",
      "Epoch 64/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1828 - sparse_categorical_accuracy: 0.9349 - val_loss: 0.3289 - val_sparse_categorical_accuracy: 0.8904\n",
      "Epoch 65/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1806 - sparse_categorical_accuracy: 0.9354 - val_loss: 0.3144 - val_sparse_categorical_accuracy: 0.8938\n",
      "Epoch 66/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1778 - sparse_categorical_accuracy: 0.9353 - val_loss: 0.3298 - val_sparse_categorical_accuracy: 0.8862\n",
      "Epoch 67/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1768 - sparse_categorical_accuracy: 0.9367 - val_loss: 0.3232 - val_sparse_categorical_accuracy: 0.8944\n",
      "Epoch 68/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.1745 - sparse_categorical_accuracy: 0.9376 - val_loss: 0.3167 - val_sparse_categorical_accuracy: 0.8976s - loss: 0.1743 - sparse_categorical_accuracy: 0.\n",
      "Epoch 69/100\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.1717 - sparse_categorical_accuracy: 0.9388 - val_loss: 0.3282 - val_sparse_categorical_accuracy: 0.8902\n",
      "Epoch 70/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.1706 - sparse_categorical_accuracy: 0.9391 - val_loss: 0.3290 - val_sparse_categorical_accuracy: 0.8858\n",
      "Epoch 71/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1693 - sparse_categorical_accuracy: 0.9398 - val_loss: 0.3245 - val_sparse_categorical_accuracy: 0.8946\n",
      "Epoch 72/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1665 - sparse_categorical_accuracy: 0.9409 - val_loss: 0.3278 - val_sparse_categorical_accuracy: 0.8930\n",
      "Epoch 73/100\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.1632 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.3388 - val_sparse_categorical_accuracy: 0.8874\n",
      "Epoch 74/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1637 - sparse_categorical_accuracy: 0.9417 - val_loss: 0.3233 - val_sparse_categorical_accuracy: 0.8948\n",
      "Epoch 75/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.1607 - sparse_categorical_accuracy: 0.9429 - val_loss: 0.3182 - val_sparse_categorical_accuracy: 0.8944\n",
      "Epoch 76/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1595 - sparse_categorical_accuracy: 0.9425 - val_loss: 0.3210 - val_sparse_categorical_accuracy: 0.8940\n",
      "Epoch 77/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1580 - sparse_categorical_accuracy: 0.9431 - val_loss: 0.3220 - val_sparse_categorical_accuracy: 0.8948\n",
      "Epoch 78/100\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.1570 - sparse_categorical_accuracy: 0.9442 - val_loss: 0.3485 - val_sparse_categorical_accuracy: 0.8882orical_a - ETA: 2s -\n",
      "Epoch 79/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.1547 - sparse_categorical_accuracy: 0.9449 - val_loss: 0.3355 - val_sparse_categorical_accuracy: 0.8960\n",
      "Epoch 80/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1523 - sparse_categorical_accuracy: 0.9462 - val_loss: 0.3359 - val_sparse_categorical_accuracy: 0.8932\n",
      "Epoch 81/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1508 - sparse_categorical_accuracy: 0.9462 - val_loss: 0.3341 - val_sparse_categorical_accuracy: 0.8952\n",
      "Epoch 82/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.1495 - sparse_categorical_accuracy: 0.9479 - val_loss: 0.3281 - val_sparse_categorical_accuracy: 0.8954 1s - loss: 0.1481 - sparse_categorical_accuracy: 0.94 - ETA: 1s - loss: 0.1475 - sparse_categoric - ETA: 0s - loss: 0.1490 - sparse_categorical_\n",
      "Epoch 83/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1479 - sparse_categorical_accuracy: 0.9479 - val_loss: 0.3244 - val_sparse_categorical_accuracy: 0.8980\n",
      "Epoch 84/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1471 - sparse_categorical_accuracy: 0.9485 - val_loss: 0.3589 - val_sparse_categorical_accuracy: 0.8910\n",
      "Epoch 85/100\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.1442 - sparse_categorical_accuracy: 0.9482 - val_loss: 0.3264 - val_sparse_categorical_accuracy: 0.8954\n",
      "Epoch 86/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1425 - sparse_categorical_accuracy: 0.9499 - val_loss: 0.3417 - val_sparse_categorical_accuracy: 0.8934\n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.1414 - sparse_categorical_accuracy: 0.9499 - val_loss: 0.3508 - val_sparse_categorical_accuracy: 0.8924\n",
      "Epoch 88/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1386 - sparse_categorical_accuracy: 0.9519 - val_loss: 0.3497 - val_sparse_categorical_accuracy: 0.8914\n",
      "Epoch 89/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.1371 - sparse_categorical_accuracy: 0.9513 - val_loss: 0.3571 - val_sparse_categorical_accuracy: 0.8880\n",
      "Epoch 90/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1362 - sparse_categorical_accuracy: 0.9522 - val_loss: 0.3442 - val_sparse_categorical_accuracy: 0.8956\n",
      "Epoch 91/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.1353 - sparse_categorical_accuracy: 0.9510 - val_loss: 0.3380 - val_sparse_categorical_accuracy: 0.8966\n",
      "Epoch 92/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.1341 - sparse_categorical_accuracy: 0.9525 - val_loss: 0.3478 - val_sparse_categorical_accuracy: 0.8920\n",
      "Epoch 93/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.1328 - sparse_categorical_accuracy: 0.9525 - val_loss: 0.3636 - val_sparse_categorical_accuracy: 0.8908\n",
      "Epoch 94/100\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.1298 - sparse_categorical_accuracy: 0.9533 - val_loss: 0.3608 - val_sparse_categorical_accuracy: 0.8878\n",
      "Epoch 95/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1291 - sparse_categorical_accuracy: 0.9546 - val_loss: 0.3515 - val_sparse_categorical_accuracy: 0.8930\n",
      "Epoch 96/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1278 - sparse_categorical_accuracy: 0.9556 - val_loss: 0.3664 - val_sparse_categorical_accuracy: 0.8896\n",
      "Epoch 97/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1270 - sparse_categorical_accuracy: 0.9548 - val_loss: 0.3611 - val_sparse_categorical_accuracy: 0.8890\n",
      "Epoch 98/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1246 - sparse_categorical_accuracy: 0.9564 - val_loss: 0.3595 - val_sparse_categorical_accuracy: 0.8908\n",
      "Epoch 99/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1241 - sparse_categorical_accuracy: 0.9564 - val_loss: 0.3426 - val_sparse_categorical_accuracy: 0.8966\n",
      "Epoch 100/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1217 - sparse_categorical_accuracy: 0.9572 - val_loss: 0.3951 - val_sparse_categorical_accuracy: 0.8856\n"
     ]
    }
   ],
   "source": [
    "input_layer = keras.layers.Input(shape=[28,28])\n",
    "flatten1=keras.layers.Flatten(input_shape=[28, 28])(input_layer)\n",
    "hidden_layer1 = keras.layers.Dense(120, activation=\"relu\")(flatten1)\n",
    "hidden_layer2 = keras.layers.Dense(60, activation=\"relu\")(hidden_layer1)\n",
    "\n",
    "concatenated_layer = keras.layers.concatenate([flatten1, hidden_layer2])\n",
    "output = keras.layers.Dense(10,activation=\"softmax\")(concatenated_layer)\n",
    "model = keras.models.Model(inputs=[input_layer], outputs=[output])\n",
    "\n",
    "model.compile(loss=keras.losses.sparse_categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.SGD(),\n",
    "              metrics=[keras.metrics.sparse_categorical_accuracy])\n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=100,validation_data=(X_valid, y_valid))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bea0a7",
   "metadata": {},
   "source": [
    "Let's use `evaluate()` function to look at the model's performance on validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e81ac800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 993us/step - loss: 0.3951 - sparse_categorical_accuracy: 0.8856\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398254d0",
   "metadata": {},
   "source": [
    "Okay now we have done an example using functional API, let's now impelement a similar structure of Wide and Deep Neural Network. To do that I will split my training and validation instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63d9c676",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 1:]\n",
    "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7848e456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 5, 28)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_A.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5164195",
   "metadata": {},
   "source": [
    "Here I will firstly code a callback which will stop our training if the validation accuracy exceeds %90."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ec51cbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class terminate(tf.keras.callbacks.Callback):\n",
    "     def on_epoch_end(self, epoch, logs={}):\n",
    "        if logs.get('val_sparse_categorical_accuracy') is not None and logs.get('val_sparse_categorical_accuracy') > 0.90:\n",
    "            print(\"\\n \\n Validation accuracy is reached termination in process...\")\n",
    "            self.model.stop_training = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "638e5206",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_wide = keras.layers.Input(shape=X_train_A.shape[1:], name=\"wide_input\")\n",
    "input_deep = keras.layers.Input(shape=X_train_B.shape[1:], name=\"deep_input\")\n",
    "\n",
    "flatten_deep=keras.layers.Flatten(input_shape=[26, 28])(input_deep)\n",
    "hidden_layer1 = keras.layers.Dense(128, activation=\"relu\")(flatten_deep)\n",
    "hidden_layer2 = keras.layers.Dense(256, activation=\"relu\")(hidden_layer1)\n",
    "hidden_layer3 = keras.layers.Dense(512, activation=\"relu\")(hidden_layer2)\n",
    "\n",
    "flatten_wide=keras.layers.Flatten(input_shape=[5, 28])(input_wide)\n",
    "concat = keras.layers.concatenate([flatten_wide, hidden_layer3])\n",
    "\n",
    "output = keras.layers.Dense(10, activation=\"softmax\", name=\"output\")(concat)\n",
    "\n",
    "model = keras.models.Model(inputs=[input_wide, input_deep], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "60ee9674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.1641 - sparse_categorical_accuracy: 0.9400 - val_loss: 0.3092 - val_sparse_categorical_accuracy: 0.8944\n",
      "Epoch 2/50\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1626 - sparse_categorical_accuracy: 0.9417 - val_loss: 0.3012 - val_sparse_categorical_accuracy: 0.8972\n",
      "Epoch 3/50\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1602 - sparse_categorical_accuracy: 0.9413 - val_loss: 0.3510 - val_sparse_categorical_accuracy: 0.8792\n",
      "Epoch 4/50\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1575 - sparse_categorical_accuracy: 0.9423 - val_loss: 0.3182 - val_sparse_categorical_accuracy: 0.8944\n",
      "Epoch 5/50\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1555 - sparse_categorical_accuracy: 0.9437 - val_loss: 0.3287 - val_sparse_categorical_accuracy: 0.8900\n",
      "Epoch 6/50\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.1536 - sparse_categorical_accuracy: 0.9441 - val_loss: 0.3415 - val_sparse_categorical_accuracy: 0.8914\n",
      "Epoch 7/50\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1508 - sparse_categorical_accuracy: 0.9448 - val_loss: 0.3261 - val_sparse_categorical_accuracy: 0.8914\n",
      "Epoch 8/50\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1481 - sparse_categorical_accuracy: 0.9459 - val_loss: 0.3376 - val_sparse_categorical_accuracy: 0.8906\n",
      "Epoch 9/50\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1452 - sparse_categorical_accuracy: 0.9476 - val_loss: 0.3234 - val_sparse_categorical_accuracy: 0.8958\n",
      "Epoch 10/50\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1440 - sparse_categorical_accuracy: 0.9474 - val_loss: 0.3116 - val_sparse_categorical_accuracy: 0.8948\n",
      "Epoch 11/50\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1413 - sparse_categorical_accuracy: 0.9486 - val_loss: 0.3410 - val_sparse_categorical_accuracy: 0.8922\n",
      "Epoch 12/50\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1386 - sparse_categorical_accuracy: 0.9499 - val_loss: 0.3211 - val_sparse_categorical_accuracy: 0.8952\n",
      "Epoch 13/50\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1355 - sparse_categorical_accuracy: 0.9497 - val_loss: 0.3268 - val_sparse_categorical_accuracy: 0.8946\n",
      "Epoch 14/50\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1324 - sparse_categorical_accuracy: 0.9522 - val_loss: 0.3474 - val_sparse_categorical_accuracy: 0.8882\n",
      "Epoch 15/50\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1311 - sparse_categorical_accuracy: 0.9515 - val_loss: 0.3338 - val_sparse_categorical_accuracy: 0.8936\n",
      "Epoch 16/50\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1291 - sparse_categorical_accuracy: 0.9534 - val_loss: 0.3542 - val_sparse_categorical_accuracy: 0.8890\n",
      "Epoch 17/50\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1274 - sparse_categorical_accuracy: 0.9535 - val_loss: 0.3409 - val_sparse_categorical_accuracy: 0.8930\n",
      "Epoch 18/50\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1252 - sparse_categorical_accuracy: 0.9544 - val_loss: 0.3675 - val_sparse_categorical_accuracy: 0.8872\n",
      "Epoch 19/50\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1225 - sparse_categorical_accuracy: 0.9551 - val_loss: 0.3519 - val_sparse_categorical_accuracy: 0.8958\n",
      "Epoch 20/50\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1219 - sparse_categorical_accuracy: 0.9568 - val_loss: 0.3628 - val_sparse_categorical_accuracy: 0.8868\n",
      "Epoch 21/50\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1200 - sparse_categorical_accuracy: 0.9567 - val_loss: 0.3549 - val_sparse_categorical_accuracy: 0.8896\n",
      "Epoch 22/50\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.1167 - sparse_categorical_accuracy: 0.9575 - val_loss: 0.3994 - val_sparse_categorical_accuracy: 0.8806\n",
      "Epoch 23/50\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1147 - sparse_categorical_accuracy: 0.9575 - val_loss: 0.3606 - val_sparse_categorical_accuracy: 0.8926\n",
      "Epoch 24/50\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1112 - sparse_categorical_accuracy: 0.9605 - val_loss: 0.3725 - val_sparse_categorical_accuracy: 0.8906\n",
      "Epoch 25/50\n",
      "1699/1719 [============================>.] - ETA: 0s - loss: 0.1117 - sparse_categorical_accuracy: 0.9588\n",
      " \n",
      " Validation accuracy is reached termination in process...\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.1116 - sparse_categorical_accuracy: 0.9588 - val_loss: 0.3426 - val_sparse_categorical_accuracy: 0.9004\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=keras.losses.sparse_categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.SGD(),# default learning_rate is 0.01\n",
    "              metrics=[keras.metrics.sparse_categorical_accuracy])\n",
    "\n",
    "callbacks = terminate()\n",
    "history = model.fit((X_train_A, X_train_B), y_train, epochs=50,validation_data=((X_valid_A, X_valid_B), y_valid), callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "51147f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step - loss: 0.3426 - sparse_categorical_accuracy: 0.9004\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.34263426065444946, 0.9003999829292297]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate((X_valid_A, X_valid_B), y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e970e0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0554ab",
   "metadata": {},
   "source": [
    "## MNIST NUMBERS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6f6139",
   "metadata": {},
   "source": [
    "Let's also implement one model one MNIST Number dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23c1afa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "648b6d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_train = X_train_full[:5000] / 255., X_train_full[5000:] / 255.\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "X_test = X_test / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "febb4c5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1e4440598b0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[13], cmap=\"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a976adf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(256, activation=\"relu\"),\n",
    "    keras.layers.Dense(128, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f7f28a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=3e-1),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3354405",
   "metadata": {},
   "outputs": [],
   "source": [
    "class terminate(tf.keras.callbacks.Callback):\n",
    "     def on_epoch_end(self, epoch, logs={}):\n",
    "        if logs.get('val_accuracy') is not None and logs.get('val_accuracy') > 0.9860:\n",
    "            print(\"\\n \\n Validation accuracy is reached termination in process...!\")\n",
    "            self.model.stop_training = True \n",
    "callbacks = terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57c31ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1692/1719 [============================>.] - ETA: 0s - loss: 2.2061e-05 - accuracy: 1.0000\n",
      " \n",
      " Validation accuracy is reached termination in process...!\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 2.1952e-05 - accuracy: 1.0000 - val_loss: 0.1032 - val_accuracy: 0.9860\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=100,\n",
    "                    validation_data=(X_valid, y_valid),callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0cbece",
   "metadata": {},
   "source": [
    "## Time to deal with Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117253f4",
   "metadata": {},
   "source": [
    "Now I will deal with some regression problems. Actually I don't like doing regression stuff with neural networks but I want to do some practice on boston dataset and the covid dataset I previously used in my machine learning repository."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5921de22",
   "metadata": {},
   "source": [
    "### Boston Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938de3ac",
   "metadata": {},
   "source": [
    "Let's load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3b7b0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_valid, y_valid)=tf.keras.datasets.boston_housing.load_data(\n",
    "      path=\"boston_housing.npz\", test_split=0.3, seed=85)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad99fef",
   "metadata": {},
   "source": [
    "Let's scale our predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a7ddc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(x_train)\n",
    "X_valid = scaler.transform(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e3ba4980",
   "metadata": {},
   "outputs": [],
   "source": [
    "class terminate(tf.keras.callbacks.Callback):\n",
    "     def on_epoch_end(self, epoch, logs={}):\n",
    "        if logs.get('val_loss') is not None and logs.get('val_loss') < 10:\n",
    "            print(\"\\n \\n Validation accuracy is reached termination in process...!\")\n",
    "            self.model.stop_training = True \n",
    "callbacks = terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b92f863b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 526.5979 - val_loss: 420.3430\n",
      "Epoch 2/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 206.0028 - val_loss: 67.3629\n",
      "Epoch 3/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 41.6832 - val_loss: 37.8082\n",
      "Epoch 4/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 28.6967 - val_loss: 30.3983\n",
      "Epoch 5/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 24.1727 - val_loss: 29.5884\n",
      "Epoch 6/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 22.2696 - val_loss: 25.2386\n",
      "Epoch 7/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 19.9773 - val_loss: 29.8627\n",
      "Epoch 8/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 19.4918 - val_loss: 27.5354\n",
      "Epoch 9/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 18.3724 - val_loss: 22.4319\n",
      "Epoch 10/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 16.7466 - val_loss: 20.1890\n",
      "Epoch 11/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 15.5518 - val_loss: 19.6111\n",
      "Epoch 12/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 14.6997 - val_loss: 19.7267\n",
      "Epoch 13/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 14.7976 - val_loss: 20.5440\n",
      "Epoch 14/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 14.0425 - val_loss: 19.7330\n",
      "Epoch 15/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 13.8641 - val_loss: 19.7725\n",
      "Epoch 16/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 13.4125 - val_loss: 18.2403\n",
      "Epoch 17/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 13.2911 - val_loss: 21.0830\n",
      "Epoch 18/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 13.1599 - val_loss: 16.2044\n",
      "Epoch 19/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 12.5080 - val_loss: 19.4986\n",
      "Epoch 20/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 12.2597 - val_loss: 17.9444\n",
      "Epoch 21/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 11.7509 - val_loss: 16.7051\n",
      "Epoch 22/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 11.2144 - val_loss: 17.9967\n",
      "Epoch 23/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 11.8700 - val_loss: 14.7377\n",
      "Epoch 24/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 11.2151 - val_loss: 15.3629\n",
      "Epoch 25/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 10.7543 - val_loss: 16.8419\n",
      "Epoch 26/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 10.7375 - val_loss: 17.2152\n",
      "Epoch 27/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 11.2779 - val_loss: 14.3920\n",
      "Epoch 28/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 10.1503 - val_loss: 20.9171\n",
      "Epoch 29/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 10.9170 - val_loss: 18.7331\n",
      "Epoch 30/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 10.8464 - val_loss: 14.0281\n",
      "Epoch 31/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 9.9067 - val_loss: 99.2260\n",
      "Epoch 32/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 18.7452 - val_loss: 15.8849\n",
      "Epoch 33/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 10.0781 - val_loss: 16.5015\n",
      "Epoch 34/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 10.5450 - val_loss: 15.3649\n",
      "Epoch 35/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 10.0174 - val_loss: 14.5533\n",
      "Epoch 36/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 9.8246 - val_loss: 13.9369\n",
      "Epoch 37/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 9.3890 - val_loss: 17.0677\n",
      "Epoch 38/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 9.7843 - val_loss: 13.9484\n",
      "Epoch 39/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 9.0089 - val_loss: 25.5673\n",
      "Epoch 40/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 11.0106 - val_loss: 23.2128\n",
      "Epoch 41/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 10.3678 - val_loss: 18.2602\n",
      "Epoch 42/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 9.5660 - val_loss: 13.4889\n",
      "Epoch 43/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 8.8743 - val_loss: 14.8979\n",
      "Epoch 44/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 9.1646 - val_loss: 14.0688\n",
      "Epoch 45/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 8.7740 - val_loss: 13.7804\n",
      "Epoch 46/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 8.7013 - val_loss: 16.8968\n",
      "Epoch 47/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 9.1992 - val_loss: 13.5672\n",
      "Epoch 48/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 8.8595 - val_loss: 13.4713\n",
      "Epoch 49/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 8.5622 - val_loss: 13.3829\n",
      "Epoch 50/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 8.3237 - val_loss: 13.9415\n",
      "Epoch 51/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 8.4549 - val_loss: 13.2341\n",
      "Epoch 52/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 8.4182 - val_loss: 15.8572\n",
      "Epoch 53/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 8.8130 - val_loss: 14.5698\n",
      "Epoch 54/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 8.7922 - val_loss: 20.4254\n",
      "Epoch 55/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 9.4795 - val_loss: 15.4960\n",
      "Epoch 56/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 8.1999 - val_loss: 22.9864\n",
      "Epoch 57/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 9.5526 - val_loss: 18.1105\n",
      "Epoch 58/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 9.2970 - val_loss: 14.1676\n",
      "Epoch 59/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 8.5562 - val_loss: 12.9462\n",
      "Epoch 60/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 8.1022 - val_loss: 99.9665\n",
      "Epoch 61/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 21.4094 - val_loss: 11.7325\n",
      "Epoch 62/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 8.5495 - val_loss: 12.1573\n",
      "Epoch 63/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 8.1990 - val_loss: 12.1395\n",
      "Epoch 64/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 8.0143 - val_loss: 12.5436\n",
      "Epoch 65/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.9160 - val_loss: 86.4411\n",
      "Epoch 66/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 16.5892 - val_loss: 12.8088\n",
      "Epoch 67/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 7.9292 - val_loss: 13.1536\n",
      "Epoch 68/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.8379 - val_loss: 12.7537\n",
      "Epoch 69/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.5365 - val_loss: 12.8429\n",
      "Epoch 70/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 7.4958 - val_loss: 13.9111\n",
      "Epoch 71/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 7.6097 - val_loss: 12.7098\n",
      "Epoch 72/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.4796 - val_loss: 12.7221\n",
      "Epoch 73/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.3327 - val_loss: 14.1685\n",
      "Epoch 74/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.5716 - val_loss: 13.1495\n",
      "Epoch 75/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.5122 - val_loss: 12.8336\n",
      "Epoch 76/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.3382 - val_loss: 12.7528\n",
      "Epoch 77/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.2001 - val_loss: 13.0710\n",
      "Epoch 78/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.3072 - val_loss: 12.5808\n",
      "Epoch 79/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.2730 - val_loss: 13.5278\n",
      "Epoch 80/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.4240 - val_loss: 15.6849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.8674 - val_loss: 14.7381\n",
      "Epoch 82/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.4934 - val_loss: 13.3862\n",
      "Epoch 83/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.2089 - val_loss: 12.8501\n",
      "Epoch 84/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.1602 - val_loss: 20.4655\n",
      "Epoch 85/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.7608 - val_loss: 13.9495\n",
      "Epoch 86/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.3611 - val_loss: 12.8054\n",
      "Epoch 87/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.9844 - val_loss: 13.9968\n",
      "Epoch 88/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.2004 - val_loss: 13.6866\n",
      "Epoch 89/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.2212 - val_loss: 14.7041\n",
      "Epoch 90/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.5540 - val_loss: 13.5956\n",
      "Epoch 91/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.0331 - val_loss: 12.9690\n",
      "Epoch 92/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.9343 - val_loss: 26.5891\n",
      "Epoch 93/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 9.7597 - val_loss: 12.9967\n",
      "Epoch 94/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.0864 - val_loss: 13.7741\n",
      "Epoch 95/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.3094 - val_loss: 12.8777\n",
      "Epoch 96/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.9647 - val_loss: 13.5019\n",
      "Epoch 97/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.8808 - val_loss: 12.8442\n",
      "Epoch 98/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.8905 - val_loss: 12.3052\n",
      "Epoch 99/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.7694 - val_loss: 12.3943\n",
      "Epoch 100/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.7206 - val_loss: 12.1923\n",
      "Epoch 101/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.5832 - val_loss: 12.4602\n",
      "Epoch 102/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.7403 - val_loss: 13.6841\n",
      "Epoch 103/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.7874 - val_loss: 14.6390\n",
      "Epoch 104/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.2060 - val_loss: 18.0666\n",
      "Epoch 105/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.7090 - val_loss: 12.6026\n",
      "Epoch 106/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.4938 - val_loss: 13.1176\n",
      "Epoch 107/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.6215 - val_loss: 12.9596\n",
      "Epoch 108/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.6120 - val_loss: 12.7563\n",
      "Epoch 109/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.6345 - val_loss: 12.6545\n",
      "Epoch 110/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.3942 - val_loss: 12.5598\n",
      "Epoch 111/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.4382 - val_loss: 13.6697\n",
      "Epoch 112/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.8682 - val_loss: 12.0889\n",
      "Epoch 113/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.5813 - val_loss: 12.2086\n",
      "Epoch 114/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.6803 - val_loss: 12.0161\n",
      "Epoch 115/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.4154 - val_loss: 12.6884\n",
      "Epoch 116/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.4484 - val_loss: 12.3846\n",
      "Epoch 117/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.4785 - val_loss: 11.8756\n",
      "Epoch 118/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.3536 - val_loss: 12.3806\n",
      "Epoch 119/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.2008 - val_loss: 92.1681\n",
      "Epoch 120/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 14.0420 - val_loss: 12.9992\n",
      "Epoch 121/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.6555 - val_loss: 17.8636\n",
      "Epoch 122/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.2650 - val_loss: 13.3245\n",
      "Epoch 123/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.5160 - val_loss: 12.4902\n",
      "Epoch 124/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.3069 - val_loss: 12.8298\n",
      "Epoch 125/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.2742 - val_loss: 14.5207\n",
      "Epoch 126/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.4233 - val_loss: 12.8890\n",
      "Epoch 127/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.1863 - val_loss: 12.3834\n",
      "Epoch 128/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.0919 - val_loss: 12.5811\n",
      "Epoch 129/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.2796 - val_loss: 12.4420\n",
      "Epoch 130/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.2110 - val_loss: 19.0604\n",
      "Epoch 131/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.2496 - val_loss: 13.2187\n",
      "Epoch 132/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.1843 - val_loss: 12.3028\n",
      "Epoch 133/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.1628 - val_loss: 12.9435\n",
      "Epoch 134/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.0563 - val_loss: 14.4648\n",
      "Epoch 135/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.3078 - val_loss: 16.4576\n",
      "Epoch 136/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.5136 - val_loss: 13.9316\n",
      "Epoch 137/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.4077 - val_loss: 13.9748\n",
      "Epoch 138/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.3552 - val_loss: 13.3792\n",
      "Epoch 139/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.2126 - val_loss: 12.3304\n",
      "Epoch 140/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.9811 - val_loss: 12.6862\n",
      "Epoch 141/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.7671 - val_loss: 12.3602\n",
      "Epoch 142/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.8242 - val_loss: 12.9951\n",
      "Epoch 143/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.9853 - val_loss: 15.4508\n",
      "Epoch 144/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.6981 - val_loss: 11.7551\n",
      "Epoch 145/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.8055 - val_loss: 11.8576\n",
      "Epoch 146/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.8082 - val_loss: 12.8888\n",
      "Epoch 147/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.9789 - val_loss: 11.9760\n",
      "Epoch 148/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.8787 - val_loss: 11.6287\n",
      "Epoch 149/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.6726 - val_loss: 13.7209\n",
      "Epoch 150/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.0994 - val_loss: 12.0053\n",
      "Epoch 151/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.7736 - val_loss: 11.7209\n",
      "Epoch 152/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.7404 - val_loss: 11.6624\n",
      "Epoch 153/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.6774 - val_loss: 12.0258\n",
      "Epoch 154/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.8724 - val_loss: 11.8144\n",
      "Epoch 155/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.6394 - val_loss: 12.3941\n",
      "Epoch 156/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.7179 - val_loss: 12.5981\n",
      "Epoch 157/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.7657 - val_loss: 11.7275\n",
      "Epoch 158/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.6897 - val_loss: 13.5674\n",
      "Epoch 159/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.6654 - val_loss: 11.3834\n",
      "Epoch 160/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 3ms/step - loss: 5.7331 - val_loss: 11.5590\n",
      "Epoch 161/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.5432 - val_loss: 11.9574\n",
      "Epoch 162/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.7699 - val_loss: 40.4984\n",
      "Epoch 163/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 9.3803 - val_loss: 11.7362\n",
      "Epoch 164/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.7064 - val_loss: 11.6520\n",
      "Epoch 165/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.5111 - val_loss: 13.5426\n",
      "Epoch 166/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.7762 - val_loss: 12.1226\n",
      "Epoch 167/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.5867 - val_loss: 27.0906\n",
      "Epoch 168/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 8.4203 - val_loss: 14.1251\n",
      "Epoch 169/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.6808 - val_loss: 15.9094\n",
      "Epoch 170/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.4550 - val_loss: 12.4913\n",
      "Epoch 171/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.6613 - val_loss: 12.2332\n",
      "Epoch 172/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.5823 - val_loss: 15.5427\n",
      "Epoch 173/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.1792 - val_loss: 12.3518\n",
      "Epoch 174/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.5208 - val_loss: 17.3461\n",
      "Epoch 175/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.9957 - val_loss: 11.5729\n",
      "Epoch 176/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.4860 - val_loss: 17.8862\n",
      "Epoch 177/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.3746 - val_loss: 13.2026\n",
      "Epoch 178/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.6452 - val_loss: 12.0849\n",
      "Epoch 179/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.3328 - val_loss: 11.9885\n",
      "Epoch 180/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.5019 - val_loss: 11.3652\n",
      "Epoch 181/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.4922 - val_loss: 11.3006\n",
      "Epoch 182/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.2310 - val_loss: 12.8936\n",
      "Epoch 183/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.5503 - val_loss: 11.8565\n",
      "Epoch 184/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.2496 - val_loss: 11.8313\n",
      "Epoch 185/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.3452 - val_loss: 11.1974\n",
      "Epoch 186/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.2820 - val_loss: 11.3335\n",
      "Epoch 187/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.2319 - val_loss: 18.9985\n",
      "Epoch 188/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.4566 - val_loss: 11.5024\n",
      "Epoch 189/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.1289 - val_loss: 14.7309\n",
      "Epoch 190/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.6938 - val_loss: 13.0351\n",
      "Epoch 191/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.2727 - val_loss: 11.9278\n",
      "Epoch 192/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.2823 - val_loss: 11.5044\n",
      "Epoch 193/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.1220 - val_loss: 30.2368\n",
      "Epoch 194/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.7772 - val_loss: 16.0738\n",
      "Epoch 195/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.5708 - val_loss: 18.7873\n",
      "Epoch 196/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.4815 - val_loss: 14.9695\n",
      "Epoch 197/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.7947 - val_loss: 14.1972\n",
      "Epoch 198/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.4456 - val_loss: 11.4383\n",
      "Epoch 199/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.0524 - val_loss: 12.0787\n",
      "Epoch 200/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.1197 - val_loss: 11.2799\n",
      "Epoch 201/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.0064 - val_loss: 20.9535\n",
      "Epoch 202/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.6988 - val_loss: 11.6821\n",
      "Epoch 203/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.1835 - val_loss: 11.2330\n",
      "Epoch 204/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.9360 - val_loss: 11.5609\n",
      "Epoch 205/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.9031 - val_loss: 11.3364\n",
      "Epoch 206/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.9273 - val_loss: 11.3732\n",
      "Epoch 207/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.7858 - val_loss: 12.1602\n",
      "Epoch 208/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.9403 - val_loss: 11.3862\n",
      "Epoch 209/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.9140 - val_loss: 13.0766\n",
      "Epoch 210/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.0571 - val_loss: 11.3749\n",
      "Epoch 211/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.9264 - val_loss: 13.0585\n",
      "Epoch 212/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.9731 - val_loss: 27.4390\n",
      "Epoch 213/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.9651 - val_loss: 10.7537\n",
      "Epoch 214/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.9094 - val_loss: 10.9081\n",
      "Epoch 215/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.7508 - val_loss: 11.0299\n",
      "Epoch 216/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.0416 - val_loss: 12.8189\n",
      "Epoch 217/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.1688 - val_loss: 10.8341\n",
      "Epoch 218/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 4.7183 - val_loss: 13.6952\n",
      "Epoch 219/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5.5459 - val_loss: 10.9090\n",
      "Epoch 220/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 4.7128 - val_loss: 10.9126\n",
      "Epoch 221/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 4.7651 - val_loss: 11.2165\n",
      "Epoch 222/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 4.8815 - val_loss: 11.3470\n",
      "Epoch 223/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 4.7355 - val_loss: 16.0529\n",
      "Epoch 224/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.4602 - val_loss: 10.7788\n",
      "Epoch 225/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 4.7599 - val_loss: 11.1036\n",
      "Epoch 226/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 4.7981 - val_loss: 11.0510\n",
      "Epoch 227/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 4.6902 - val_loss: 11.0577\n",
      "Epoch 228/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 4.7720 - val_loss: 13.5462\n",
      "Epoch 229/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.0401 - val_loss: 11.1525\n",
      "Epoch 230/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.7325 - val_loss: 12.3075\n",
      "Epoch 231/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.8273 - val_loss: 10.4759\n",
      "Epoch 232/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 4.6355 - val_loss: 10.4314\n",
      "Epoch 233/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 4.6808 - val_loss: 13.5656\n",
      "Epoch 234/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.3229 - val_loss: 12.4194\n",
      "Epoch 235/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.7194 - val_loss: 12.0317\n",
      "Epoch 236/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.0536 - val_loss: 11.3419\n",
      "Epoch 237/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 4.6607 - val_loss: 12.5058\n",
      "Epoch 238/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 4.6513 - val_loss: 15.1466\n",
      "Epoch 239/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 3ms/step - loss: 5.2050 - val_loss: 10.2405\n",
      "Epoch 240/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.5733 - val_loss: 11.6650\n",
      "Epoch 241/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.5009 - val_loss: 10.3144\n",
      "Epoch 242/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.5220 - val_loss: 10.2692\n",
      "Epoch 243/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.5238 - val_loss: 10.8509\n",
      "Epoch 244/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.6233 - val_loss: 10.3432\n",
      "Epoch 245/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.4797 - val_loss: 10.3943\n",
      "Epoch 246/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.4476 - val_loss: 14.6344\n",
      "Epoch 247/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.0556 - val_loss: 11.8129\n",
      "Epoch 248/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.6399 - val_loss: 17.0406\n",
      "Epoch 249/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.2688 - val_loss: 14.6664\n",
      "Epoch 250/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 4.8683 - val_loss: 10.5253\n",
      "Epoch 251/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 4.3360 - val_loss: 10.4030\n",
      "Epoch 252/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.3384 - val_loss: 94.1144\n",
      "Epoch 253/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 15.0242 - val_loss: 19.0727\n",
      "Epoch 254/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.8649 - val_loss: 11.0515\n",
      "Epoch 255/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 4.6115 - val_loss: 11.3822\n",
      "Epoch 256/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 4.4468 - val_loss: 10.8070\n",
      "Epoch 257/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 4.3529 - val_loss: 10.6743\n",
      "Epoch 258/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.4078 - val_loss: 10.8420\n",
      "Epoch 259/1000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 4.3794 - val_loss: 11.1349\n",
      "Epoch 260/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 4.5353 - val_loss: 11.2766\n",
      "Epoch 261/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.3027 - val_loss: 11.2295\n",
      "Epoch 262/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.4549 - val_loss: 10.6695\n",
      "Epoch 263/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.4848 - val_loss: 19.5053\n",
      "Epoch 264/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.2698 - val_loss: 17.7675\n",
      "Epoch 265/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.3741 - val_loss: 15.5572\n",
      "Epoch 266/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.8105 - val_loss: 11.0401\n",
      "Epoch 267/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.2787 - val_loss: 11.3950\n",
      "Epoch 268/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.3014 - val_loss: 10.8091\n",
      "Epoch 269/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.3797 - val_loss: 10.5343\n",
      "Epoch 270/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.1175 - val_loss: 10.3828\n",
      "Epoch 271/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.2068 - val_loss: 12.8476\n",
      "Epoch 272/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.4237 - val_loss: 11.2006\n",
      "Epoch 273/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.3005 - val_loss: 17.6753\n",
      "Epoch 274/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.0741 - val_loss: 10.5210\n",
      "Epoch 275/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.1831 - val_loss: 11.1784\n",
      "Epoch 276/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.3154 - val_loss: 10.7422\n",
      "Epoch 277/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 4.4521 - val_loss: 10.6218\n",
      "Epoch 278/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.9772 - val_loss: 10.5983\n",
      "Epoch 279/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.1016 - val_loss: 10.9638\n",
      "Epoch 280/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.2340 - val_loss: 11.8810\n",
      "Epoch 281/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.2554 - val_loss: 12.4234\n",
      "Epoch 282/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.3344 - val_loss: 11.1818\n",
      "Epoch 283/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.1816 - val_loss: 11.0023\n",
      "Epoch 284/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.2936 - val_loss: 15.5496\n",
      "Epoch 285/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.8699 - val_loss: 15.4910\n",
      "Epoch 286/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 4.6343 - val_loss: 12.4101\n",
      "Epoch 287/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.5918 - val_loss: 12.0268\n",
      "Epoch 288/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.1583 - val_loss: 10.5165\n",
      "Epoch 289/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.1003 - val_loss: 10.7172\n",
      "Epoch 290/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.1195 - val_loss: 26.1278\n",
      "Epoch 291/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.5748 - val_loss: 19.2091\n",
      "Epoch 292/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.1866 - val_loss: 10.4704\n",
      "Epoch 293/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.0829 - val_loss: 10.5154\n",
      "Epoch 294/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.0168 - val_loss: 10.1825\n",
      "Epoch 295/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.9964 - val_loss: 12.9688\n",
      "Epoch 296/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.7930 - val_loss: 15.6460\n",
      "Epoch 297/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.8747 - val_loss: 12.1479\n",
      "Epoch 298/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.4496 - val_loss: 14.3969\n",
      "Epoch 299/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 4.6927 - val_loss: 10.5382\n",
      "Epoch 300/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.9766 - val_loss: 10.2260\n",
      "Epoch 301/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.8401 - val_loss: 11.1217\n",
      "Epoch 302/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 4.0696 - val_loss: 10.4326\n",
      "Epoch 303/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 3.8977 - val_loss: 10.2975\n",
      "Epoch 304/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.8990 - val_loss: 10.5883\n",
      "Epoch 305/1000\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 5.0641\n",
      " \n",
      " Validation accuracy is reached termination in process...!\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 3.9966 - val_loss: 9.8434\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(100, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "history = model.fit(X_train, y_train, epochs=1000, validation_data=(X_valid, y_valid),callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0bd4f55d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 1ms/step - loss: 9.8434\n"
     ]
    }
   ],
   "source": [
    "mse = model.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354a6349",
   "metadata": {},
   "source": [
    "We can also calculate MSE as we did in machine learning repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0dc08bbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.843425541292964"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_valid)\n",
    "\n",
    "mean_squared_error(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e6c3e175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(model3.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ab0311",
   "metadata": {},
   "source": [
    "### Covid Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb6cd73",
   "metadata": {},
   "source": [
    "I previously worked on this data on my machine learning regression exercises. That's why, I won't describe the steps that I did to get data ready but you can find them in my machine learning repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7edfdc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"covidtenmost.csv\")\n",
    "data = data.rename(columns={'Sum_Confirmed': 'sum_Confirmed'})\n",
    "\n",
    "country_list = data['Country'].unique().tolist()\n",
    "population_list=[\"66727461\",\"64842509\",\"46647428\",\"17021347\",\"207833823\",\"11419748\",\"9904896\",\"8829628\",\"60673701\",\n",
    "                \"145530082\"]\n",
    "\n",
    "hospital_list=[\"1257\",\"3042\",\"782\",\"549\",\"6738\",\"165\",\"100\",\"350\",\"1048\",\"5300\",\n",
    "                ]\n",
    "df_population=pd.DataFrame(population_list,columns=[\"Population\"]) # Data frame of population\n",
    "df_hospital=pd.DataFrame(hospital_list,columns=[\"Number of Hospitals\"]) # Data frame of Hospitals\n",
    "df_country=pd.DataFrame(country_list,columns=[\"Country\"])\n",
    "df_GDP=pd.concat([df_country,df_population[\"Population\"].apply(pd.to_numeric,errors='coerce'),\n",
    "                  df_hospital[\"Number of Hospitals\"].apply(pd.to_numeric,errors='coerce')],axis = 1) # joining data frames\n",
    "df_GDP\n",
    "\n",
    "data_final = data.merge(df_GDP, how='left', on = 'Country')\n",
    "\n",
    "target=pd.DataFrame(data_final[\"sum_Deaths\"])\n",
    "\n",
    "data_final.drop([\"Date\",\"Lat\",\"Median_CaseFatalityRatio\",\"Median_IncidenceRate\",\"Lon\",\"sum_Deaths\"],axis=1,inplace=True)\n",
    "\n",
    "data_final_ohc=pd.get_dummies(data_final, columns=[\"Country\"], drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbc1ad5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final.drop(\"Country\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cf3e1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(data_final, target, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c2f8f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_valid_s = scaler.transform(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085cef95",
   "metadata": {},
   "source": [
    "Time to construct our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "94f0716b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "71/71 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/50\n",
      "71/71 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/50\n",
      "71/71 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/50\n",
      "71/71 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/50\n",
      "71/71 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/50\n",
      "71/71 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/50\n",
      "71/71 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/50\n",
      "71/71 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/50\n",
      "71/71 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/50\n",
      "71/71 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/50\n",
      "71/71 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 12/50\n",
      "71/71 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 13/50\n",
      "71/71 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 14/50\n",
      "71/71 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 15/50\n",
      "71/71 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 16/50\n",
      "71/71 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 17/50\n",
      "71/71 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 18/50\n",
      "71/71 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 19/50\n",
      "71/71 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 20/50\n",
      "71/71 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 21/50\n",
      "71/71 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 22/50\n",
      "71/71 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 23/50\n",
      "71/71 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 24/50\n",
      "71/71 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 25/50\n",
      "71/71 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 26/50\n",
      "71/71 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 27/50\n",
      "71/71 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 28/50\n",
      "71/71 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 29/50\n",
      "71/71 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 30/50\n",
      "71/71 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 31/50\n",
      "71/71 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 32/50\n",
      "71/71 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 33/50\n",
      "71/71 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 34/50\n",
      "71/71 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 35/50\n",
      "71/71 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 36/50\n",
      "71/71 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 37/50\n",
      "71/71 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 38/50\n",
      "71/71 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 39/50\n",
      "71/71 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 40/50\n",
      "71/71 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 41/50\n",
      "71/71 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 42/50\n",
      "71/71 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 43/50\n",
      "71/71 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 44/50\n",
      "71/71 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 45/50\n",
      "71/71 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 46/50\n",
      "71/71 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 47/50\n",
      "71/71 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 48/50\n",
      "71/71 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 49/50\n",
      "71/71 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 50/50\n",
      "71/71 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(480, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.Dense(256, activation=\"relu\"),\n",
    "    keras.layers.Dense(120, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD())\n",
    "history = model.fit(X_train_s, y_train, epochs=50, validation_data=(X_valid_s, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d30fe78",
   "metadata": {},
   "source": [
    "Interesting, I don't think I have a problem with implementation but loss return NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "70a6abe1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 2527705432064.0000 - val_loss: 9432000512.0000\n",
      "Epoch 2/50\n",
      "71/71 [==============================] - 0s 4ms/step - loss: 6122108928.0000 - val_loss: 771674112.0000\n",
      "Epoch 3/50\n",
      "71/71 [==============================] - 0s 4ms/step - loss: 459246208.0000 - val_loss: 235280336.0000\n",
      "Epoch 4/50\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 258118528.0000 - val_loss: 195277456.0000\n",
      "Epoch 5/50\n",
      "71/71 [==============================] - 0s 4ms/step - loss: 526405280.0000 - val_loss: 286363328.0000\n",
      "Epoch 6/50\n",
      "71/71 [==============================] - 0s 4ms/step - loss: 294265376.0000 - val_loss: 324628928.0000\n",
      "Epoch 7/50\n",
      "71/71 [==============================] - 0s 4ms/step - loss: 348583136.0000 - val_loss: 230983856.0000\n",
      "Epoch 8/50\n",
      "71/71 [==============================] - 0s 4ms/step - loss: 261625920.0000 - val_loss: 273786272.0000\n",
      "Epoch 9/50\n",
      "71/71 [==============================] - 0s 4ms/step - loss: 378700576.0000 - val_loss: 547483200.0000\n",
      "Epoch 10/50\n",
      "71/71 [==============================] - 0s 4ms/step - loss: 274668448.0000 - val_loss: 416754752.0000\n",
      "Epoch 11/50\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 542300416.0000 - val_loss: 440683488.0000\n",
      "Epoch 12/50\n",
      "71/71 [==============================] - 0s 4ms/step - loss: 422446784.0000 - val_loss: 244006144.0000\n",
      "Epoch 13/50\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 346008960.0000 - val_loss: 327894080.0000\n",
      "Epoch 14/50\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 367384928.0000 - val_loss: 812287040.0000\n",
      "Epoch 15/50\n",
      "71/71 [==============================] - 0s 4ms/step - loss: 1189488768.0000 - val_loss: 310298976.0000\n",
      "Epoch 16/50\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 1257523712.0000 - val_loss: 4615806976.0000\n",
      "Epoch 17/50\n",
      "71/71 [==============================] - 0s 4ms/step - loss: 39136899072.0000 - val_loss: 39433605120.0000\n",
      "Epoch 18/50\n",
      "71/71 [==============================] - 0s 4ms/step - loss: 8908127232.0000 - val_loss: 665621760.0000\n",
      "Epoch 19/50\n",
      "71/71 [==============================] - 0s 4ms/step - loss: 753309888.0000 - val_loss: 551511488.0000\n",
      "Epoch 20/50\n",
      "71/71 [==============================] - 0s 4ms/step - loss: 435069856.0000 - val_loss: 224304256.0000\n",
      "Epoch 21/50\n",
      "71/71 [==============================] - 0s 4ms/step - loss: 394771232.0000 - val_loss: 201191184.0000\n",
      "Epoch 22/50\n",
      "71/71 [==============================] - 0s 4ms/step - loss: 1321927296.0000 - val_loss: 8921110528.0000\n",
      "Epoch 23/50\n",
      "71/71 [==============================] - 0s 4ms/step - loss: 5824218624.0000 - val_loss: 226310576.0000\n",
      "Epoch 24/50\n",
      "71/71 [==============================] - 0s 4ms/step - loss: 227945792.0000 - val_loss: 277376992.0000\n",
      "Epoch 25/50\n",
      "71/71 [==============================] - 0s 4ms/step - loss: 439328800.0000 - val_loss: 2385001728.0000\n",
      "Epoch 26/50\n",
      "71/71 [==============================] - 0s 4ms/step - loss: 683735552.0000 - val_loss: 1139570432.0000\n",
      "Epoch 27/50\n",
      "71/71 [==============================] - 0s 4ms/step - loss: 981715712.0000 - val_loss: 221178208.0000\n",
      "Epoch 28/50\n",
      "71/71 [==============================] - 0s 6ms/step - loss: 380871808.0000 - val_loss: 210586448.0000\n",
      "Epoch 29/50\n",
      "71/71 [==============================] - 0s 4ms/step - loss: 408373376.0000 - val_loss: 251337040.0000\n",
      "Epoch 30/50\n",
      "71/71 [==============================] - 0s 4ms/step - loss: 54068895744.0000 - val_loss: 61135540224.0000\n",
      "Epoch 31/50\n",
      "71/71 [==============================] - 0s 4ms/step - loss: 4756850176.0000 - val_loss: 1364900864.0000\n",
      "Epoch 32/50\n",
      "71/71 [==============================] - 0s 4ms/step - loss: 669206528.0000 - val_loss: 337383392.0000\n",
      "Epoch 33/50\n",
      "71/71 [==============================] - 0s 4ms/step - loss: 305678400.0000 - val_loss: 278931264.0000\n",
      "Epoch 34/50\n",
      "71/71 [==============================] - 0s 4ms/step - loss: 265079776.0000 - val_loss: 339279872.0000\n",
      "Epoch 35/50\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 261951056.0000 - val_loss: 199861104.0000\n",
      "Epoch 36/50\n",
      "71/71 [==============================] - 0s 4ms/step - loss: 595182464.0000 - val_loss: 2351813120.0000\n",
      "Epoch 37/50\n",
      "71/71 [==============================] - 0s 4ms/step - loss: 395654816.0000 - val_loss: 2455897344.0000\n",
      "Epoch 38/50\n",
      "71/71 [==============================] - 0s 4ms/step - loss: 1844815232.0000 - val_loss: 572341248.0000\n",
      "Epoch 39/50\n",
      "71/71 [==============================] - 0s 4ms/step - loss: 550708672.0000 - val_loss: 212783712.0000\n",
      "Epoch 40/50\n",
      "71/71 [==============================] - 0s 4ms/step - loss: 266564080.0000 - val_loss: 228906144.0000\n",
      "Epoch 41/50\n",
      "71/71 [==============================] - 0s 4ms/step - loss: 310008672.0000 - val_loss: 383059264.0000\n",
      "Epoch 42/50\n",
      "71/71 [==============================] - 0s 4ms/step - loss: 300697312.0000 - val_loss: 203766528.0000\n",
      "Epoch 43/50\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 546070016.0000 - val_loss: 213086080.0000\n",
      "Epoch 44/50\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 317411296.0000 - val_loss: 404754848.0000\n",
      "Epoch 45/50\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 639741888.0000 - val_loss: 3451537920.0000\n",
      "Epoch 46/50\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 2594402816.0000 - val_loss: 525394752.0000\n",
      "Epoch 47/50\n",
      "71/71 [==============================] - 0s 4ms/step - loss: 514068160.0000 - val_loss: 195816368.0000\n",
      "Epoch 48/50\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 367622048.0000 - val_loss: 2203612672.0000\n",
      "Epoch 49/50\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 275300896.0000 - val_loss: 209333952.0000\n",
      "Epoch 50/50\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 490752672.0000 - val_loss: 481036736.0000\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(480, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.Dense(256, activation=\"relu\"),\n",
    "    keras.layers.Dense(120, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.Adam())\n",
    "history = model.fit(X_train_s, y_train, epochs=50, validation_data=(X_valid_s, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a559da6",
   "metadata": {},
   "source": [
    "I think there is a problem with gradient, when I used Adam optimization, even though the loss is so high I can get some values. I look for this nan loss problem on the internet. I found a stackoverflow post about that problem and using gradient_clipping solved the problem so it is probably about that gradients are exploiding during the training. [stackoverflow_post](https://stackoverflow.com/questions/37232782/nan-loss-when-training-regression-network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "fc8319a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 2651757312.0000 - val_loss: 2738427648.0000\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 2651525376.0000 - val_loss: 2738015488.0000\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2650873600.0000 - val_loss: 2736983296.0000\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2649401088.0000 - val_loss: 2734701568.0000\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2646205696.0000 - val_loss: 2730118400.0000\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 2640062720.0000 - val_loss: 2721582336.0000\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2628940544.0000 - val_loss: 2706589696.0000\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 2610080512.0000 - val_loss: 2681532928.0000\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 2578543360.0000 - val_loss: 2641497856.0000\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 2529809152.0000 - val_loss: 2580040448.0000\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2458298624.0000 - val_loss: 2488949760.0000\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 2351310336.0000 - val_loss: 2358301952.0000\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 2200225792.0000 - val_loss: 2177776128.0000\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 2010690688.0000 - val_loss: 1938541312.0000\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 1737452288.0000 - val_loss: 1635455104.0000\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 1418046208.0000 - val_loss: 1274187904.0000\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 1043701952.0000 - val_loss: 883573824.0000\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 667842944.0000 - val_loss: 527846784.0000\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 387184416.0000 - val_loss: 324296448.0000\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 286764672.0000 - val_loss: 288908448.0000\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 262033152.0000 - val_loss: 264038976.0000\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 241497696.0000 - val_loss: 240755728.0000\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 222914560.0000 - val_loss: 222514432.0000\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 207266928.0000 - val_loss: 205545744.0000\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 193552976.0000 - val_loss: 195256272.0000\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 183964416.0000 - val_loss: 183802240.0000\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 175193728.0000 - val_loss: 174619696.0000\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 168511232.0000 - val_loss: 169355296.0000\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 164277168.0000 - val_loss: 165510672.0000\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 160029984.0000 - val_loss: 162616048.0000\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 156734464.0000 - val_loss: 156923488.0000\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 153746368.0000 - val_loss: 155448592.0000\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 150442304.0000 - val_loss: 150171040.0000\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 147931840.0000 - val_loss: 148397392.0000\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 145738640.0000 - val_loss: 144956880.0000\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 143475696.0000 - val_loss: 144825824.0000\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 141346736.0000 - val_loss: 143722208.0000\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 139171632.0000 - val_loss: 141628928.0000\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 136034800.0000 - val_loss: 138845008.0000\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 134035720.0000 - val_loss: 137967344.0000\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 132203392.0000 - val_loss: 131368264.0000\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 129379920.0000 - val_loss: 128768288.0000\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 126581304.0000 - val_loss: 125856872.0000\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 125425328.0000 - val_loss: 123544016.0000\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 122094856.0000 - val_loss: 120725864.0000\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 119462944.0000 - val_loss: 125716208.0000\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 117618192.0000 - val_loss: 115681320.0000\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 113632752.0000 - val_loss: 113816048.0000\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 111574864.0000 - val_loss: 110143224.0000\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 108400232.0000 - val_loss: 107627592.0000\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 106022424.0000 - val_loss: 104473080.0000\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 103459168.0000 - val_loss: 102039168.0000\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 100393552.0000 - val_loss: 100040424.0000\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 98088512.0000 - val_loss: 96181808.0000\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 95319480.0000 - val_loss: 93749368.0000\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 92234104.0000 - val_loss: 90531760.0000\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 89305232.0000 - val_loss: 89217992.0000\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 86371328.0000 - val_loss: 85066840.0000\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 84174792.0000 - val_loss: 84811240.0000\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 81285640.0000 - val_loss: 82085056.0000\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 79668896.0000 - val_loss: 81900288.0000\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 78630656.0000 - val_loss: 77017584.0000\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 76533416.0000 - val_loss: 76633496.0000\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 74767504.0000 - val_loss: 76239432.0000\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 73181184.0000 - val_loss: 71370968.0000\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 71852288.0000 - val_loss: 74258560.0000\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 70137192.0000 - val_loss: 70398712.0000\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 68735304.0000 - val_loss: 71606728.0000\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 67217976.0000 - val_loss: 66318544.0000\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 66789304.0000 - val_loss: 65720136.0000\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 12ms/step - loss: 65464448.0000 - val_loss: 65768288.0000\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 64443940.0000 - val_loss: 65313064.0000\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 64420828.0000 - val_loss: 63801212.0000\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 62734512.0000 - val_loss: 61609844.0000\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 61993420.0000 - val_loss: 62234820.0000\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 61531724.0000 - val_loss: 59315612.0000\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 60469228.0000 - val_loss: 58823160.0000\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 59381056.0000 - val_loss: 58251756.0000\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 59863532.0000 - val_loss: 57152504.0000\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 58482860.0000 - val_loss: 57984140.0000\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 56711808.0000 - val_loss: 54789544.0000\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 56297408.0000 - val_loss: 53498752.0000\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 54967056.0000 - val_loss: 52441984.0000\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 55142724.0000 - val_loss: 52542728.0000\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 53558408.0000 - val_loss: 50790280.0000\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 52780080.0000 - val_loss: 49901912.0000\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 51634336.0000 - val_loss: 49076448.0000\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 50953736.0000 - val_loss: 47625512.0000\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 50270684.0000 - val_loss: 46978428.0000\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 49682036.0000 - val_loss: 46613656.0000\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 48663156.0000 - val_loss: 45530156.0000\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 47836596.0000 - val_loss: 46959644.0000\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 47321740.0000 - val_loss: 43437552.0000\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 46222468.0000 - val_loss: 43830908.0000\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 45233736.0000 - val_loss: 42096380.0000\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 44507352.0000 - val_loss: 42233768.0000\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 43683104.0000 - val_loss: 44945808.0000\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 43285420.0000 - val_loss: 40623860.0000\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 42222264.0000 - val_loss: 39646252.0000\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 41929036.0000 - val_loss: 38758572.0000\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(600, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(480, activation=\"relu\"),\n",
    "    keras.layers.Dense(375, activation=\"relu\"),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.Dense(256, activation=\"relu\"),\n",
    "    keras.layers.Dense(128, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(clipnorm=1))\n",
    "history = model.fit(X_train_s, y_train, epochs=100, validation_data=(X_valid_s, y_valid), batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e9ed67",
   "metadata": {},
   "source": [
    "Okay the val_loss is too high, let's scale our target variable as well and use the network again. About scaling [link](https://machinelearningmastery.com/how-to-improve-neural-network-stability-and-modeling-performance-with-data-scaling/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "3278b87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler2 = StandardScaler()\n",
    "y_train_s = scaler2.fit_transform(y_train)\n",
    "y_valid_s = scaler2.transform(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "a9a04ebe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0307 - val_loss: 0.0269\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0225 - val_loss: 0.0228\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0202 - val_loss: 0.0211\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0192 - val_loss: 0.0202\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0184 - val_loss: 0.0194\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0178 - val_loss: 0.0188\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0173 - val_loss: 0.0183\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0169 - val_loss: 0.0178\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0165 - val_loss: 0.0174\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0161 - val_loss: 0.0170\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0157 - val_loss: 0.0167\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0154 - val_loss: 0.0163\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0150 - val_loss: 0.0160\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0147 - val_loss: 0.0156\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0144 - val_loss: 0.0153\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0141 - val_loss: 0.0150\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0138 - val_loss: 0.0147\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0135 - val_loss: 0.0143\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0132 - val_loss: 0.0140\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0129 - val_loss: 0.0138\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0126 - val_loss: 0.0135\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0123 - val_loss: 0.0131\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0120 - val_loss: 0.0128\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0117 - val_loss: 0.0125\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0115 - val_loss: 0.0122\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0112 - val_loss: 0.0120\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0109 - val_loss: 0.0117\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0107 - val_loss: 0.0114\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0104 - val_loss: 0.0112\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0102 - val_loss: 0.0109\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0100 - val_loss: 0.0107\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0098 - val_loss: 0.0104\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0096 - val_loss: 0.0102\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0093 - val_loss: 0.0100\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0091 - val_loss: 0.0098\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0089 - val_loss: 0.0096\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0087 - val_loss: 0.0093\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0085 - val_loss: 0.0091\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0083 - val_loss: 0.0089\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0081 - val_loss: 0.0087\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.0080 - val_loss: 0.0085\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0078 - val_loss: 0.0083\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0076 - val_loss: 0.0081\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0074 - val_loss: 0.0079\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0072 - val_loss: 0.0077\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0071 - val_loss: 0.0075\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0069 - val_loss: 0.0074\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0067 - val_loss: 0.0072\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0065 - val_loss: 0.0070\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0064 - val_loss: 0.0068\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0062 - val_loss: 0.0067\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.0060 - val_loss: 0.0065\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0059 - val_loss: 0.0063\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0057 - val_loss: 0.0061\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0056 - val_loss: 0.0060\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0054 - val_loss: 0.0058\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0053 - val_loss: 0.0057\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0051 - val_loss: 0.0055\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0050 - val_loss: 0.0053\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0048 - val_loss: 0.0052\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0047 - val_loss: 0.0051\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0042 - val_loss: 0.0045\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0039 - val_loss: 0.0042\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0038 - val_loss: 0.0041\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0037 - val_loss: 0.0040\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0036 - val_loss: 0.0039\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0032 - val_loss: 0.0035\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0031 - val_loss: 0.0034\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 0.0020\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(600, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(480, activation=\"relu\"),\n",
    "    keras.layers.Dense(375, activation=\"relu\"),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.Dense(256, activation=\"relu\"),\n",
    "    keras.layers.Dense(128, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD())\n",
    "history = model.fit(X_train_s, y_train_s, epochs=100, validation_data=(X_valid_s, y_valid_s), batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "b1258bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 3ms/step - loss: 0.0018\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0017837422201409936"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_valid_s, y_valid_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717ba07f",
   "metadata": {},
   "source": [
    "The performs seems to have a great performance on the regression problem. However, we actually need to see its performance with unscaled features. I will use `inverse_transform` to get back our unscaled values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "dae71e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_train_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "adce5c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inversed = scaler2.inverse_transform(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "9b55a958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147180936.2110633"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mean_squared_error(y_valid,inversed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26573438",
   "metadata": {},
   "source": [
    "Well looks like my model doesn't perform well on this dataset. In fact we can improve this model but I don't think I will not much need MLP for regression (actually I even used DL for regression just a couple of times) so I don't want to spend much time on it.  A good discussion about Regression with MLP [link](https://stats.stackexchange.com/questions/319349/why-doesnt-deep-learning-work-as-well-in-regression-as-in-classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a7b6bd",
   "metadata": {},
   "source": [
    "### Instead of that I can also use normalization layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "2f19455f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "predictor_normalizer = layers.experimental.preprocessing.Normalization(input_shape=data_final.shape[1:], axis=None)\n",
    "\n",
    "predictor_normalizer.adapt(np.array(data_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f93457b",
   "metadata": {},
   "source": [
    "let's also scale our target feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "c4d099e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scaler_norm = MinMaxScaler()\n",
    "y_train_norm = scaler_norm.fit_transform(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "1b610c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "horsepower_model = keras.Sequential([\n",
    "    predictor_normalizer,\n",
    "    keras.layers.Dense(300, activation=\"relu\",input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(256, activation=\"relu\"),\n",
    "    keras.layers.Dense(128, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "c35f584c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17/17 [==============================] - 1s 37ms/step - loss: 0.0279 - val_loss: 0.0095\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 0.0278 - val_loss: 0.0111\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0278 - val_loss: 0.0098\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0278 - val_loss: 0.0105\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0278 - val_loss: 0.0106\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0278 - val_loss: 0.0100\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0278 - val_loss: 0.0112\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0278 - val_loss: 0.0098\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0278 - val_loss: 0.0106\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0278 - val_loss: 0.0108\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0278 - val_loss: 0.0105\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0279 - val_loss: 0.0116\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0278 - val_loss: 0.0103\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 0.0278 - val_loss: 0.0108\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0278 - val_loss: 0.0107\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0278 - val_loss: 0.0107\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0278 - val_loss: 0.0104\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0278 - val_loss: 0.0105\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0278 - val_loss: 0.0103\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0278 - val_loss: 0.0105\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0278 - val_loss: 0.0102\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0278 - val_loss: 0.0102\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0278 - val_loss: 0.0106\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0278 - val_loss: 0.0101\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0278 - val_loss: 0.0112\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0279 - val_loss: 0.0101\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0278 - val_loss: 0.0106\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0278 - val_loss: 0.0105\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0278 - val_loss: 0.0104\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0278 - val_loss: 0.0110\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0278 - val_loss: 0.0104\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0278 - val_loss: 0.0103\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0278 - val_loss: 0.0103\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0278 - val_loss: 0.0104\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0278 - val_loss: 0.0106\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0278 - val_loss: 0.0102\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0278 - val_loss: 0.0110\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0278 - val_loss: 0.0101\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0278 - val_loss: 0.0106\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0278 - val_loss: 0.0104\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0278 - val_loss: 0.0102\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0278 - val_loss: 0.0108\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0278 - val_loss: 0.0108\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0278 - val_loss: 0.0104\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0278 - val_loss: 0.0104\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0278 - val_loss: 0.0108\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0278 - val_loss: 0.0103\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0278 - val_loss: 0.0105\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 0.0278 - val_loss: 0.0110\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0278 - val_loss: 0.0107\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0278 - val_loss: 0.0105\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0278 - val_loss: 0.0107\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0278 - val_loss: 0.0104\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0278 - val_loss: 0.0108\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0278 - val_loss: 0.0104\n",
      "Epoch 56/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0278 - val_loss: 0.0104\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0278 - val_loss: 0.0105\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0278 - val_loss: 0.0103\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0278 - val_loss: 0.0109\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0278 - val_loss: 0.0106\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0278 - val_loss: 0.0106\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0278 - val_loss: 0.0104\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0278 - val_loss: 0.0108\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0278 - val_loss: 0.0105\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0278 - val_loss: 0.0106\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0278 - val_loss: 0.0103\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0278 - val_loss: 0.0104\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0278 - val_loss: 0.0104\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0278 - val_loss: 0.0105\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0278 - val_loss: 0.0103\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0278 - val_loss: 0.0103\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0278 - val_loss: 0.0108\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0278 - val_loss: 0.0103\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0278 - val_loss: 0.0106\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0278 - val_loss: 0.0102\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0278 - val_loss: 0.0104\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0278 - val_loss: 0.0109\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 0.0278 - val_loss: 0.0103\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0278 - val_loss: 0.0109\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0278 - val_loss: 0.0104\n",
      "Epoch 81/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0278 - val_loss: 0.0104\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0278 - val_loss: 0.0104\n",
      "Epoch 83/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0278 - val_loss: 0.0106\n",
      "Epoch 84/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0278 - val_loss: 0.0103\n",
      "Epoch 85/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0278 - val_loss: 0.0105\n",
      "Epoch 86/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0278 - val_loss: 0.0109\n",
      "Epoch 87/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0278 - val_loss: 0.0104\n",
      "Epoch 88/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0278 - val_loss: 0.0107\n",
      "Epoch 89/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0278 - val_loss: 0.0104\n",
      "Epoch 90/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0278 - val_loss: 0.0107\n",
      "Epoch 91/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0278 - val_loss: 0.0105\n",
      "Epoch 92/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0278 - val_loss: 0.0108\n",
      "Epoch 93/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0278 - val_loss: 0.0105\n",
      "Epoch 94/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0278 - val_loss: 0.0103\n",
      "Epoch 95/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0278 - val_loss: 0.0106\n",
      "Epoch 96/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0278 - val_loss: 0.0107\n",
      "Epoch 97/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0279 - val_loss: 0.0100\n",
      "Epoch 98/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0278 - val_loss: 0.0108\n",
      "Epoch 99/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0278 - val_loss: 0.0107\n",
      "Epoch 100/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0278 - val_loss: 0.0104\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.Adam())\n",
    "history = model.fit(data_final, y_train_norm, epochs=100, batch_size=128,validation_split = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "dc0df481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1678160361.6851528"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypredict=model.predict(data_final)\n",
    "inversed = scaler_norm.inverse_transform(ypredict)\n",
    "mean_squared_error(target,inversed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04e0fb3",
   "metadata": {},
   "source": [
    "There is very good documentation about this normalization layer : [link](https://www.tensorflow.org/tutorials/keras/regression#regression_using_a_dnn_and_multiple_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76829909",
   "metadata": {},
   "source": [
    "## Deep and Wide Neural Network for Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7435caa4",
   "metadata": {},
   "source": [
    "Okay now let's use this deep and wide architecture for a regression problem. Here I will go on using boston dataset and fit the model that I have used for Fashion MNIST for a regression problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b412cc",
   "metadata": {},
   "source": [
    "Splitting the training instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5305e63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(x_train)\n",
    "X_valid = scaler.transform(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ab0b3997",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_wide, X_train_deep = X_train[:, :5], X_train[:, 2:]\n",
    "X_valid_wide, X_valid_deep = X_valid[:, :5], X_valid[:, 2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e733e383",
   "metadata": {},
   "source": [
    "Implementing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "50a687cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_wide = keras.layers.Input(shape=X_train_wide.shape[1:], name=\"wide_model\")\n",
    "input_deep= keras.layers.Input(shape=X_train_deep.shape[1:], name=\"deep_model\")\n",
    "hidden_layer1 = keras.layers.Dense(30, activation=\"relu\")(input_deep)\n",
    "hidden_layer2 = keras.layers.Dense(30, activation=\"relu\")(hidden_layer1)\n",
    "concat_layer = keras.layers.concatenate([input_wide, hidden_layer2])\n",
    "output = keras.layers.Dense(1, name=\"output\")(concat_layer)\n",
    "model = keras.models.Model(inputs=[input_wide, input_deep], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f0dce304",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(lr=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "34b7d185",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 482.5355WARNING:tensorflow:Callbacks method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_begin` time: 0.0010s). Check your callbacks.\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 531.3338 - val_loss: 464.4315\n",
      "Epoch 2/30\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 264.6585 - val_loss: 111.0571\n",
      "Epoch 3/30\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 64.1007 - val_loss: 60.4406\n",
      "Epoch 4/30\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 42.3278 - val_loss: 45.3553\n",
      "Epoch 5/30\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.5223 - val_loss: 41.2515\n",
      "Epoch 6/30\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 29.2972 - val_loss: 33.4458\n",
      "Epoch 7/30\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 25.9065 - val_loss: 28.8316\n",
      "Epoch 8/30\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 23.3728 - val_loss: 26.6050\n",
      "Epoch 9/30\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 21.8898 - val_loss: 25.5184\n",
      "Epoch 10/30\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 20.4155 - val_loss: 24.5610\n",
      "Epoch 11/30\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 19.6307 - val_loss: 27.4006\n",
      "Epoch 12/30\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 18.9298 - val_loss: 22.5862\n",
      "Epoch 13/30\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 17.6766 - val_loss: 21.5588\n",
      "Epoch 14/30\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 16.5540 - val_loss: 19.8701\n",
      "Epoch 15/30\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 16.1151 - val_loss: 21.2026\n",
      "Epoch 16/30\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 16.1189 - val_loss: 21.0826\n",
      "Epoch 17/30\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 15.3859 - val_loss: 17.8515\n",
      "Epoch 18/30\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 14.7425 - val_loss: 17.3745\n",
      "Epoch 19/30\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 14.3949 - val_loss: 17.0453\n",
      "Epoch 20/30\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 13.9994 - val_loss: 16.5208\n",
      "Epoch 21/30\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 13.7691 - val_loss: 16.4586\n",
      "Epoch 22/30\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 13.7093 - val_loss: 21.1475\n",
      "Epoch 23/30\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 14.4092 - val_loss: 16.0130\n",
      "Epoch 24/30\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 13.0360 - val_loss: 24.3614\n",
      "Epoch 25/30\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 14.3444 - val_loss: 20.6603\n",
      "Epoch 26/30\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 13.7520 - val_loss: 15.6579\n",
      "Epoch 27/30\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 12.7286 - val_loss: 15.3415\n",
      "Epoch 28/30\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 12.2987 - val_loss: 15.3782\n",
      "Epoch 29/30\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 12.3051 - val_loss: 15.3552\n",
      "Epoch 30/30\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 12.0375 - val_loss: 15.2005\n"
     ]
    }
   ],
   "source": [
    "history = model.fit((X_train_wide, X_train_deep), y_train, epochs=30,validation_data=((X_valid_wide, X_valid_deep), y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e3854886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 999us/step - loss: 15.2005\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15.200505256652832"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate((X_valid_wide, X_valid_deep), y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778268d8",
   "metadata": {},
   "source": [
    "## Sub Class API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e471532",
   "metadata": {},
   "source": [
    "Okay We deal with Sequential and Functional API, now It's time to go to third one which provides us the most flexibility. The functional API is declarative, in other words, it is static. We cannot add loops, or basically dynamic behaviors into these two API. On the other hand, Sub Class API provides us that freedom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "53f40eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeepModel(keras.models.Model):\n",
    "    def __init__(self, units1=60,units2=30, activation=\"relu\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden_layer1 = keras.layers.Dense(units1, activation=activation)\n",
    "        self.hidden_layer2 = keras.layers.Dense(units2, activation=activation)\n",
    "        self.model_output = keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        input_wide, input_deep = inputs\n",
    "        hidden_layer1 = self.hidden_layer1(input_deep)\n",
    "        hidden_layer2 = self.hidden_layer2(hidden_layer1)\n",
    "        concat_layer = keras.layers.concatenate([input_wide, hidden_layer2])\n",
    "        output = self.model_output(concat_layer)\n",
    "        return output\n",
    "\n",
    "model = WideAndDeepModel(60,30,activation=\"relu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2932041b",
   "metadata": {},
   "source": [
    "The basic steps to do\n",
    "1. Create the layers that you are going to use in your model in constructor.\n",
    "2. By using the method `call()` perform the computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3a521dc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 422.9424 - val_loss: 196.9852\n",
      "Epoch 2/30\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 79.2062 - val_loss: 56.7003\n",
      "Epoch 3/30\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 38.5891 - val_loss: 42.3823\n",
      "Epoch 4/30\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 29.8230 - val_loss: 37.2370\n",
      "Epoch 5/30\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 25.9101 - val_loss: 33.2582\n",
      "Epoch 6/30\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 23.2522 - val_loss: 28.4117\n",
      "Epoch 7/30\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 20.7349 - val_loss: 26.1935\n",
      "Epoch 8/30\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 19.4715 - val_loss: 24.2142\n",
      "Epoch 9/30\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 18.1533 - val_loss: 27.7501\n",
      "Epoch 10/30\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 17.8728 - val_loss: 22.7223\n",
      "Epoch 11/30\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 16.4746 - val_loss: 22.6101\n",
      "Epoch 12/30\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 16.0702 - val_loss: 20.1676\n",
      "Epoch 13/30\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 14.9763 - val_loss: 28.2763\n",
      "Epoch 14/30\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 15.6227 - val_loss: 17.8744\n",
      "Epoch 15/30\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 13.8909 - val_loss: 20.0937\n",
      "Epoch 16/30\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 14.0267 - val_loss: 57.3842\n",
      "Epoch 17/30\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 19.0012 - val_loss: 18.2794\n",
      "Epoch 18/30\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 12.9373 - val_loss: 17.0113\n",
      "Epoch 19/30\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 12.4848 - val_loss: 18.9244\n",
      "Epoch 20/30\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 12.6229 - val_loss: 18.8685\n",
      "Epoch 21/30\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 12.5902 - val_loss: 15.7725\n",
      "Epoch 22/30\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 11.8172 - val_loss: 15.9212\n",
      "Epoch 23/30\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 11.6711 - val_loss: 15.4897\n",
      "Epoch 24/30\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 11.5339 - val_loss: 36.9533\n",
      "Epoch 25/30\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 15.9624 - val_loss: 13.3506\n",
      "Epoch 26/30\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 11.6717 - val_loss: 14.7378\n",
      "Epoch 27/30\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 11.4986 - val_loss: 14.4310\n",
      "Epoch 28/30\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 11.3137 - val_loss: 14.2446\n",
      "Epoch 29/30\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 10.9162 - val_loss: 14.1860\n",
      "Epoch 30/30\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 10.9432 - val_loss: 16.5039\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "\n",
    "history = model.fit((X_train_wide, X_train_deep), y_train, epochs=30,validation_data=((X_valid_wide, X_valid_deep), y_valid))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "48f4fd34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 800us/step - loss: 16.5039\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16.503881454467773"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate((X_valid_wide, X_valid_deep), y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e36f3e",
   "metadata": {},
   "source": [
    "## Regression for Covid Dataset Revisited"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1961e204",
   "metadata": {},
   "source": [
    "Okay the regression performance for Covid Dataset was awful. I thought I could perhaps improve it a bit and written the code below. I didn't improve it much, in fact, I could improve it more if I used hyperparameter tuning but I save this subject for another day."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8348a45d",
   "metadata": {},
   "source": [
    "I don't want to scale one_hot_encoding for the column:Country. To skip this column I will use `ColumnTransformer()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "acee25b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline = Pipeline([\n",
    "         ('polynomial_features',PolynomialFeatures(degree=3)),#4\n",
    "        ('minmax-scaler', MinMaxScaler()),\n",
    "        \n",
    "    ])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "        remainder='passthrough', #passthough features not listed\n",
    "        transformers=[\n",
    "            ('mm', num_pipeline , ['sum_Confirmed','sum_Recovered','sum_Active','Population','Number of Hospitals'])\n",
    "        ])\n",
    "covid_prepared = preprocessor.fit_transform(data_final_ohc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0100e728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3011, 30)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid_prepared.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608ce99f",
   "metadata": {},
   "source": [
    "Let's split our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84cae05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(covid_prepared, target, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ddbb90",
   "metadata": {},
   "source": [
    "Normalizing the target:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4505f93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer=MinMaxScaler()\n",
    "y_train_norm=normalizer.fit_transform(y_train)\n",
    "y_valid_norm=normalizer.transform(y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5ffc4c",
   "metadata": {},
   "source": [
    "Implementing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5b888116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.0695 - val_loss: 0.0295\n",
      "Epoch 2/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0188 - val_loss: 0.0124\n",
      "Epoch 3/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0118 - val_loss: 0.0102\n",
      "Epoch 4/4000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0095 - val_loss: 0.0082\n",
      "Epoch 5/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0090 - val_loss: 0.0085\n",
      "Epoch 6/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0083 - val_loss: 0.0075\n",
      "Epoch 7/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0080 - val_loss: 0.0085\n",
      "Epoch 8/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0078 - val_loss: 0.0063\n",
      "Epoch 9/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0076 - val_loss: 0.0081\n",
      "Epoch 10/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0077 - val_loss: 0.0077\n",
      "Epoch 11/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0079 - val_loss: 0.0077\n",
      "Epoch 12/4000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0075 - val_loss: 0.0071\n",
      "Epoch 13/4000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0067 - val_loss: 0.0073\n",
      "Epoch 14/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0068 - val_loss: 0.0063\n",
      "Epoch 15/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0064 - val_loss: 0.0062\n",
      "Epoch 16/4000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0065 - val_loss: 0.0059\n",
      "Epoch 17/4000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0062 - val_loss: 0.0066\n",
      "Epoch 18/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0069 - val_loss: 0.0055\n",
      "Epoch 19/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0063 - val_loss: 0.0062\n",
      "Epoch 20/4000\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0072 - val_loss: 0.0065\n",
      "Epoch 21/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0064 - val_loss: 0.0059\n",
      "Epoch 22/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0064 - val_loss: 0.0058\n",
      "Epoch 23/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0062 - val_loss: 0.0061\n",
      "Epoch 24/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0063 - val_loss: 0.0057\n",
      "Epoch 25/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0062 - val_loss: 0.0062\n",
      "Epoch 26/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0063 - val_loss: 0.0055\n",
      "Epoch 27/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0058 - val_loss: 0.0051\n",
      "Epoch 28/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0059 - val_loss: 0.0056\n",
      "Epoch 29/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0060 - val_loss: 0.0054\n",
      "Epoch 30/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0057 - val_loss: 0.0052\n",
      "Epoch 31/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0057 - val_loss: 0.0055\n",
      "Epoch 32/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 33/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0054 - val_loss: 0.0049\n",
      "Epoch 34/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0054 - val_loss: 0.0057\n",
      "Epoch 35/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0057 - val_loss: 0.0052\n",
      "Epoch 36/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 37/4000\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.005 - 0s 8ms/step - loss: 0.0056 - val_loss: 0.0045\n",
      "Epoch 38/4000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0059 - val_loss: 0.0065\n",
      "Epoch 39/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0066 - val_loss: 0.0050\n",
      "Epoch 40/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0050 - val_loss: 0.0044\n",
      "Epoch 41/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0051 - val_loss: 0.0057\n",
      "Epoch 42/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0053 - val_loss: 0.0044\n",
      "Epoch 43/4000\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.005 - 0s 5ms/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 44/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0050 - val_loss: 0.0051\n",
      "Epoch 45/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 46/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0049 - val_loss: 0.0044\n",
      "Epoch 47/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 48/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 49/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0049 - val_loss: 0.0043\n",
      "Epoch 50/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 51/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 52/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0049 - val_loss: 0.0064\n",
      "Epoch 53/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0054 - val_loss: 0.0043\n",
      "Epoch 54/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 55/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0039\n",
      "Epoch 56/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 57/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0048 - val_loss: 0.0039\n",
      "Epoch 58/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0048 - val_loss: 0.0045\n",
      "Epoch 59/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0048 - val_loss: 0.0038\n",
      "Epoch 60/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 61/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0037\n",
      "Epoch 62/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 63/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0042\n",
      "Epoch 64/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0038\n",
      "Epoch 65/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0039\n",
      "Epoch 66/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0042\n",
      "Epoch 67/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 68/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0044\n",
      "Epoch 69/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 70/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - val_loss: 0.0034\n",
      "Epoch 71/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 72/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 73/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0050 - val_loss: 0.0047\n",
      "Epoch 74/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 75/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 76/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 77/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - val_loss: 0.0041\n",
      "Epoch 78/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - val_loss: 0.0042\n",
      "Epoch 79/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 80/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0039 - val_loss: 0.0041\n",
      "Epoch 81/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0042 - val_loss: 0.0039\n",
      "Epoch 82/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - val_loss: 0.0041\n",
      "Epoch 83/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0041 - val_loss: 0.0038\n",
      "Epoch 84/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 85/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 86/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0042\n",
      "Epoch 87/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 88/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - val_loss: 0.0040\n",
      "Epoch 89/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 90/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0034\n",
      "Epoch 91/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 92/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 93/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 94/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0031\n",
      "Epoch 95/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0032\n",
      "Epoch 96/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0044\n",
      "Epoch 97/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 98/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 99/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 100/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - val_loss: 0.0042\n",
      "Epoch 101/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 102/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 103/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0033 - val_loss: 0.0041\n",
      "Epoch 104/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 105/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0032\n",
      "Epoch 106/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 107/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 108/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 109/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 110/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 111/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 112/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0035 - val_loss: 0.0031\n",
      "Epoch 113/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 114/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0043\n",
      "Epoch 115/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 116/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0032 - val_loss: 0.0036\n",
      "Epoch 117/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0040 - val_loss: 0.0032\n",
      "Epoch 118/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0034\n",
      "Epoch 119/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0029\n",
      "Epoch 120/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0031 - val_loss: 0.0034\n",
      "Epoch 121/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 122/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 123/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0034\n",
      "Epoch 124/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 125/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0039 - val_loss: 0.0031\n",
      "Epoch 126/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0031 - val_loss: 0.0028\n",
      "Epoch 127/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.0026\n",
      "Epoch 128/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0029 - val_loss: 0.0026\n",
      "Epoch 129/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0030 - val_loss: 0.0026\n",
      "Epoch 130/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 131/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0028\n",
      "Epoch 132/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 133/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 134/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 135/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 136/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0029 - val_loss: 0.0024\n",
      "Epoch 137/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 138/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0032 - val_loss: 0.0026\n",
      "Epoch 139/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 140/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 141/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 142/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 143/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0029 - val_loss: 0.0026\n",
      "Epoch 144/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 145/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0028 - val_loss: 0.0023\n",
      "Epoch 146/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 147/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.0024\n",
      "Epoch 148/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 149/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 150/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0030 - val_loss: 0.0027\n",
      "Epoch 151/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0027 - val_loss: 0.0021\n",
      "Epoch 152/4000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 153/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 154/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 155/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 156/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 157/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 158/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0031 - val_loss: 0.0039\n",
      "Epoch 159/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 160/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0025 - val_loss: 0.0020\n",
      "Epoch 161/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 162/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 163/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 164/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 165/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 166/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 167/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 168/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 169/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 170/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 171/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 172/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 173/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 174/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 175/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 176/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 177/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 178/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0029 - val_loss: 0.0024\n",
      "Epoch 179/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 180/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 181/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0028 - val_loss: 0.0025\n",
      "Epoch 182/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 183/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 184/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 185/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 186/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 0.0030\n",
      "Epoch 187/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0023\n",
      "Epoch 188/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 189/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 190/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 191/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Epoch 192/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0023\n",
      "Epoch 193/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 194/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 195/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 196/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 197/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 198/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 199/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0021 - val_loss: 0.0032\n",
      "Epoch 200/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0030 - val_loss: 0.0025\n",
      "Epoch 201/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0022\n",
      "Epoch 202/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 203/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 204/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 205/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 206/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 207/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 208/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0029 - val_loss: 0.0024\n",
      "Epoch 209/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 210/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 211/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 212/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0031 - val_loss: 0.0024\n",
      "Epoch 213/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 214/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 215/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0028 - val_loss: 0.0023\n",
      "Epoch 216/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 217/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0019\n",
      "Epoch 218/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 219/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 220/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 221/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 222/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 223/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 224/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 225/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 226/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 227/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 228/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 229/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 230/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 231/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 232/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0021\n",
      "Epoch 233/4000\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 234/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 235/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 236/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 237/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 238/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 239/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 240/4000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 241/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 242/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 243/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 244/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 245/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 246/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 247/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 248/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 249/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 250/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 251/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 252/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0027 - val_loss: 0.0023\n",
      "Epoch 253/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 254/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 255/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 256/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 257/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 258/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 259/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 260/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 261/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 262/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 263/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 264/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 265/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 266/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 267/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 268/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 269/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 270/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 271/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 272/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 273/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 274/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 275/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 276/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 277/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 278/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 279/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 280/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 281/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 282/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 283/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 284/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 285/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 286/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 287/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 288/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 289/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 290/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 291/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 292/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 293/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 294/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 295/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 296/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 297/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 298/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 299/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 300/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 301/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 302/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 303/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 304/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 305/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 306/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 307/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 308/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 309/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 310/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 311/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 312/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 313/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 314/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 315/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 316/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 317/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 318/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 319/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 320/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 321/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 322/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 323/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 324/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0020 - val_loss: 0.0034\n",
      "Epoch 325/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 326/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 327/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 328/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 329/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 330/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 331/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 332/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 333/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 334/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 335/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 336/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 337/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 338/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 339/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 340/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 341/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 342/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 343/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 344/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 345/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 346/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 347/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 348/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 349/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 350/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 351/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 352/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 353/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 354/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 355/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 356/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 357/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 358/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 359/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 360/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 361/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 362/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 363/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 364/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 365/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 366/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 367/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 368/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 369/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 370/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 371/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 372/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 373/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 374/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 375/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 376/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 377/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 378/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 379/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 380/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 381/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 382/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 383/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 384/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 385/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 386/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 387/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 388/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 389/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 390/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 391/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 392/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 393/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 394/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 395/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 396/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 397/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 398/4000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 399/4000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 400/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 401/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 402/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 403/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0025 - val_loss: 0.0020\n",
      "Epoch 404/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 405/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 406/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 407/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 408/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 409/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 410/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 411/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 412/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 413/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 414/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 415/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 416/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 417/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 418/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 419/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 420/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 421/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 422/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 423/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 424/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 425/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 426/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 427/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 428/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 429/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 430/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 431/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 432/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 433/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 434/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 435/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 436/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 437/4000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 438/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 439/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 440/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 441/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 442/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 443/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 444/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 445/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 446/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 447/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 448/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 449/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 450/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 451/4000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 452/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 453/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 454/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 455/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 456/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 457/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 458/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 459/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 460/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 461/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 462/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 463/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 464/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 465/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 466/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 467/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 468/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 469/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 470/4000\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 471/4000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 472/4000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 473/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0027 - val_loss: 0.0022\n",
      "Epoch 474/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 475/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 476/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 477/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 478/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 479/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 480/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 481/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 482/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 483/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 484/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 485/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 486/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 487/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 488/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 489/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 490/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 491/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 492/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 493/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 494/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 495/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 496/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 497/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 498/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 499/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 500/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 501/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 502/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 503/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 504/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 505/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 506/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 507/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 508/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 509/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 510/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 511/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 512/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 513/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 514/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 515/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 516/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 517/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 518/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 519/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 520/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 521/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 522/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 523/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 524/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 525/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 526/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 527/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 9.6980e-04\n",
      "Epoch 528/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 529/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 530/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 531/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 532/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 533/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 534/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 535/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 536/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 537/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 538/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 539/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 540/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 541/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 542/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 543/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 544/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 545/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 546/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 547/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 548/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 549/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 550/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 551/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 552/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 553/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 554/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 555/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 556/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 557/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 558/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 559/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 560/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 561/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 562/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 563/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 564/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 565/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 566/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0022 - val_loss: 0.0012\n",
      "Epoch 567/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 568/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 569/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 570/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 571/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 572/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 573/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 574/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 575/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 576/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 577/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 578/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 579/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 580/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 581/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 582/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 9.9954e-04\n",
      "Epoch 583/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 584/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 585/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 586/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 587/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 588/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 589/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 590/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 591/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 592/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 593/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 594/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 595/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 596/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 597/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 598/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 599/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 600/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 601/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 602/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 603/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 604/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 605/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 606/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 607/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 608/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 609/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 610/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 611/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 612/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 613/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0025\n",
      "Epoch 614/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 615/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 616/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 617/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 618/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 619/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 620/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 621/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 622/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 623/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 624/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 625/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 626/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 627/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 628/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 629/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 630/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 631/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 632/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 633/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 634/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 635/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 636/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 637/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 638/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 639/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 640/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 641/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 642/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 643/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 644/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 645/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 646/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 647/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 648/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 649/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 650/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 651/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 652/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 653/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 654/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 655/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 656/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 657/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 658/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 659/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 660/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 661/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 662/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 663/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 664/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 665/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 666/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 667/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 668/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 669/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 670/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 671/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 672/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 673/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 674/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 675/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 676/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 677/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 678/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 679/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 680/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 681/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 682/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 683/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 684/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 685/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 686/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 687/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 688/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 689/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 690/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 691/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 692/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 9.9977e-04\n",
      "Epoch 693/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 694/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 695/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 696/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 697/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 698/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 699/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 700/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 701/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 702/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 703/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 704/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 705/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 706/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 707/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 708/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 709/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 710/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 711/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 712/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 713/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 714/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 715/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 716/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 717/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 718/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 719/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 720/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 8.9812e-04\n",
      "Epoch 721/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 722/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 723/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 724/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 9.9235e-04\n",
      "Epoch 725/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 726/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 727/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 728/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 729/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 730/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 731/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 732/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 733/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 9.8667e-04\n",
      "Epoch 734/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 735/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 736/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 8.4656e-04\n",
      "Epoch 737/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 738/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 739/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 740/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 741/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 742/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 743/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 744/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 745/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 746/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 747/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 748/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 749/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 750/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 9.9234e-04\n",
      "Epoch 751/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 752/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 753/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 754/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 755/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 756/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 757/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 758/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 759/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 760/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 761/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 762/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 763/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 764/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 765/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 766/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 767/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 768/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 769/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 9.1559e-04\n",
      "Epoch 770/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 771/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 772/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 9.7815e-04\n",
      "Epoch 773/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 774/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 775/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 776/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 777/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 778/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 8.0490e-04\n",
      "Epoch 779/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 780/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 781/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 782/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 783/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 9.9037e-04\n",
      "Epoch 784/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 785/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 786/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 787/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 788/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 789/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 790/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 791/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 9.5244e-04\n",
      "Epoch 792/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 793/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 9.5062e-04\n",
      "Epoch 794/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 9.9729e-04\n",
      "Epoch 795/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 796/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 797/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 798/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 799/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 800/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 801/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 802/4000\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.001 - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 803/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 804/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 9.5321e-04\n",
      "Epoch 805/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 806/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 807/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 808/4000\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.001 - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 809/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 810/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 811/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 812/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 9.7260e-04\n",
      "Epoch 813/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 814/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 815/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 816/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 817/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 818/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 9.7928e-04\n",
      "Epoch 819/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 820/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 8.6347e-04\n",
      "Epoch 821/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 9.4675e-04\n",
      "Epoch 822/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 823/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 824/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 825/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 826/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 827/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 9.0708e-04\n",
      "Epoch 828/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 829/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 830/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 831/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 832/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 833/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 834/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 835/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 836/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 837/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 9.9560e-04\n",
      "Epoch 838/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 839/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 840/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 9.4009e-04\n",
      "Epoch 841/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 842/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 843/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 844/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 845/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 846/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 9.9233e-04\n",
      "Epoch 847/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 848/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 849/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 850/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 851/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 852/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 853/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 854/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 855/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 856/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 857/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 858/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 859/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 860/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 861/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 8.2636e-04\n",
      "Epoch 862/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 863/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 864/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 865/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 866/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 867/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 868/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 869/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 870/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 871/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 872/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 873/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0031\n",
      "Epoch 874/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 875/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 876/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 9.9369e-04\n",
      "Epoch 877/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 9.7348e-04\n",
      "Epoch 878/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 879/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 880/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 9.9710e-04\n",
      "Epoch 881/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 882/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 883/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 884/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 885/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 886/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 887/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 888/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 889/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 890/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 9.6141e-04\n",
      "Epoch 891/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 9.0485e-04\n",
      "Epoch 892/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 8.9874e-04\n",
      "Epoch 893/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 894/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0030\n",
      "Epoch 895/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 896/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 897/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 898/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 899/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 900/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 901/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 902/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 903/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 904/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 905/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 906/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 9.4506e-04\n",
      "Epoch 907/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 908/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 909/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 9.2721e-04\n",
      "Epoch 910/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 911/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 912/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 913/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 8.6013e-04\n",
      "Epoch 914/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.7349e-04 - val_loss: 8.7092e-04\n",
      "Epoch 915/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 9.2872e-04\n",
      "Epoch 916/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 917/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 9.6314e-04\n",
      "Epoch 918/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 9.6299e-04\n",
      "Epoch 919/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 9.2294e-04\n",
      "Epoch 920/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 9.8622e-04\n",
      "Epoch 921/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 922/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 923/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 924/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 925/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 926/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 927/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 928/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 929/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 930/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 931/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 932/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 933/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 934/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 9.9327e-04\n",
      "Epoch 935/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 936/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 937/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 938/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 939/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 940/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 9.1330e-04\n",
      "Epoch 941/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 942/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 943/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 944/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 945/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 946/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 947/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 948/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 949/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 950/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 951/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 952/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 953/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 954/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 955/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 956/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 957/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 958/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 959/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 960/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 7.7798e-04\n",
      "Epoch 961/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 962/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 9.3183e-04\n",
      "Epoch 963/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 964/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 965/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 966/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 967/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 968/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 969/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 970/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 971/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 972/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 973/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 974/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 975/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 976/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 977/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 978/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 9.5855e-04\n",
      "Epoch 979/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 980/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 981/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 982/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 983/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 984/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 985/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 986/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 987/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 9.4287e-04\n",
      "Epoch 988/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 989/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 9.7712e-04\n",
      "Epoch 990/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 991/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 9.9901e-04\n",
      "Epoch 992/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 993/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 994/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 995/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 996/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 997/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 9.9425e-04\n",
      "Epoch 998/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 999/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 9.8062e-04\n",
      "Epoch 1000/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 1001/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 1002/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 1003/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 9.7607e-04\n",
      "Epoch 1004/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 1005/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 8.7532e-04\n",
      "Epoch 1006/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 1007/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 1008/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 1009/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 9.4384e-04\n",
      "Epoch 1010/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 1011/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 1012/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 9.0504e-04\n",
      "Epoch 1013/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 1014/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 8.6916e-04\n",
      "Epoch 1015/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 9.0679e-04\n",
      "Epoch 1016/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 9.6986e-04\n",
      "Epoch 1017/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 1018/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 9.4833e-04\n",
      "Epoch 1019/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 8.8483e-04\n",
      "Epoch 1020/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1021/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 1022/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 1023/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1024/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 1025/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 1026/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 8.8753e-04\n",
      "Epoch 1027/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 9.9436e-04\n",
      "Epoch 1028/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 9.7689e-04\n",
      "Epoch 1029/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 1030/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 9.9748e-04\n",
      "Epoch 1031/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 9.3917e-04\n",
      "Epoch 1032/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 1033/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 1034/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 1035/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 1036/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 1037/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 1038/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 1039/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 1040/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 1041/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 1042/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 1043/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1044/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 7.7003e-04\n",
      "Epoch 1045/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1046/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 1047/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 9.3375e-04\n",
      "Epoch 1048/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 1049/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 1050/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 9.5408e-04\n",
      "Epoch 1051/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 9.7926e-04\n",
      "Epoch 1052/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 1053/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 1054/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 1055/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 1056/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 1057/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 1058/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 8.6939e-04\n",
      "Epoch 1059/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 9.0359e-04\n",
      "Epoch 1060/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 1061/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 1062/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 1063/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1064/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 9.5400e-04\n",
      "Epoch 1065/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 7.6498e-04\n",
      "Epoch 1066/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 1067/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1068/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 1069/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 1070/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 1071/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 1072/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 8.5437e-04\n",
      "Epoch 1073/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 9.2241e-04\n",
      "Epoch 1074/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 8.0159e-04\n",
      "Epoch 1075/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 8.8169e-04\n",
      "Epoch 1076/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 9.2382e-04\n",
      "Epoch 1077/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 1078/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 8.1252e-04\n",
      "Epoch 1079/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 9.0849e-04\n",
      "Epoch 1080/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 8.9987e-04\n",
      "Epoch 1081/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 8.8401e-04\n",
      "Epoch 1082/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 1083/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 1084/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 1085/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 1086/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 1087/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 1088/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 1089/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 1090/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 8.0259e-04\n",
      "Epoch 1091/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 1092/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 1093/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 9.7315e-04\n",
      "Epoch 1094/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 8.7985e-04\n",
      "Epoch 1095/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 9.3040e-04\n",
      "Epoch 1096/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 1097/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 1098/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 1099/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 9.8076e-04\n",
      "Epoch 1100/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 1101/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 1102/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1103/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 1104/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 1105/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1106/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 9.7490e-04\n",
      "Epoch 1107/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 8.6787e-04\n",
      "Epoch 1108/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1109/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 1110/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 1111/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 1112/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 1113/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 1114/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 1115/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 1116/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 1117/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 8.6066e-04\n",
      "Epoch 1118/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 9.1062e-04\n",
      "Epoch 1119/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1120/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 1121/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 1122/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 1123/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 1124/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 1125/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 8.1393e-04\n",
      "Epoch 1126/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 9.4344e-04\n",
      "Epoch 1127/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 8.5785e-04\n",
      "Epoch 1128/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 9.8168e-04\n",
      "Epoch 1129/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 9.8824e-04\n",
      "Epoch 1130/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 9.1899e-04\n",
      "Epoch 1131/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 1132/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 1133/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 9.5305e-04\n",
      "Epoch 1134/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 7.6336e-04\n",
      "Epoch 1135/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 1136/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1137/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 1138/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 1139/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 1140/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 1141/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 1142/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1143/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 1144/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 8.2561e-04\n",
      "Epoch 1145/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 8.8649e-04\n",
      "Epoch 1146/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 9.1465e-04\n",
      "Epoch 1147/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 1148/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 1149/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 1150/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1151/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 1152/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 1153/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 1154/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 9.3108e-04\n",
      "Epoch 1155/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 9.2033e-04\n",
      "Epoch 1156/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 8.7114e-04\n",
      "Epoch 1157/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1158/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 1159/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 9.6963e-04\n",
      "Epoch 1160/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 9.9024e-04\n",
      "Epoch 1161/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 1162/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 1163/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 8.4156e-04\n",
      "Epoch 1164/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 8.2645e-04\n",
      "Epoch 1165/4000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 9.1901e-04\n",
      "Epoch 1166/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 8.4852e-04\n",
      "Epoch 1167/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.8358e-04 - val_loss: 8.4688e-04\n",
      "Epoch 1168/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.7035e-04 - val_loss: 8.6918e-04\n",
      "Epoch 1169/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 1170/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 1171/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 1172/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 1173/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 1174/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 1175/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 1176/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 8.2979e-04\n",
      "Epoch 1177/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 9.1489e-04\n",
      "Epoch 1178/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 9.4590e-04\n",
      "Epoch 1179/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1180/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 9.5921e-04\n",
      "Epoch 1181/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 8.2116e-04\n",
      "Epoch 1182/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 1183/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 1184/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1185/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 1186/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 1187/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 1188/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 1189/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1190/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1191/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 1192/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1193/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 9.4426e-04\n",
      "Epoch 1194/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 8.4504e-04\n",
      "Epoch 1195/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 9.9328e-04\n",
      "Epoch 1196/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1197/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 1198/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1199/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 9.4131e-04\n",
      "Epoch 1200/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1201/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 1202/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 1203/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1204/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 1205/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 1206/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 7.9593e-04\n",
      "Epoch 1207/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.9702e-04 - val_loss: 0.0012\n",
      "Epoch 1208/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 1209/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 9.8798e-04\n",
      "Epoch 1210/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 1211/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 1212/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 1213/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 1214/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1215/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 1216/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 1217/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 9.9022e-04\n",
      "Epoch 1218/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 9.5064e-04\n",
      "Epoch 1219/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 1220/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1221/4000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1222/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 1223/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 1224/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 9.0400e-04\n",
      "Epoch 1225/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1226/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1227/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 8.8830e-04\n",
      "Epoch 1228/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.1289e-04 - val_loss: 7.9655e-04\n",
      "Epoch 1229/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 1230/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 9.5145e-04\n",
      "Epoch 1231/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1232/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 9.2720e-04\n",
      "Epoch 1233/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 1234/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 9.3219e-04\n",
      "Epoch 1235/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 8.7543e-04\n",
      "Epoch 1236/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 1237/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 8.6556e-04\n",
      "Epoch 1238/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 1239/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 8.4900e-04\n",
      "Epoch 1240/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 1241/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 8.9094e-04\n",
      "Epoch 1242/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1243/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 1244/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 9.4014e-04\n",
      "Epoch 1245/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 1246/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 1247/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 7.9871e-04\n",
      "Epoch 1248/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.8714e-04 - val_loss: 0.0011\n",
      "Epoch 1249/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1250/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 7.6231e-04\n",
      "Epoch 1251/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 8.7269e-04\n",
      "Epoch 1252/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1253/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 1254/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 1255/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 8.7151e-04\n",
      "Epoch 1256/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1257/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 9.8904e-04\n",
      "Epoch 1258/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1259/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 8.5595e-04\n",
      "Epoch 1260/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 1261/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 1262/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 9.0198e-04\n",
      "Epoch 1263/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 9.8989e-04\n",
      "Epoch 1264/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1265/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 9.2927e-04\n",
      "Epoch 1266/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 1267/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 7.7926e-04\n",
      "Epoch 1268/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 9.4218e-04\n",
      "Epoch 1269/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 1270/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 8.7642e-04\n",
      "Epoch 1271/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.7047e-04 - val_loss: 8.0313e-04\n",
      "Epoch 1272/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 7.5657e-04\n",
      "Epoch 1273/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 6ms/step - loss: 9.6970e-04 - val_loss: 9.7173e-04\n",
      "Epoch 1274/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1275/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 1276/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 9.8888e-04\n",
      "Epoch 1277/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 8.5705e-04\n",
      "Epoch 1278/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.9786e-04 - val_loss: 0.0010\n",
      "Epoch 1279/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 8.6073e-04\n",
      "Epoch 1280/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 7.5605e-04\n",
      "Epoch 1281/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 1282/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 1283/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 1284/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 8.4808e-04\n",
      "Epoch 1285/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 9.7453e-04\n",
      "Epoch 1286/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 8.4593e-04\n",
      "Epoch 1287/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 8.6458e-04\n",
      "Epoch 1288/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1289/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 1290/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 1291/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 9.0853e-04\n",
      "Epoch 1292/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 9.0624e-04\n",
      "Epoch 1293/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 1294/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 1295/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 1296/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 9.6355e-04\n",
      "Epoch 1297/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 9.0924e-04\n",
      "Epoch 1298/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 8.5680e-04\n",
      "Epoch 1299/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 9.8854e-04\n",
      "Epoch 1300/4000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 9.9616e-04 - val_loss: 0.0010\n",
      "Epoch 1301/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 9.7196e-04\n",
      "Epoch 1302/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 1303/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 9.8644e-04\n",
      "Epoch 1304/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 9.8712e-04\n",
      "Epoch 1305/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 1306/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1307/4000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 1308/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 1309/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 1310/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 9.4850e-04\n",
      "Epoch 1311/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 1312/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 7.5108e-04\n",
      "Epoch 1313/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.5285e-04 - val_loss: 9.3746e-04\n",
      "Epoch 1314/4000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 9.7458e-04 - val_loss: 0.0011\n",
      "Epoch 1315/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 8.4296e-04\n",
      "Epoch 1316/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 1317/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 1318/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 1319/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 8.6452e-04\n",
      "Epoch 1320/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 9.2801e-04\n",
      "Epoch 1321/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 1322/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1323/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 1324/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 9.2302e-04\n",
      "Epoch 1325/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 1326/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.5623e-04 - val_loss: 9.7713e-04\n",
      "Epoch 1327/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 9.5077e-04\n",
      "Epoch 1328/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 8.1683e-04\n",
      "Epoch 1329/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 8.5821e-04\n",
      "Epoch 1330/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 1331/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 1332/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 8.0870e-04\n",
      "Epoch 1333/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 9.7174e-04\n",
      "Epoch 1334/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1335/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.7812e-04 - val_loss: 7.6808e-04\n",
      "Epoch 1336/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 1337/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 1338/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 1339/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 9.4397e-04\n",
      "Epoch 1340/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 9.5754e-04\n",
      "Epoch 1341/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 1342/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 8.2772e-04\n",
      "Epoch 1343/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 8.6718e-04\n",
      "Epoch 1344/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1345/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 8.2421e-04\n",
      "Epoch 1346/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 1347/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 9.7753e-04\n",
      "Epoch 1348/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 7.8328e-04\n",
      "Epoch 1349/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.8967e-04 - val_loss: 8.5016e-04\n",
      "Epoch 1350/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1351/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 1352/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1353/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 9.9147e-04\n",
      "Epoch 1354/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 9.2261e-04\n",
      "Epoch 1355/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 9.6866e-04\n",
      "Epoch 1356/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 9.2097e-04\n",
      "Epoch 1357/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 1358/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 8.0111e-04\n",
      "Epoch 1359/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 1360/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 1361/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 9.8081e-04\n",
      "Epoch 1362/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 1363/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 1364/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 1365/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 1366/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 7.7507e-04\n",
      "Epoch 1367/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 1368/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 9.8089e-04\n",
      "Epoch 1369/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 9.9189e-04\n",
      "Epoch 1370/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 8.5539e-04\n",
      "Epoch 1371/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 9.2943e-04\n",
      "Epoch 1372/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 8.5357e-04\n",
      "Epoch 1373/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 1374/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1375/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 1376/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1377/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 1378/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1379/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 9.5124e-04\n",
      "Epoch 1380/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 1381/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 1382/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1383/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1384/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 1385/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 9.0227e-04\n",
      "Epoch 1386/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 8.5994e-04\n",
      "Epoch 1387/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.7053e-04 - val_loss: 7.9900e-04\n",
      "Epoch 1388/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.5036e-04 - val_loss: 7.7158e-04\n",
      "Epoch 1389/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.5489e-04 - val_loss: 0.0012\n",
      "Epoch 1390/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 8.7297e-04\n",
      "Epoch 1391/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 1392/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 8.3399e-04\n",
      "Epoch 1393/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1394/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1395/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 8.8696e-04\n",
      "Epoch 1396/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 1397/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 1398/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1399/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 1400/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 1401/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 1402/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 9.6817e-04\n",
      "Epoch 1403/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.5889e-04 - val_loss: 8.6204e-04\n",
      "Epoch 1404/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 1405/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 1406/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 1407/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 8.3798e-04\n",
      "Epoch 1408/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 8.2209e-04\n",
      "Epoch 1409/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1410/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 1411/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 9.1151e-04\n",
      "Epoch 1412/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 7.2547e-04\n",
      "Epoch 1413/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.8767e-04 - val_loss: 7.0082e-04\n",
      "Epoch 1414/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.4964e-04 - val_loss: 0.0012\n",
      "Epoch 1415/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 1416/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 9.9257e-04\n",
      "Epoch 1417/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 1418/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 8.3952e-04\n",
      "Epoch 1419/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 1420/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 1421/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 1422/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 9.4710e-04\n",
      "Epoch 1423/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 9.9115e-04\n",
      "Epoch 1424/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 1425/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 9.2120e-04\n",
      "Epoch 1426/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1427/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 8.7477e-04\n",
      "Epoch 1428/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 1429/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 9.4393e-04\n",
      "Epoch 1430/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.9272e-04 - val_loss: 8.2066e-04\n",
      "Epoch 1431/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 9.5096e-04\n",
      "Epoch 1432/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 8.9766e-04\n",
      "Epoch 1433/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 1434/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 9.0316e-04\n",
      "Epoch 1435/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.9736e-04 - val_loss: 8.2931e-04\n",
      "Epoch 1436/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 8.4971e-04\n",
      "Epoch 1437/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 8.6412e-04\n",
      "Epoch 1438/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 1439/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1440/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1441/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1442/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1443/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 8.5418e-04\n",
      "Epoch 1444/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 8.3320e-04\n",
      "Epoch 1445/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 1446/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 9.6010e-04\n",
      "Epoch 1447/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1448/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 9.9118e-04\n",
      "Epoch 1449/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 9.8974e-04\n",
      "Epoch 1450/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 9.4230e-04\n",
      "Epoch 1451/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 1452/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 1453/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 7.8323e-04\n",
      "Epoch 1454/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 1455/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1456/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 1457/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 9.9162e-04\n",
      "Epoch 1458/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 7.1988e-04\n",
      "Epoch 1459/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.2115e-04 - val_loss: 7.3530e-04\n",
      "Epoch 1460/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 8.3245e-04\n",
      "Epoch 1461/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.9459e-04 - val_loss: 7.8993e-04\n",
      "Epoch 1462/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 1463/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 8.6238e-04\n",
      "Epoch 1464/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 8.8318e-04\n",
      "Epoch 1465/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 1466/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 7.4565e-04\n",
      "Epoch 1467/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 1468/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 9.7772e-04\n",
      "Epoch 1469/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 9.1662e-04\n",
      "Epoch 1470/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.7749e-04 - val_loss: 9.9270e-04\n",
      "Epoch 1471/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 1472/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 9.7053e-04\n",
      "Epoch 1473/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 8.6619e-04\n",
      "Epoch 1474/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 7.7847e-04\n",
      "Epoch 1475/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 1476/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 1477/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 1478/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 9.9713e-04\n",
      "Epoch 1479/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.5208e-04 - val_loss: 9.7976e-04\n",
      "Epoch 1480/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1481/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 1482/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 9.4930e-04\n",
      "Epoch 1483/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 8.8545e-04\n",
      "Epoch 1484/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.1475e-04 - val_loss: 8.5922e-04\n",
      "Epoch 1485/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.2000e-04 - val_loss: 8.9652e-04\n",
      "Epoch 1486/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1487/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 8.1274e-04\n",
      "Epoch 1488/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.7529e-04 - val_loss: 9.1617e-04\n",
      "Epoch 1489/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 1490/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 1491/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1492/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 7.7517e-04\n",
      "Epoch 1493/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 9.9197e-04\n",
      "Epoch 1494/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 9.6698e-04\n",
      "Epoch 1495/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 9.1845e-04\n",
      "Epoch 1496/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.7892e-04 - val_loss: 8.6727e-04\n",
      "Epoch 1497/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 9.2991e-04\n",
      "Epoch 1498/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1499/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 9.7805e-04\n",
      "Epoch 1500/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 9.6934e-04\n",
      "Epoch 1501/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1502/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 9.1149e-04\n",
      "Epoch 1503/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1504/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 8.6639e-04\n",
      "Epoch 1505/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 9.9734e-04\n",
      "Epoch 1506/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 1507/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 8.1309e-04\n",
      "Epoch 1508/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 1509/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 1510/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 9.8398e-04\n",
      "Epoch 1511/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1512/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 9.6582e-04\n",
      "Epoch 1513/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1514/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 9.5145e-04\n",
      "Epoch 1515/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.8801e-04 - val_loss: 0.0012\n",
      "Epoch 1516/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1517/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 1518/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 1519/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 8.2931e-04\n",
      "Epoch 1520/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 8.8711e-04\n",
      "Epoch 1521/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 8.3638e-04\n",
      "Epoch 1522/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.9522e-04 - val_loss: 0.0011\n",
      "Epoch 1523/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 9.4438e-04\n",
      "Epoch 1524/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.5482e-04 - val_loss: 7.5448e-04\n",
      "Epoch 1525/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.1399e-04 - val_loss: 9.0464e-04\n",
      "Epoch 1526/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1527/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 1528/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 1529/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1530/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1531/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 8.5089e-04\n",
      "Epoch 1532/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.9378e-04 - val_loss: 9.4330e-04\n",
      "Epoch 1533/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 8.0244e-04\n",
      "Epoch 1534/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9.7746e-04 - val_loss: 0.0011\n",
      "Epoch 1535/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 1536/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1537/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 8.5702e-04\n",
      "Epoch 1538/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.6976e-04 - val_loss: 9.7025e-04\n",
      "Epoch 1539/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.7062e-04 - val_loss: 7.8386e-04\n",
      "Epoch 1540/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.1202e-04 - val_loss: 7.4290e-04\n",
      "Epoch 1541/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 9.7651e-04\n",
      "Epoch 1542/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 9.0190e-04\n",
      "Epoch 1543/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.3004e-04 - val_loss: 8.2913e-04\n",
      "Epoch 1544/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.4138e-04 - val_loss: 7.9423e-04\n",
      "Epoch 1545/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 1546/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.8886e-04 - val_loss: 8.8825e-04\n",
      "Epoch 1547/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.9674e-04 - val_loss: 6.6029e-04\n",
      "Epoch 1548/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 8.8547e-04\n",
      "Epoch 1549/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 1550/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1551/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 1552/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 9.2200e-04\n",
      "Epoch 1553/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 1554/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 8.5078e-04\n",
      "Epoch 1555/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 8.7385e-04\n",
      "Epoch 1556/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 7.2429e-04\n",
      "Epoch 1557/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 1558/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 1559/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 1560/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1561/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 9.5455e-04\n",
      "Epoch 1562/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 7.4702e-04\n",
      "Epoch 1563/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 8.8988e-04\n",
      "Epoch 1564/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 7.4735e-04\n",
      "Epoch 1565/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.6842e-04 - val_loss: 9.1260e-04\n",
      "Epoch 1566/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 1567/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1568/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 8.0628e-04\n",
      "Epoch 1569/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.7218e-04 - val_loss: 9.5151e-04\n",
      "Epoch 1570/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 9.1822e-04\n",
      "Epoch 1571/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 9.7265e-04\n",
      "Epoch 1572/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 1573/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 1574/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1575/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 9.1662e-04\n",
      "Epoch 1576/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 1577/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 9.6628e-04\n",
      "Epoch 1578/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 1579/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 1580/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1581/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.9611e-04 - val_loss: 7.7470e-04\n",
      "Epoch 1582/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.0564e-04 - val_loss: 0.0014\n",
      "Epoch 1583/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 1584/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 1585/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 9.8469e-04\n",
      "Epoch 1586/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 1587/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 1588/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 1589/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 1590/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 9.0170e-04\n",
      "Epoch 1591/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 8.2526e-04\n",
      "Epoch 1592/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 9.6477e-04\n",
      "Epoch 1593/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 8.7353e-04\n",
      "Epoch 1594/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 8.4921e-04\n",
      "Epoch 1595/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 1596/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 1597/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 9.0124e-04\n",
      "Epoch 1598/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.8354e-04 - val_loss: 0.0012\n",
      "Epoch 1599/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 9.1336e-04\n",
      "Epoch 1600/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1601/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 9.7555e-04\n",
      "Epoch 1602/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 7.8894e-04\n",
      "Epoch 1603/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.2075e-04 - val_loss: 0.0011\n",
      "Epoch 1604/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 9.2679e-04\n",
      "Epoch 1605/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 1606/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 8.8907e-04\n",
      "Epoch 1607/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 1608/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.9027e-04 - val_loss: 8.5348e-04\n",
      "Epoch 1609/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.8433e-04 - val_loss: 8.1412e-04\n",
      "Epoch 1610/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 1611/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 9.0546e-04\n",
      "Epoch 1612/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.7810e-04 - val_loss: 8.2708e-04\n",
      "Epoch 1613/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.7853e-04 - val_loss: 0.0010\n",
      "Epoch 1614/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 9.8913e-04\n",
      "Epoch 1615/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 9.0124e-04\n",
      "Epoch 1616/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 8.6422e-04\n",
      "Epoch 1617/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 8.7153e-04\n",
      "Epoch 1618/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.7188e-04 - val_loss: 7.3220e-04\n",
      "Epoch 1619/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.1318e-04 - val_loss: 7.8527e-04\n",
      "Epoch 1620/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 8.8451e-04\n",
      "Epoch 1621/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 9.2628e-04\n",
      "Epoch 1622/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.5416e-04 - val_loss: 7.9137e-04\n",
      "Epoch 1623/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 1624/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.9719e-04 - val_loss: 7.5658e-04\n",
      "Epoch 1625/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.5055e-04 - val_loss: 0.0012\n",
      "Epoch 1626/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 1627/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 1628/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 1629/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 7.3351e-04\n",
      "Epoch 1630/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 9.6416e-04\n",
      "Epoch 1631/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 1632/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 9.1772e-04\n",
      "Epoch 1633/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 8.1110e-04\n",
      "Epoch 1634/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1635/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 9.3667e-04\n",
      "Epoch 1636/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 8.3511e-04\n",
      "Epoch 1637/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.0763e-04 - val_loss: 9.4244e-04\n",
      "Epoch 1638/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.2984e-04 - val_loss: 7.3514e-04\n",
      "Epoch 1639/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 9.9013e-04\n",
      "Epoch 1640/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 9.4721e-04\n",
      "Epoch 1641/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.6197e-04 - val_loss: 9.0189e-04\n",
      "Epoch 1642/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 1643/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 1644/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 1645/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 1646/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 8.9994e-04\n",
      "Epoch 1647/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 1648/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 8.6245e-04\n",
      "Epoch 1649/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 1650/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 1651/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 1652/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 1653/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 9.1758e-04\n",
      "Epoch 1654/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.6311e-04 - val_loss: 7.7551e-04\n",
      "Epoch 1655/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.8476e-04 - val_loss: 6.9953e-04\n",
      "Epoch 1656/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.6903e-04 - val_loss: 7.2707e-04\n",
      "Epoch 1657/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.4054e-04 - val_loss: 8.8399e-04\n",
      "Epoch 1658/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 1659/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 8.5767e-04\n",
      "Epoch 1660/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 1661/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 1662/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 1663/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 9.1262e-04\n",
      "Epoch 1664/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1665/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 1666/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.3789e-04 - val_loss: 9.5100e-04\n",
      "Epoch 1667/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.1295e-04 - val_loss: 9.8334e-04\n",
      "Epoch 1668/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 1669/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1670/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 1671/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1672/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 1673/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1674/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 8.2144e-04\n",
      "Epoch 1675/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 8.1875e-04\n",
      "Epoch 1676/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 9.4903e-04\n",
      "Epoch 1677/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 8.1184e-04\n",
      "Epoch 1678/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 1679/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 7.6350e-04\n",
      "Epoch 1680/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.9756e-04 - val_loss: 8.0664e-04\n",
      "Epoch 1681/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.5732e-04 - val_loss: 0.0011\n",
      "Epoch 1682/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.9446e-04 - val_loss: 7.0449e-04\n",
      "Epoch 1683/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.5995e-04 - val_loss: 8.9795e-04\n",
      "Epoch 1684/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 9.2965e-04\n",
      "Epoch 1685/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 7.5094e-04\n",
      "Epoch 1686/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.4271e-04 - val_loss: 9.1130e-04\n",
      "Epoch 1687/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 8.0123e-04\n",
      "Epoch 1688/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.6000e-04 - val_loss: 7.6324e-04\n",
      "Epoch 1689/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.3557e-04 - val_loss: 8.4665e-04\n",
      "Epoch 1690/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.8508e-04 - val_loss: 9.1052e-04\n",
      "Epoch 1691/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.0813e-04 - val_loss: 8.0645e-04\n",
      "Epoch 1692/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 7.8937e-04\n",
      "Epoch 1693/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.8786e-04 - val_loss: 9.2978e-04\n",
      "Epoch 1694/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 1695/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 1696/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 9.1491e-04\n",
      "Epoch 1697/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9.5920e-04 - val_loss: 9.7163e-04\n",
      "Epoch 1698/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9.6091e-04 - val_loss: 0.0011\n",
      "Epoch 1699/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 8.3032e-04\n",
      "Epoch 1700/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 8.2989e-04\n",
      "Epoch 1701/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 1702/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 1703/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 7.8025e-04\n",
      "Epoch 1704/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.8981e-04 - val_loss: 7.4493e-04\n",
      "Epoch 1705/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.4063e-04 - val_loss: 0.0012\n",
      "Epoch 1706/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 7.9825e-04\n",
      "Epoch 1707/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.4199e-04 - val_loss: 7.4396e-04\n",
      "Epoch 1708/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9.4718e-04 - val_loss: 8.8290e-04\n",
      "Epoch 1709/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1710/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 1711/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 9.9519e-04\n",
      "Epoch 1712/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.8397e-04 - val_loss: 7.9537e-04\n",
      "Epoch 1713/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 1714/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 1715/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 1716/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 1717/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 8.4206e-04\n",
      "Epoch 1718/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.8531e-04 - val_loss: 9.3911e-04\n",
      "Epoch 1719/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.4218e-04 - val_loss: 8.8766e-04\n",
      "Epoch 1720/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.4254e-04 - val_loss: 0.0012\n",
      "Epoch 1721/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 8.4875e-04\n",
      "Epoch 1722/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 9.4745e-04\n",
      "Epoch 1723/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.7463e-04 - val_loss: 0.0011\n",
      "Epoch 1724/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 8.5584e-04\n",
      "Epoch 1725/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 9.4144e-04\n",
      "Epoch 1726/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 8.3246e-04\n",
      "Epoch 1727/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.7898e-04 - val_loss: 6.9632e-04\n",
      "Epoch 1728/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.0793e-04 - val_loss: 8.1661e-04\n",
      "Epoch 1729/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 1730/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 1731/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 8.6377e-04\n",
      "Epoch 1732/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 1733/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.2751e-04 - val_loss: 0.0012\n",
      "Epoch 1734/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 1735/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.9981e-04 - val_loss: 8.3858e-04\n",
      "Epoch 1736/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.5076e-04 - val_loss: 9.3504e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1737/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9.6617e-04 - val_loss: 9.9537e-04\n",
      "Epoch 1738/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.2379e-04 - val_loss: 9.3466e-04\n",
      "Epoch 1739/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.2410e-04 - val_loss: 0.0012\n",
      "Epoch 1740/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 1741/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.9551e-04 - val_loss: 8.6900e-04\n",
      "Epoch 1742/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1743/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 1744/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.9659e-04 - val_loss: 8.1809e-04\n",
      "Epoch 1745/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.9217e-04 - val_loss: 9.7173e-04\n",
      "Epoch 1746/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 8.9723e-04\n",
      "Epoch 1747/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 1748/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1749/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 7.4358e-04\n",
      "Epoch 1750/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.7378e-04 - val_loss: 0.0010\n",
      "Epoch 1751/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.0295e-04 - val_loss: 8.3635e-04\n",
      "Epoch 1752/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 8.3366e-04\n",
      "Epoch 1753/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 1754/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 9.3142e-04\n",
      "Epoch 1755/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.7523e-04 - val_loss: 8.6233e-04\n",
      "Epoch 1756/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 9.3808e-04\n",
      "Epoch 1757/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 1758/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 9.0217e-04\n",
      "Epoch 1759/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.3480e-04 - val_loss: 8.5243e-04\n",
      "Epoch 1760/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.4791e-04 - val_loss: 0.0012\n",
      "Epoch 1761/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 8.6896e-04 - val_loss: 7.7877e-04\n",
      "Epoch 1762/4000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 8.0445e-04 - val_loss: 9.5443e-04\n",
      "Epoch 1763/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 7.7427e-04\n",
      "Epoch 1764/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1765/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.9709e-04 - val_loss: 6.8621e-04\n",
      "Epoch 1766/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.8126e-04 - val_loss: 8.7496e-04\n",
      "Epoch 1767/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.7894e-04 - val_loss: 8.0875e-04\n",
      "Epoch 1768/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1769/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 7.8642e-04\n",
      "Epoch 1770/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.5141e-04 - val_loss: 6.8534e-04\n",
      "Epoch 1771/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.2670e-04 - val_loss: 8.5042e-04\n",
      "Epoch 1772/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.6678e-04 - val_loss: 7.4071e-04\n",
      "Epoch 1773/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.9193e-04 - val_loss: 9.9618e-04\n",
      "Epoch 1774/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 8.3561e-04\n",
      "Epoch 1775/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.9432e-04 - val_loss: 9.4046e-04\n",
      "Epoch 1776/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.2792e-04 - val_loss: 8.6978e-04\n",
      "Epoch 1777/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.0651e-04 - val_loss: 9.6273e-04\n",
      "Epoch 1778/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1779/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.3837e-04 - val_loss: 7.0881e-04\n",
      "Epoch 1780/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.2824e-04 - val_loss: 9.5731e-04\n",
      "Epoch 1781/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 1782/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 9.2562e-04\n",
      "Epoch 1783/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.1574e-04 - val_loss: 7.7594e-04\n",
      "Epoch 1784/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.4569e-04 - val_loss: 6.8055e-04\n",
      "Epoch 1785/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.2449e-04 - val_loss: 6.8556e-04\n",
      "Epoch 1786/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.9582e-04 - val_loss: 7.8263e-04\n",
      "Epoch 1787/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.1555e-04 - val_loss: 0.0012\n",
      "Epoch 1788/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 8.4267e-04\n",
      "Epoch 1789/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 8.0111e-04\n",
      "Epoch 1790/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.0372e-04 - val_loss: 9.9262e-04\n",
      "Epoch 1791/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 1792/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 1793/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 1794/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.2875e-04 - val_loss: 8.6407e-04\n",
      "Epoch 1795/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.3648e-04 - val_loss: 0.0011\n",
      "Epoch 1796/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.7968e-04 - val_loss: 7.4890e-04\n",
      "Epoch 1797/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.6630e-04 - val_loss: 7.3400e-04\n",
      "Epoch 1798/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.7159e-04 - val_loss: 8.2290e-04\n",
      "Epoch 1799/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.0736e-04 - val_loss: 8.8480e-04\n",
      "Epoch 1800/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 9.3003e-04\n",
      "Epoch 1801/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1802/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 8.6222e-04\n",
      "Epoch 1803/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.0907e-04 - val_loss: 8.0809e-04\n",
      "Epoch 1804/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.2690e-04 - val_loss: 8.4913e-04\n",
      "Epoch 1805/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 1806/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 8.2890e-04\n",
      "Epoch 1807/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.9262e-04 - val_loss: 0.0010\n",
      "Epoch 1808/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 1809/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 9.1678e-04\n",
      "Epoch 1810/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 1811/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 1812/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.6343e-04 - val_loss: 8.2331e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1813/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.1656e-04 - val_loss: 8.9701e-04\n",
      "Epoch 1814/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 8.1651e-04\n",
      "Epoch 1815/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.7730e-04 - val_loss: 0.0013\n",
      "Epoch 1816/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 7.4793e-04\n",
      "Epoch 1817/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.4585e-04 - val_loss: 7.8130e-04\n",
      "Epoch 1818/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.6945e-04 - val_loss: 0.0011\n",
      "Epoch 1819/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 8.2570e-04\n",
      "Epoch 1820/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.6377e-04 - val_loss: 9.2186e-04\n",
      "Epoch 1821/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.2264e-04 - val_loss: 7.6363e-04\n",
      "Epoch 1822/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.6698e-04 - val_loss: 8.7836e-04\n",
      "Epoch 1823/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.6052e-04 - val_loss: 8.6583e-04\n",
      "Epoch 1824/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.2138e-04 - val_loss: 7.6996e-04\n",
      "Epoch 1825/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 9.6285e-04\n",
      "Epoch 1826/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 1827/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 9.6258e-04\n",
      "Epoch 1828/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 1829/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.5179e-04 - val_loss: 6.4271e-04\n",
      "Epoch 1830/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.2593e-04 - val_loss: 0.0012\n",
      "Epoch 1831/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 9.4165e-04\n",
      "Epoch 1832/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.9672e-04 - val_loss: 0.0012\n",
      "Epoch 1833/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9.1256e-04 - val_loss: 8.3784e-04\n",
      "Epoch 1834/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.4661e-04 - val_loss: 0.0010\n",
      "Epoch 1835/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.6856e-04 - val_loss: 8.9266e-04\n",
      "Epoch 1836/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.6802e-04 - val_loss: 8.4403e-04\n",
      "Epoch 1837/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.5636e-04 - val_loss: 9.3316e-04\n",
      "Epoch 1838/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.2263e-04 - val_loss: 9.2297e-04\n",
      "Epoch 1839/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.8514e-04 - val_loss: 8.2904e-04\n",
      "Epoch 1840/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.4788e-04 - val_loss: 7.9212e-04\n",
      "Epoch 1841/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 1842/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 1843/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 8.8857e-04\n",
      "Epoch 1844/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 8.9515e-04\n",
      "Epoch 1845/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 8.5834e-04\n",
      "Epoch 1846/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 1847/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 1848/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 9.8074e-04\n",
      "Epoch 1849/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.0926e-04 - val_loss: 8.7203e-04\n",
      "Epoch 1850/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.4336e-04 - val_loss: 8.7008e-04\n",
      "Epoch 1851/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.2678e-04 - val_loss: 7.7072e-04\n",
      "Epoch 1852/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.8786e-04 - val_loss: 9.8402e-04\n",
      "Epoch 1853/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.6956e-04 - val_loss: 7.5812e-04\n",
      "Epoch 1854/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.4425e-04 - val_loss: 8.3831e-04\n",
      "Epoch 1855/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 9.1933e-04\n",
      "Epoch 1856/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.2203e-04 - val_loss: 8.4054e-04\n",
      "Epoch 1857/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.5517e-04 - val_loss: 7.5029e-04\n",
      "Epoch 1858/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 1859/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 9.9965e-04\n",
      "Epoch 1860/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1861/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 8.5741e-04\n",
      "Epoch 1862/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 1863/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 8.7451e-04\n",
      "Epoch 1864/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.9447e-04 - val_loss: 8.3188e-04\n",
      "Epoch 1865/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1866/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1867/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.4943e-04 - val_loss: 9.9772e-04\n",
      "Epoch 1868/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 9.9812e-04\n",
      "Epoch 1869/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.6627e-04 - val_loss: 8.2235e-04\n",
      "Epoch 1870/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.1675e-04 - val_loss: 9.8228e-04\n",
      "Epoch 1871/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 1872/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.6843e-04 - val_loss: 0.0012\n",
      "Epoch 1873/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 9.4763e-04\n",
      "Epoch 1874/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.6275e-04 - val_loss: 8.2077e-04\n",
      "Epoch 1875/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.2167e-04 - val_loss: 7.0998e-04\n",
      "Epoch 1876/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 1877/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 1878/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.8212e-04 - val_loss: 9.5532e-04\n",
      "Epoch 1879/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 9.0033e-04\n",
      "Epoch 1880/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.1531e-04 - val_loss: 7.4051e-04\n",
      "Epoch 1881/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.6645e-04 - val_loss: 9.9395e-04\n",
      "Epoch 1882/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.7154e-04 - val_loss: 7.6793e-04\n",
      "Epoch 1883/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.6566e-04 - val_loss: 0.0010\n",
      "Epoch 1884/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 1885/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 1886/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.4631e-04 - val_loss: 0.0011\n",
      "Epoch 1887/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 8.7844e-04 - val_loss: 7.1360e-04\n",
      "Epoch 1888/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.6799e-04 - val_loss: 0.0013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1889/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 9.4376e-04\n",
      "Epoch 1890/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 1891/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 1892/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 1893/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 1894/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.6871e-04 - val_loss: 8.5374e-04\n",
      "Epoch 1895/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.4482e-04 - val_loss: 0.0011\n",
      "Epoch 1896/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.2184e-04 - val_loss: 7.7048e-04\n",
      "Epoch 1897/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.3358e-04 - val_loss: 8.1220e-04\n",
      "Epoch 1898/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1899/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.0629e-04 - val_loss: 7.7007e-04\n",
      "Epoch 1900/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.8555e-04 - val_loss: 9.9982e-04\n",
      "Epoch 1901/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 1902/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 1903/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 9.3080e-04\n",
      "Epoch 1904/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.2887e-04 - val_loss: 9.8190e-04\n",
      "Epoch 1905/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.2048e-04 - val_loss: 0.0010\n",
      "Epoch 1906/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.4998e-04 - val_loss: 7.2094e-04\n",
      "Epoch 1907/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 1908/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 7.6642e-04\n",
      "Epoch 1909/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.9014e-04 - val_loss: 7.1498e-04\n",
      "Epoch 1910/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.9031e-04 - val_loss: 0.0011\n",
      "Epoch 1911/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.6099e-04 - val_loss: 8.4947e-04\n",
      "Epoch 1912/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.2628e-04 - val_loss: 8.2008e-04\n",
      "Epoch 1913/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 1914/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.9981e-04 - val_loss: 9.3841e-04\n",
      "Epoch 1915/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.7534e-04 - val_loss: 7.7898e-04\n",
      "Epoch 1916/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.9595e-04 - val_loss: 7.3795e-04\n",
      "Epoch 1917/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.3704e-04 - val_loss: 0.0014\n",
      "Epoch 1918/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 8.5398e-04\n",
      "Epoch 1919/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 9.0062e-04\n",
      "Epoch 1920/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.1136e-04 - val_loss: 0.0012\n",
      "Epoch 1921/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 1922/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 1923/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 1924/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 1925/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 7.2046e-04\n",
      "Epoch 1926/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.8566e-04 - val_loss: 7.3474e-04\n",
      "Epoch 1927/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 8.2744e-04\n",
      "Epoch 1928/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.8243e-04 - val_loss: 8.4103e-04\n",
      "Epoch 1929/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 1930/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 1931/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 1932/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 9.8995e-04\n",
      "Epoch 1933/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.4843e-04 - val_loss: 9.9202e-04\n",
      "Epoch 1934/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 8.3741e-04\n",
      "Epoch 1935/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.8574e-04 - val_loss: 7.8829e-04\n",
      "Epoch 1936/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.1349e-04 - val_loss: 7.6716e-04\n",
      "Epoch 1937/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.5028e-04 - val_loss: 0.0012\n",
      "Epoch 1938/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 1939/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 7.6111e-04\n",
      "Epoch 1940/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1941/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 1942/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 8.1763e-04\n",
      "Epoch 1943/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.3624e-04 - val_loss: 9.0310e-04\n",
      "Epoch 1944/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 8.5661e-04\n",
      "Epoch 1945/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.8459e-04 - val_loss: 9.5160e-04\n",
      "Epoch 1946/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.5934e-04 - val_loss: 9.5322e-04\n",
      "Epoch 1947/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.1875e-04 - val_loss: 8.5379e-04\n",
      "Epoch 1948/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 1949/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.9376e-04 - val_loss: 9.2989e-04\n",
      "Epoch 1950/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.8071e-04 - val_loss: 7.8455e-04\n",
      "Epoch 1951/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.1330e-04 - val_loss: 9.1982e-04\n",
      "Epoch 1952/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 1953/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.4982e-04 - val_loss: 9.4889e-04\n",
      "Epoch 1954/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.5174e-04 - val_loss: 8.1166e-04\n",
      "Epoch 1955/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.2642e-04 - val_loss: 9.0905e-04\n",
      "Epoch 1956/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.2873e-04 - val_loss: 7.7253e-04\n",
      "Epoch 1957/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.2392e-04 - val_loss: 0.0013\n",
      "Epoch 1958/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1959/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 1960/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 1961/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 8.8459e-04\n",
      "Epoch 1962/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.9551e-04 - val_loss: 9.1058e-04\n",
      "Epoch 1963/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.9495e-04 - val_loss: 8.1107e-04\n",
      "Epoch 1964/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.6491e-04 - val_loss: 8.2565e-04\n",
      "Epoch 1965/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 6ms/step - loss: 8.3997e-04 - val_loss: 8.6085e-04\n",
      "Epoch 1966/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 1967/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 9.1632e-04\n",
      "Epoch 1968/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 8.8836e-04\n",
      "Epoch 1969/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.4608e-04 - val_loss: 7.3865e-04\n",
      "Epoch 1970/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.9023e-04 - val_loss: 0.0011\n",
      "Epoch 1971/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 1972/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 9.6975e-04\n",
      "Epoch 1973/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 8.5782e-04\n",
      "Epoch 1974/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 1975/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.8850e-04 - val_loss: 9.6354e-04\n",
      "Epoch 1976/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.6675e-04 - val_loss: 7.4861e-04\n",
      "Epoch 1977/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.9959e-04 - val_loss: 7.4899e-04\n",
      "Epoch 1978/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.7200e-04 - val_loss: 9.6492e-04\n",
      "Epoch 1979/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.6642e-04 - val_loss: 0.0011\n",
      "Epoch 1980/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 1981/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 9.4130e-04\n",
      "Epoch 1982/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 1983/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 8.8741e-04\n",
      "Epoch 1984/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.7241e-04 - val_loss: 7.4213e-04\n",
      "Epoch 1985/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.9547e-04 - val_loss: 7.3656e-04\n",
      "Epoch 1986/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.7281e-04 - val_loss: 6.5684e-04\n",
      "Epoch 1987/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.3775e-04 - val_loss: 7.8231e-04\n",
      "Epoch 1988/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.0960e-04 - val_loss: 0.0011\n",
      "Epoch 1989/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.5987e-04 - val_loss: 8.4438e-04\n",
      "Epoch 1990/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.3588e-04 - val_loss: 8.2986e-04\n",
      "Epoch 1991/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.7658e-04 - val_loss: 8.0643e-04\n",
      "Epoch 1992/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.7061e-04 - val_loss: 8.1183e-04\n",
      "Epoch 1993/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.1358e-04 - val_loss: 8.8925e-04\n",
      "Epoch 1994/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.5322e-04 - val_loss: 9.2481e-04\n",
      "Epoch 1995/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.7497e-04 - val_loss: 8.4651e-04\n",
      "Epoch 1996/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.2794e-04 - val_loss: 8.8477e-04\n",
      "Epoch 1997/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.8005e-04 - val_loss: 8.3278e-04\n",
      "Epoch 1998/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.6258e-04 - val_loss: 7.6074e-04\n",
      "Epoch 1999/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 2000/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.3107e-04 - val_loss: 8.5173e-04\n",
      "Epoch 2001/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.9517e-04 - val_loss: 7.7580e-04\n",
      "Epoch 2002/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.4044e-04 - val_loss: 0.0011\n",
      "Epoch 2003/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 2004/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 2005/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 9.2462e-04\n",
      "Epoch 2006/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.3657e-04 - val_loss: 8.3923e-04\n",
      "Epoch 2007/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.4577e-04 - val_loss: 6.9143e-04\n",
      "Epoch 2008/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.9512e-04 - val_loss: 8.8637e-04\n",
      "Epoch 2009/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.3400e-04 - val_loss: 6.9425e-04\n",
      "Epoch 2010/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.3357e-04 - val_loss: 6.7918e-04\n",
      "Epoch 2011/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 2012/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 2013/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 2014/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 9.5425e-04\n",
      "Epoch 2015/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.4779e-04 - val_loss: 8.9719e-04\n",
      "Epoch 2016/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.8958e-04 - val_loss: 8.8544e-04\n",
      "Epoch 2017/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.4176e-04 - val_loss: 0.0012\n",
      "Epoch 2018/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.4495e-04 - val_loss: 8.2962e-04\n",
      "Epoch 2019/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.4898e-04 - val_loss: 0.0011\n",
      "Epoch 2020/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 8.0534e-04\n",
      "Epoch 2021/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.7810e-04 - val_loss: 8.7650e-04\n",
      "Epoch 2022/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.4630e-04 - val_loss: 8.5723e-04\n",
      "Epoch 2023/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.1549e-04 - val_loss: 8.7823e-04\n",
      "Epoch 2024/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.1832e-04 - val_loss: 0.0010\n",
      "Epoch 2025/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.3295e-04 - val_loss: 8.7752e-04\n",
      "Epoch 2026/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 2027/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 2028/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9.0920e-04 - val_loss: 8.1163e-04\n",
      "Epoch 2029/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.5296e-04 - val_loss: 0.0010\n",
      "Epoch 2030/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.3323e-04 - val_loss: 0.0012\n",
      "Epoch 2031/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 2032/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 9.1824e-04\n",
      "Epoch 2033/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 8.9336e-04\n",
      "Epoch 2034/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.3955e-04 - val_loss: 9.9405e-04\n",
      "Epoch 2035/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 2036/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 2037/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 8.9084e-04\n",
      "Epoch 2038/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.1064e-04 - val_loss: 0.0012\n",
      "Epoch 2039/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.4219e-04 - val_loss: 8.0396e-04\n",
      "Epoch 2040/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.2496e-04 - val_loss: 9.4937e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2041/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 8.2455e-04\n",
      "Epoch 2042/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.5917e-04 - val_loss: 0.0011\n",
      "Epoch 2043/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.9050e-04 - val_loss: 9.8515e-04\n",
      "Epoch 2044/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 2045/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 7.6695e-04\n",
      "Epoch 2046/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.8447e-04 - val_loss: 9.3243e-04\n",
      "Epoch 2047/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.3599e-04 - val_loss: 8.3007e-04\n",
      "Epoch 2048/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.4912e-04 - val_loss: 0.0010\n",
      "Epoch 2049/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.8258e-04 - val_loss: 0.0011\n",
      "Epoch 2050/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.3443e-04 - val_loss: 9.2165e-04\n",
      "Epoch 2051/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.6861e-04 - val_loss: 7.1383e-04\n",
      "Epoch 2052/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.7208e-04 - val_loss: 8.6418e-04\n",
      "Epoch 2053/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.9892e-04 - val_loss: 0.0010\n",
      "Epoch 2054/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.5457e-04 - val_loss: 8.7317e-04\n",
      "Epoch 2055/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 9.8067e-04\n",
      "Epoch 2056/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.8088e-04 - val_loss: 8.8630e-04\n",
      "Epoch 2057/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 2058/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.9156e-04 - val_loss: 8.0809e-04\n",
      "Epoch 2059/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.6679e-04 - val_loss: 9.5333e-04\n",
      "Epoch 2060/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.8445e-04 - val_loss: 9.2364e-04\n",
      "Epoch 2061/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.6145e-04 - val_loss: 8.7527e-04\n",
      "Epoch 2062/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.8382e-04 - val_loss: 9.4976e-04\n",
      "Epoch 2063/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.7953e-04 - val_loss: 6.7267e-04\n",
      "Epoch 2064/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.1700e-04 - val_loss: 8.5219e-04\n",
      "Epoch 2065/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.8409e-04 - val_loss: 9.6146e-04\n",
      "Epoch 2066/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.5875e-04 - val_loss: 9.0943e-04\n",
      "Epoch 2067/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 2068/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.6922e-04 - val_loss: 7.0137e-04\n",
      "Epoch 2069/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.5040e-04 - val_loss: 7.8522e-04\n",
      "Epoch 2070/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.7775e-04 - val_loss: 7.1731e-04\n",
      "Epoch 2071/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.9559e-04 - val_loss: 8.2193e-04\n",
      "Epoch 2072/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.4518e-04 - val_loss: 0.0010\n",
      "Epoch 2073/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 2074/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.5769e-04 - val_loss: 8.3402e-04\n",
      "Epoch 2075/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.5168e-04 - val_loss: 7.6818e-04\n",
      "Epoch 2076/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.8099e-04 - val_loss: 7.0895e-04\n",
      "Epoch 2077/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.1578e-04 - val_loss: 9.7918e-04\n",
      "Epoch 2078/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.7564e-04 - val_loss: 0.0010\n",
      "Epoch 2079/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.4790e-04 - val_loss: 7.2899e-04\n",
      "Epoch 2080/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.6794e-04 - val_loss: 7.9993e-04\n",
      "Epoch 2081/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.0609e-04 - val_loss: 8.1130e-04\n",
      "Epoch 2082/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 2083/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.2904e-04 - val_loss: 8.2874e-04\n",
      "Epoch 2084/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.2601e-04 - val_loss: 6.7265e-04\n",
      "Epoch 2085/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.4288e-04 - val_loss: 8.8130e-04\n",
      "Epoch 2086/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.3982e-04 - val_loss: 8.6130e-04\n",
      "Epoch 2087/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.0511e-04 - val_loss: 0.0013\n",
      "Epoch 2088/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 2089/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.5228e-04 - val_loss: 9.0218e-04\n",
      "Epoch 2090/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.2722e-04 - val_loss: 9.5261e-04\n",
      "Epoch 2091/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.9020e-04 - val_loss: 7.0327e-04\n",
      "Epoch 2092/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.2242e-04 - val_loss: 0.0011\n",
      "Epoch 2093/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.8882e-04 - val_loss: 6.9298e-04\n",
      "Epoch 2094/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.9121e-04 - val_loss: 9.1505e-04\n",
      "Epoch 2095/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.6562e-04 - val_loss: 8.4878e-04\n",
      "Epoch 2096/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 9.7965e-04\n",
      "Epoch 2097/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.5460e-04 - val_loss: 0.0011\n",
      "Epoch 2098/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.7107e-04 - val_loss: 7.7856e-04\n",
      "Epoch 2099/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.8616e-04 - val_loss: 0.0011\n",
      "Epoch 2100/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 9.9833e-04\n",
      "Epoch 2101/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 9.2078e-04\n",
      "Epoch 2102/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.4604e-04 - val_loss: 9.9959e-04\n",
      "Epoch 2103/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.9322e-04 - val_loss: 9.3141e-04\n",
      "Epoch 2104/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 8.2374e-04\n",
      "Epoch 2105/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 7.7971e-04\n",
      "Epoch 2106/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.4033e-04 - val_loss: 8.7036e-04\n",
      "Epoch 2107/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 7.4048e-04\n",
      "Epoch 2108/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.6689e-04 - val_loss: 8.0788e-04\n",
      "Epoch 2109/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.0468e-04 - val_loss: 8.3335e-04\n",
      "Epoch 2110/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.2812e-04 - val_loss: 0.0010\n",
      "Epoch 2111/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.1967e-04 - val_loss: 9.5967e-04\n",
      "Epoch 2112/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.3658e-04 - val_loss: 8.3635e-04\n",
      "Epoch 2113/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.6525e-04 - val_loss: 9.4380e-04\n",
      "Epoch 2114/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.5755e-04 - val_loss: 8.3490e-04\n",
      "Epoch 2115/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.2333e-04 - val_loss: 8.1183e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2116/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.8216e-04 - val_loss: 8.9470e-04\n",
      "Epoch 2117/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 7.8145e-04\n",
      "Epoch 2118/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.1880e-04 - val_loss: 7.2787e-04\n",
      "Epoch 2119/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.7391e-04 - val_loss: 9.3962e-04\n",
      "Epoch 2120/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.0646e-04 - val_loss: 7.4161e-04\n",
      "Epoch 2121/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.6520e-04 - val_loss: 7.9460e-04\n",
      "Epoch 2122/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.3297e-04 - val_loss: 9.6690e-04\n",
      "Epoch 2123/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 2124/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 8.5358e-04\n",
      "Epoch 2125/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 2126/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 9.7518e-04\n",
      "Epoch 2127/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.4410e-04 - val_loss: 8.0389e-04\n",
      "Epoch 2128/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.4690e-04 - val_loss: 7.4222e-04\n",
      "Epoch 2129/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.3926e-04 - val_loss: 6.8407e-04\n",
      "Epoch 2130/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.1397e-04 - val_loss: 0.0013\n",
      "Epoch 2131/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.9297e-04 - val_loss: 7.7874e-04\n",
      "Epoch 2132/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.8066e-04 - val_loss: 7.4093e-04\n",
      "Epoch 2133/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.0749e-04 - val_loss: 8.0625e-04\n",
      "Epoch 2134/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.2529e-04 - val_loss: 0.0014\n",
      "Epoch 2135/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 2136/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 7.2224e-04\n",
      "Epoch 2137/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 2138/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 9.0734e-04\n",
      "Epoch 2139/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.2908e-04 - val_loss: 6.8986e-04\n",
      "Epoch 2140/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.3397e-04 - val_loss: 0.0011\n",
      "Epoch 2141/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.8542e-04 - val_loss: 7.1530e-04\n",
      "Epoch 2142/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.3218e-04 - val_loss: 0.0011\n",
      "Epoch 2143/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 2144/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.8040e-04 - val_loss: 8.6758e-04\n",
      "Epoch 2145/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.5623e-04 - val_loss: 8.5596e-04\n",
      "Epoch 2146/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.1461e-04 - val_loss: 6.8156e-04\n",
      "Epoch 2147/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.4938e-04 - val_loss: 7.2834e-04\n",
      "Epoch 2148/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.8388e-04 - val_loss: 7.7991e-04\n",
      "Epoch 2149/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9.1611e-04 - val_loss: 9.4896e-04\n",
      "Epoch 2150/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.9489e-04 - val_loss: 8.4558e-04\n",
      "Epoch 2151/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.4731e-04 - val_loss: 8.9750e-04\n",
      "Epoch 2152/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.8793e-04 - val_loss: 7.9539e-04\n",
      "Epoch 2153/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 9.7414e-04\n",
      "Epoch 2154/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 7.5097e-04\n",
      "Epoch 2155/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.6948e-04 - val_loss: 9.1934e-04\n",
      "Epoch 2156/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.8673e-04 - val_loss: 9.8201e-04\n",
      "Epoch 2157/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 8.5917e-04\n",
      "Epoch 2158/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 2159/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.2450e-04 - val_loss: 8.0019e-04\n",
      "Epoch 2160/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.6128e-04 - val_loss: 8.6708e-04\n",
      "Epoch 2161/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.3670e-04 - val_loss: 9.8956e-04\n",
      "Epoch 2162/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.2001e-04 - val_loss: 6.7007e-04\n",
      "Epoch 2163/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.3859e-04 - val_loss: 8.6140e-04\n",
      "Epoch 2164/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.6811e-04 - val_loss: 8.9200e-04\n",
      "Epoch 2165/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 2166/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 7.7178e-04\n",
      "Epoch 2167/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.2244e-04 - val_loss: 0.0011\n",
      "Epoch 2168/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.9988e-04 - val_loss: 8.2375e-04\n",
      "Epoch 2169/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.3883e-04 - val_loss: 9.4343e-04\n",
      "Epoch 2170/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.9773e-04 - val_loss: 9.1469e-04\n",
      "Epoch 2171/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.9663e-04 - val_loss: 9.5525e-04\n",
      "Epoch 2172/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 8.6677e-04 - val_loss: 0.0011\n",
      "Epoch 2173/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.4246e-04 - val_loss: 8.3305e-04\n",
      "Epoch 2174/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.2509e-04 - val_loss: 8.2245e-04\n",
      "Epoch 2175/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.2207e-04 - val_loss: 0.0010\n",
      "Epoch 2176/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.9623e-04 - val_loss: 7.5986e-04\n",
      "Epoch 2177/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.3128e-04 - val_loss: 9.0089e-04\n",
      "Epoch 2178/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.4565e-04 - val_loss: 8.7090e-04\n",
      "Epoch 2179/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.9775e-04 - val_loss: 9.2122e-04\n",
      "Epoch 2180/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.4851e-04 - val_loss: 8.1798e-04\n",
      "Epoch 2181/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.2706e-04 - val_loss: 7.4184e-04\n",
      "Epoch 2182/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.4386e-04 - val_loss: 8.5028e-04\n",
      "Epoch 2183/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.4544e-04 - val_loss: 8.7072e-04\n",
      "Epoch 2184/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.1928e-04 - val_loss: 8.2080e-04\n",
      "Epoch 2185/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.4175e-04 - val_loss: 8.1366e-04\n",
      "Epoch 2186/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 7.0611e-04\n",
      "Epoch 2187/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.1744e-04 - val_loss: 6.9611e-04\n",
      "Epoch 2188/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.0245e-04 - val_loss: 9.6997e-04\n",
      "Epoch 2189/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.9514e-04 - val_loss: 0.0011\n",
      "Epoch 2190/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 2191/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 5ms/step - loss: 9.6242e-04 - val_loss: 7.2747e-04\n",
      "Epoch 2192/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.7845e-04 - val_loss: 9.3844e-04\n",
      "Epoch 2193/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.2160e-04 - val_loss: 7.5452e-04\n",
      "Epoch 2194/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 7.8054e-04\n",
      "Epoch 2195/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.0160e-04 - val_loss: 7.1133e-04\n",
      "Epoch 2196/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.3848e-04 - val_loss: 8.3345e-04\n",
      "Epoch 2197/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.4341e-04 - val_loss: 0.0010\n",
      "Epoch 2198/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.9038e-04 - val_loss: 0.0011\n",
      "Epoch 2199/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.9420e-04 - val_loss: 0.0012\n",
      "Epoch 2200/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.4591e-04 - val_loss: 8.4873e-04\n",
      "Epoch 2201/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.6401e-04 - val_loss: 7.5474e-04\n",
      "Epoch 2202/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.9265e-04 - val_loss: 7.4434e-04\n",
      "Epoch 2203/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.2967e-04 - val_loss: 8.7891e-04\n",
      "Epoch 2204/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 2205/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 9.9382e-04\n",
      "Epoch 2206/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.2389e-04 - val_loss: 9.5594e-04\n",
      "Epoch 2207/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.7199e-04 - val_loss: 0.0014\n",
      "Epoch 2208/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.4871e-04 - val_loss: 0.0012\n",
      "Epoch 2209/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 2210/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.4164e-04 - val_loss: 9.0375e-04\n",
      "Epoch 2211/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 8.7020e-04 - val_loss: 7.0006e-04\n",
      "Epoch 2212/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.5721e-04 - val_loss: 7.2803e-04\n",
      "Epoch 2213/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9.0385e-04 - val_loss: 8.3066e-04\n",
      "Epoch 2214/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.9052e-04 - val_loss: 9.5758e-04\n",
      "Epoch 2215/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.2345e-04 - val_loss: 6.7433e-04\n",
      "Epoch 2216/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 8.5888e-04 - val_loss: 7.4406e-04\n",
      "Epoch 2217/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.8385e-04 - val_loss: 8.5235e-04\n",
      "Epoch 2218/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.4564e-04 - val_loss: 0.0010\n",
      "Epoch 2219/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9.1459e-04 - val_loss: 7.0603e-04\n",
      "Epoch 2220/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.2822e-04 - val_loss: 7.8737e-04\n",
      "Epoch 2221/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.6334e-04 - val_loss: 7.3744e-04\n",
      "Epoch 2222/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.6713e-04 - val_loss: 7.4194e-04\n",
      "Epoch 2223/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.3346e-04 - val_loss: 0.0015\n",
      "Epoch 2224/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 2225/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 9.9763e-04\n",
      "Epoch 2226/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 8.1362e-04\n",
      "Epoch 2227/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.2565e-04 - val_loss: 9.8254e-04\n",
      "Epoch 2228/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 8.3604e-04\n",
      "Epoch 2229/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.9261e-04 - val_loss: 7.5648e-04\n",
      "Epoch 2230/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.8986e-04 - val_loss: 7.8500e-04\n",
      "Epoch 2231/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.7684e-04 - val_loss: 9.5836e-04\n",
      "Epoch 2232/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.6275e-04 - val_loss: 0.0011\n",
      "Epoch 2233/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.9683e-04 - val_loss: 6.6725e-04\n",
      "Epoch 2234/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.5153e-04 - val_loss: 0.0010\n",
      "Epoch 2235/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 8.3656e-04\n",
      "Epoch 2236/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 8.7978e-04\n",
      "Epoch 2237/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.8696e-04 - val_loss: 8.7760e-04\n",
      "Epoch 2238/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.4010e-04 - val_loss: 7.5216e-04\n",
      "Epoch 2239/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.3172e-04 - val_loss: 9.7884e-04\n",
      "Epoch 2240/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 2241/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 2242/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.2879e-04 - val_loss: 7.8719e-04\n",
      "Epoch 2243/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.6281e-04 - val_loss: 8.3746e-04\n",
      "Epoch 2244/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.5111e-04 - val_loss: 8.1881e-04\n",
      "Epoch 2245/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.6516e-04 - val_loss: 7.8955e-04\n",
      "Epoch 2246/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.6787e-04 - val_loss: 0.0013\n",
      "Epoch 2247/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 9.7852e-04\n",
      "Epoch 2248/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.3738e-04 - val_loss: 0.0013\n",
      "Epoch 2249/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.6825e-04 - val_loss: 6.9619e-04\n",
      "Epoch 2250/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.5103e-04 - val_loss: 0.0010\n",
      "Epoch 2251/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 2252/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 2253/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 9.6027e-04\n",
      "Epoch 2254/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 9.8326e-04\n",
      "Epoch 2255/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 2256/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.8126e-04 - val_loss: 7.9697e-04\n",
      "Epoch 2257/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.6622e-04 - val_loss: 7.6098e-04\n",
      "Epoch 2258/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 2259/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.7421e-04 - val_loss: 0.0010\n",
      "Epoch 2260/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 8.1887e-04\n",
      "Epoch 2261/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9.4730e-04 - val_loss: 8.8838e-04\n",
      "Epoch 2262/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.6708e-04 - val_loss: 7.5537e-04\n",
      "Epoch 2263/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.4899e-04 - val_loss: 6.8031e-04\n",
      "Epoch 2264/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.5687e-04 - val_loss: 0.0013\n",
      "Epoch 2265/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 2266/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 7.4351e-04\n",
      "Epoch 2267/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.8607e-04 - val_loss: 9.0919e-04\n",
      "Epoch 2268/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.3261e-04 - val_loss: 7.6208e-04\n",
      "Epoch 2269/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.0374e-04 - val_loss: 0.0012\n",
      "Epoch 2270/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.3486e-04 - val_loss: 8.2823e-04\n",
      "Epoch 2271/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.7228e-04 - val_loss: 9.5354e-04\n",
      "Epoch 2272/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.0847e-04 - val_loss: 0.0013\n",
      "Epoch 2273/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 8.8905e-04\n",
      "Epoch 2274/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.8844e-04 - val_loss: 7.7626e-04\n",
      "Epoch 2275/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.0311e-04 - val_loss: 8.3688e-04\n",
      "Epoch 2276/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.5354e-04 - val_loss: 0.0011\n",
      "Epoch 2277/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.1419e-04 - val_loss: 9.1145e-04\n",
      "Epoch 2278/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.9607e-04 - val_loss: 8.1860e-04\n",
      "Epoch 2279/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.6571e-04 - val_loss: 9.5288e-04\n",
      "Epoch 2280/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.2658e-04 - val_loss: 8.6686e-04\n",
      "Epoch 2281/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 2282/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.3118e-04 - val_loss: 7.7518e-04\n",
      "Epoch 2283/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.0428e-04 - val_loss: 8.0709e-04\n",
      "Epoch 2284/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 2285/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 7.6352e-04\n",
      "Epoch 2286/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.9485e-04 - val_loss: 8.8590e-04\n",
      "Epoch 2287/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.0734e-04 - val_loss: 6.9169e-04\n",
      "Epoch 2288/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.7726e-04 - val_loss: 7.5372e-04\n",
      "Epoch 2289/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.6659e-04 - val_loss: 8.0566e-04\n",
      "Epoch 2290/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.3349e-04 - val_loss: 9.6156e-04\n",
      "Epoch 2291/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 2292/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.7777e-04 - val_loss: 8.3993e-04\n",
      "Epoch 2293/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.4782e-04 - val_loss: 0.0012\n",
      "Epoch 2294/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.6669e-04 - val_loss: 7.1361e-04\n",
      "Epoch 2295/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.8480e-04 - val_loss: 8.9009e-04\n",
      "Epoch 2296/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.7202e-04 - val_loss: 9.4652e-04\n",
      "Epoch 2297/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.4635e-04 - val_loss: 7.2094e-04\n",
      "Epoch 2298/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.2625e-04 - val_loss: 7.1371e-04\n",
      "Epoch 2299/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.3228e-04 - val_loss: 9.0326e-04\n",
      "Epoch 2300/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.6118e-04 - val_loss: 6.8211e-04\n",
      "Epoch 2301/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.5005e-04 - val_loss: 9.1406e-04\n",
      "Epoch 2302/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.8904e-04 - val_loss: 7.4952e-04\n",
      "Epoch 2303/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.9219e-04 - val_loss: 9.6433e-04\n",
      "Epoch 2304/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.9589e-04 - val_loss: 7.1463e-04\n",
      "Epoch 2305/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.6702e-04 - val_loss: 7.4547e-04\n",
      "Epoch 2306/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.8518e-04 - val_loss: 8.7364e-04\n",
      "Epoch 2307/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.5266e-04 - val_loss: 8.8584e-04\n",
      "Epoch 2308/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.2245e-04 - val_loss: 8.3187e-04\n",
      "Epoch 2309/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.6734e-04 - val_loss: 8.8088e-04\n",
      "Epoch 2310/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.6859e-04 - val_loss: 8.0337e-04\n",
      "Epoch 2311/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 2312/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 9.9477e-04\n",
      "Epoch 2313/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.5059e-04 - val_loss: 8.2781e-04\n",
      "Epoch 2314/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 8.7908e-04\n",
      "Epoch 2315/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.6787e-04 - val_loss: 0.0011\n",
      "Epoch 2316/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.0032e-04 - val_loss: 0.0010\n",
      "Epoch 2317/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.4230e-04 - val_loss: 7.3785e-04\n",
      "Epoch 2318/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.9912e-04 - val_loss: 0.0012\n",
      "Epoch 2319/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 2320/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.4926e-04 - val_loss: 0.0011\n",
      "Epoch 2321/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 2322/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.7233e-04 - val_loss: 9.1346e-04\n",
      "Epoch 2323/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 9.0725e-04\n",
      "Epoch 2324/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 7.5401e-04\n",
      "Epoch 2325/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.5193e-04 - val_loss: 9.5434e-04\n",
      "Epoch 2326/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.7254e-04 - val_loss: 7.7717e-04\n",
      "Epoch 2327/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.1530e-04 - val_loss: 6.7120e-04\n",
      "Epoch 2328/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.6960e-04 - val_loss: 8.9867e-04\n",
      "Epoch 2329/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.4058e-04 - val_loss: 0.0010\n",
      "Epoch 2330/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.0252e-04 - val_loss: 0.0010\n",
      "Epoch 2331/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.4973e-04 - val_loss: 7.9409e-04\n",
      "Epoch 2332/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.0631e-04 - val_loss: 9.5144e-04\n",
      "Epoch 2333/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.7102e-04 - val_loss: 8.4696e-04\n",
      "Epoch 2334/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.3457e-04 - val_loss: 9.0580e-04\n",
      "Epoch 2335/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.9147e-04 - val_loss: 0.0010\n",
      "Epoch 2336/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9.3919e-04 - val_loss: 9.5319e-04\n",
      "Epoch 2337/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.5735e-04 - val_loss: 8.3278e-04\n",
      "Epoch 2338/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.0616e-04 - val_loss: 8.0128e-04\n",
      "Epoch 2339/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.7697e-04 - val_loss: 7.3263e-04\n",
      "Epoch 2340/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.6162e-04 - val_loss: 8.7668e-04\n",
      "Epoch 2341/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 5ms/step - loss: 9.0854e-04 - val_loss: 0.0010\n",
      "Epoch 2342/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.3983e-04 - val_loss: 7.8313e-04\n",
      "Epoch 2343/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 2344/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.5418e-04 - val_loss: 7.4870e-04\n",
      "Epoch 2345/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.3861e-04 - val_loss: 8.3260e-04\n",
      "Epoch 2346/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.0859e-04 - val_loss: 8.1307e-04\n",
      "Epoch 2347/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.3847e-04 - val_loss: 8.7273e-04\n",
      "Epoch 2348/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 2349/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 2350/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 9.5205e-04\n",
      "Epoch 2351/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 2352/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 8.4866e-04\n",
      "Epoch 2353/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.7636e-04 - val_loss: 8.2283e-04\n",
      "Epoch 2354/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 9.1675e-04\n",
      "Epoch 2355/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.0713e-04 - val_loss: 0.0012\n",
      "Epoch 2356/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 2357/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 9.6666e-04\n",
      "Epoch 2358/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 2359/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.6441e-04 - val_loss: 9.7217e-04\n",
      "Epoch 2360/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.5443e-04 - val_loss: 8.6580e-04\n",
      "Epoch 2361/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.4350e-04 - val_loss: 7.6203e-04\n",
      "Epoch 2362/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 2363/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 7.9650e-04\n",
      "Epoch 2364/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.9011e-04 - val_loss: 7.7741e-04\n",
      "Epoch 2365/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.2889e-04 - val_loss: 8.4960e-04\n",
      "Epoch 2366/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.6085e-04 - val_loss: 8.8156e-04\n",
      "Epoch 2367/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.0966e-04 - val_loss: 7.8835e-04\n",
      "Epoch 2368/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 8.0072e-04 - val_loss: 9.9774e-04\n",
      "Epoch 2369/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.9414e-04 - val_loss: 9.6042e-04\n",
      "Epoch 2370/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 9.9603e-04\n",
      "Epoch 2371/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.8412e-04 - val_loss: 6.7621e-04\n",
      "Epoch 2372/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.7140e-04 - val_loss: 6.6229e-04\n",
      "Epoch 2373/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 8.7305e-04\n",
      "Epoch 2374/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.0308e-04 - val_loss: 8.9057e-04\n",
      "Epoch 2375/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.8616e-04 - val_loss: 7.2308e-04\n",
      "Epoch 2376/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.8448e-04 - val_loss: 8.3005e-04\n",
      "Epoch 2377/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.7570e-04 - val_loss: 8.0585e-04\n",
      "Epoch 2378/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 2379/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 7.5751e-04\n",
      "Epoch 2380/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.6918e-04 - val_loss: 7.0767e-04\n",
      "Epoch 2381/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.3356e-04 - val_loss: 0.0015\n",
      "Epoch 2382/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 2383/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 2384/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.7507e-04 - val_loss: 0.0012\n",
      "Epoch 2385/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 2386/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 9.0024e-04\n",
      "Epoch 2387/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.2139e-04 - val_loss: 8.2988e-04\n",
      "Epoch 2388/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.7413e-04 - val_loss: 0.0010\n",
      "Epoch 2389/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 9.0503e-04\n",
      "Epoch 2390/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.1988e-04 - val_loss: 6.7935e-04\n",
      "Epoch 2391/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.9846e-04 - val_loss: 0.0011\n",
      "Epoch 2392/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 7.7719e-04\n",
      "Epoch 2393/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.3029e-04 - val_loss: 7.2858e-04\n",
      "Epoch 2394/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.7661e-04 - val_loss: 9.5852e-04\n",
      "Epoch 2395/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.1460e-04 - val_loss: 8.2499e-04\n",
      "Epoch 2396/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.7235e-04 - val_loss: 7.9188e-04\n",
      "Epoch 2397/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.4042e-04 - val_loss: 8.2082e-04\n",
      "Epoch 2398/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.1302e-04 - val_loss: 8.1947e-04\n",
      "Epoch 2399/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.6613e-04 - val_loss: 0.0012\n",
      "Epoch 2400/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.8803e-04 - val_loss: 7.7151e-04\n",
      "Epoch 2401/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.9248e-04 - val_loss: 0.0012\n",
      "Epoch 2402/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.2399e-04 - val_loss: 8.6529e-04\n",
      "Epoch 2403/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.6090e-04 - val_loss: 8.9745e-04\n",
      "Epoch 2404/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.3779e-04 - val_loss: 9.4136e-04\n",
      "Epoch 2405/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 7.4583e-04\n",
      "Epoch 2406/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.5270e-04 - val_loss: 0.0012\n",
      "Epoch 2407/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.4634e-04 - val_loss: 8.4435e-04\n",
      "Epoch 2408/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.1315e-04 - val_loss: 8.3052e-04\n",
      "Epoch 2409/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.4410e-04 - val_loss: 9.2862e-04\n",
      "Epoch 2410/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.5151e-04 - val_loss: 8.5843e-04\n",
      "Epoch 2411/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.9247e-04 - val_loss: 7.4834e-04\n",
      "Epoch 2412/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.2120e-04 - val_loss: 0.0012\n",
      "Epoch 2413/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 7.5885e-04\n",
      "Epoch 2414/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.3881e-04 - val_loss: 7.3823e-04\n",
      "Epoch 2415/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.1893e-04 - val_loss: 7.7135e-04\n",
      "Epoch 2416/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 5ms/step - loss: 7.8296e-04 - val_loss: 0.0010\n",
      "Epoch 2417/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.8859e-04 - val_loss: 8.7913e-04\n",
      "Epoch 2418/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.8787e-04 - val_loss: 7.2704e-04\n",
      "Epoch 2419/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.1249e-04 - val_loss: 8.2444e-04\n",
      "Epoch 2420/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.9888e-04 - val_loss: 7.1229e-04\n",
      "Epoch 2421/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.0202e-04 - val_loss: 0.0010\n",
      "Epoch 2422/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 9.2833e-04\n",
      "Epoch 2423/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.5459e-04 - val_loss: 7.5561e-04\n",
      "Epoch 2424/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.8737e-04 - val_loss: 8.3605e-04\n",
      "Epoch 2425/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.9923e-04 - val_loss: 8.3857e-04\n",
      "Epoch 2426/4000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 9.2148e-04 - val_loss: 9.0669e-04\n",
      "Epoch 2427/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.9941e-04 - val_loss: 0.0013\n",
      "Epoch 2428/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.7560e-04 - val_loss: 8.7795e-04\n",
      "Epoch 2429/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.7463e-04 - val_loss: 7.4333e-04\n",
      "Epoch 2430/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.6449e-04 - val_loss: 7.3897e-04\n",
      "Epoch 2431/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.8567e-04 - val_loss: 7.8968e-04\n",
      "Epoch 2432/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.3204e-04 - val_loss: 7.6414e-04\n",
      "Epoch 2433/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.9031e-04 - val_loss: 9.1188e-04\n",
      "Epoch 2434/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.0829e-04 - val_loss: 8.0362e-04\n",
      "Epoch 2435/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.3293e-04 - val_loss: 9.1324e-04\n",
      "Epoch 2436/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.5449e-04 - val_loss: 9.6961e-04\n",
      "Epoch 2437/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.4401e-04 - val_loss: 6.8122e-04\n",
      "Epoch 2438/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.2657e-04 - val_loss: 7.3158e-04\n",
      "Epoch 2439/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.5400e-04 - val_loss: 8.0178e-04\n",
      "Epoch 2440/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.0763e-04 - val_loss: 8.6198e-04\n",
      "Epoch 2441/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.1525e-04 - val_loss: 0.0012\n",
      "Epoch 2442/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 8.5316e-04\n",
      "Epoch 2443/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.5279e-04 - val_loss: 8.4273e-04\n",
      "Epoch 2444/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.0962e-04 - val_loss: 8.0740e-04\n",
      "Epoch 2445/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.6338e-04 - val_loss: 0.0012\n",
      "Epoch 2446/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 9.7498e-04\n",
      "Epoch 2447/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.7505e-04 - val_loss: 8.4349e-04\n",
      "Epoch 2448/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.8538e-04 - val_loss: 7.3035e-04\n",
      "Epoch 2449/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.8457e-04 - val_loss: 8.3488e-04\n",
      "Epoch 2450/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.5682e-04 - val_loss: 6.5174e-04\n",
      "Epoch 2451/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.3544e-04 - val_loss: 7.6606e-04\n",
      "Epoch 2452/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.4411e-04 - val_loss: 8.3811e-04\n",
      "Epoch 2453/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.2624e-04 - val_loss: 6.8983e-04\n",
      "Epoch 2454/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.4112e-04 - val_loss: 0.0010\n",
      "Epoch 2455/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 2456/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 2457/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.6006e-04 - val_loss: 7.8003e-04\n",
      "Epoch 2458/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.6314e-04 - val_loss: 8.4677e-04\n",
      "Epoch 2459/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.3626e-04 - val_loss: 8.0611e-04\n",
      "Epoch 2460/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.7184e-04 - val_loss: 8.0384e-04\n",
      "Epoch 2461/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.8048e-04 - val_loss: 7.5420e-04\n",
      "Epoch 2462/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 2463/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 9.4027e-04\n",
      "Epoch 2464/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.9357e-04 - val_loss: 0.0012\n",
      "Epoch 2465/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 8.0129e-04\n",
      "Epoch 2466/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 8.8149e-04\n",
      "Epoch 2467/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.5812e-04 - val_loss: 7.6541e-04\n",
      "Epoch 2468/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.4899e-04 - val_loss: 8.9471e-04\n",
      "Epoch 2469/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.3529e-04 - val_loss: 0.0012\n",
      "Epoch 2470/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 9.1533e-04\n",
      "Epoch 2471/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.0221e-04 - val_loss: 8.6775e-04\n",
      "Epoch 2472/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.4468e-04 - val_loss: 0.0013\n",
      "Epoch 2473/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 9.2091e-04\n",
      "Epoch 2474/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.8618e-04 - val_loss: 0.0011\n",
      "Epoch 2475/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 9.0199e-04\n",
      "Epoch 2476/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.8698e-04 - val_loss: 8.4336e-04\n",
      "Epoch 2477/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.8654e-04 - val_loss: 7.5889e-04\n",
      "Epoch 2478/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.8294e-04 - val_loss: 9.3689e-04\n",
      "Epoch 2479/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9.5903e-04 - val_loss: 0.0013\n",
      "Epoch 2480/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 2481/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 7.2954e-04\n",
      "Epoch 2482/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 7.8624e-04 - val_loss: 8.3214e-04\n",
      "Epoch 2483/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.8589e-04 - val_loss: 7.5274e-04\n",
      "Epoch 2484/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 8.3069e-04 - val_loss: 7.9301e-04\n",
      "Epoch 2485/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 8.5166e-04\n",
      "Epoch 2486/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.9473e-04 - val_loss: 8.4167e-04\n",
      "Epoch 2487/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.4121e-04 - val_loss: 8.1570e-04\n",
      "Epoch 2488/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.7064e-04 - val_loss: 7.3726e-04\n",
      "Epoch 2489/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.6648e-04 - val_loss: 9.7133e-04\n",
      "Epoch 2490/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 9.4757e-04\n",
      "Epoch 2491/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 6ms/step - loss: 9.5333e-04 - val_loss: 0.0011\n",
      "Epoch 2492/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.8864e-04 - val_loss: 0.0011\n",
      "Epoch 2493/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.9586e-04 - val_loss: 6.4874e-04\n",
      "Epoch 2494/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.5266e-04 - val_loss: 9.8715e-04\n",
      "Epoch 2495/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.2542e-04 - val_loss: 8.0068e-04\n",
      "Epoch 2496/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.8541e-04 - val_loss: 9.2471e-04\n",
      "Epoch 2497/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.7706e-04 - val_loss: 0.0016\n",
      "Epoch 2498/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 9.0016e-04\n",
      "Epoch 2499/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.5252e-04 - val_loss: 8.5650e-04\n",
      "Epoch 2500/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 2501/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 2502/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 8.5791e-04\n",
      "Epoch 2503/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.0421e-04 - val_loss: 9.1216e-04\n",
      "Epoch 2504/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 8.3755e-04\n",
      "Epoch 2505/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.1649e-04 - val_loss: 9.3446e-04\n",
      "Epoch 2506/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.5693e-04 - val_loss: 8.5214e-04\n",
      "Epoch 2507/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.8190e-04 - val_loss: 8.5555e-04\n",
      "Epoch 2508/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 8.7512e-04\n",
      "Epoch 2509/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.7284e-04 - val_loss: 0.0011\n",
      "Epoch 2510/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.9797e-04 - val_loss: 7.9932e-04\n",
      "Epoch 2511/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.4634e-04 - val_loss: 0.0012\n",
      "Epoch 2512/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.0285e-04 - val_loss: 8.9052e-04\n",
      "Epoch 2513/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.3789e-04 - val_loss: 9.8584e-04\n",
      "Epoch 2514/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.7699e-04 - val_loss: 8.5284e-04\n",
      "Epoch 2515/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.0887e-04 - val_loss: 7.1751e-04\n",
      "Epoch 2516/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.9520e-04 - val_loss: 7.9180e-04\n",
      "Epoch 2517/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.0872e-04 - val_loss: 6.7724e-04\n",
      "Epoch 2518/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.5279e-04 - val_loss: 9.0846e-04\n",
      "Epoch 2519/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 2520/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.2846e-04 - val_loss: 7.4243e-04\n",
      "Epoch 2521/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.9354e-04 - val_loss: 8.2423e-04\n",
      "Epoch 2522/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.8379e-04 - val_loss: 9.0162e-04\n",
      "Epoch 2523/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.7474e-04 - val_loss: 8.0487e-04\n",
      "Epoch 2524/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.2004e-04 - val_loss: 6.9980e-04\n",
      "Epoch 2525/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.5428e-04 - val_loss: 8.2968e-04\n",
      "Epoch 2526/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 8.7506e-04 - val_loss: 7.7844e-04\n",
      "Epoch 2527/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.6549e-04 - val_loss: 9.7148e-04\n",
      "Epoch 2528/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 7.8889e-04\n",
      "Epoch 2529/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.3813e-04 - val_loss: 7.4184e-04\n",
      "Epoch 2530/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.5319e-04 - val_loss: 8.1891e-04\n",
      "Epoch 2531/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.7750e-04 - val_loss: 7.1165e-04\n",
      "Epoch 2532/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.2955e-04 - val_loss: 8.5445e-04\n",
      "Epoch 2533/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.0567e-04 - val_loss: 0.0011\n",
      "Epoch 2534/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.8887e-04 - val_loss: 8.4237e-04\n",
      "Epoch 2535/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.6624e-04 - val_loss: 7.6183e-04\n",
      "Epoch 2536/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.2896e-04 - val_loss: 9.4279e-04\n",
      "Epoch 2537/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.2745e-04 - val_loss: 8.1512e-04\n",
      "Epoch 2538/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.3928e-04 - val_loss: 7.2438e-04\n",
      "Epoch 2539/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.0556e-04 - val_loss: 7.8582e-04\n",
      "Epoch 2540/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.4921e-04 - val_loss: 8.4837e-04\n",
      "Epoch 2541/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.5849e-04 - val_loss: 0.0012\n",
      "Epoch 2542/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 9.3393e-04\n",
      "Epoch 2543/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.5741e-04 - val_loss: 7.9582e-04\n",
      "Epoch 2544/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 9.6700e-04\n",
      "Epoch 2545/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.2977e-04 - val_loss: 8.2868e-04\n",
      "Epoch 2546/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.4519e-04 - val_loss: 6.7385e-04\n",
      "Epoch 2547/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.7019e-04 - val_loss: 6.5415e-04\n",
      "Epoch 2548/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.2674e-04 - val_loss: 9.8228e-04\n",
      "Epoch 2549/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.6700e-04 - val_loss: 8.0912e-04\n",
      "Epoch 2550/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.2216e-04 - val_loss: 7.6703e-04\n",
      "Epoch 2551/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 2552/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.6660e-04 - val_loss: 9.4785e-04\n",
      "Epoch 2553/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.6276e-04 - val_loss: 7.5966e-04\n",
      "Epoch 2554/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.6351e-04 - val_loss: 0.0010\n",
      "Epoch 2555/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.1853e-04 - val_loss: 8.5458e-04\n",
      "Epoch 2556/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 9.6958e-04\n",
      "Epoch 2557/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.7242e-04 - val_loss: 8.2087e-04\n",
      "Epoch 2558/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.2007e-04 - val_loss: 7.4779e-04\n",
      "Epoch 2559/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.0467e-04 - val_loss: 9.2790e-04\n",
      "Epoch 2560/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.9327e-04 - val_loss: 0.0011\n",
      "Epoch 2561/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.5568e-04 - val_loss: 6.9441e-04\n",
      "Epoch 2562/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.2249e-04 - val_loss: 6.3778e-04\n",
      "Epoch 2563/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.4439e-04 - val_loss: 8.4708e-04\n",
      "Epoch 2564/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.1383e-04 - val_loss: 7.8636e-04\n",
      "Epoch 2565/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 9.2099e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2566/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.8888e-04 - val_loss: 7.6721e-04\n",
      "Epoch 2567/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.7929e-04 - val_loss: 8.5491e-04\n",
      "Epoch 2568/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.2194e-04 - val_loss: 0.0013\n",
      "Epoch 2569/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 7.1880e-04\n",
      "Epoch 2570/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.7998e-04 - val_loss: 7.7220e-04\n",
      "Epoch 2571/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.0523e-04 - val_loss: 6.7387e-04\n",
      "Epoch 2572/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.6546e-04 - val_loss: 7.0890e-04\n",
      "Epoch 2573/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.8326e-04 - val_loss: 8.2396e-04\n",
      "Epoch 2574/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 7.5580e-04 - val_loss: 6.7722e-04\n",
      "Epoch 2575/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.0822e-04 - val_loss: 7.6200e-04\n",
      "Epoch 2576/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.6180e-04 - val_loss: 9.1633e-04\n",
      "Epoch 2577/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 2578/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 9.9204e-04\n",
      "Epoch 2579/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.8147e-04 - val_loss: 7.9369e-04\n",
      "Epoch 2580/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9.5475e-04 - val_loss: 8.9082e-04\n",
      "Epoch 2581/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.3032e-04 - val_loss: 0.0011\n",
      "Epoch 2582/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9.1862e-04 - val_loss: 7.1829e-04\n",
      "Epoch 2583/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.6445e-04 - val_loss: 8.7248e-04\n",
      "Epoch 2584/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.6909e-04 - val_loss: 6.8707e-04\n",
      "Epoch 2585/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.8580e-04 - val_loss: 8.1170e-04\n",
      "Epoch 2586/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.1790e-04 - val_loss: 8.4928e-04\n",
      "Epoch 2587/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.2324e-04 - val_loss: 7.6017e-04\n",
      "Epoch 2588/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 2589/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 2590/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 7.7685e-04\n",
      "Epoch 2591/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 8.0417e-04\n",
      "Epoch 2592/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.5859e-04 - val_loss: 0.0011\n",
      "Epoch 2593/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.9162e-04 - val_loss: 0.0011\n",
      "Epoch 2594/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.7542e-04 - val_loss: 0.0014\n",
      "Epoch 2595/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 8.2350e-04\n",
      "Epoch 2596/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.8358e-04 - val_loss: 8.0250e-04\n",
      "Epoch 2597/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.0074e-04 - val_loss: 8.4893e-04\n",
      "Epoch 2598/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.2972e-04 - val_loss: 7.9494e-04\n",
      "Epoch 2599/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.4937e-04 - val_loss: 9.2170e-04\n",
      "Epoch 2600/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.4789e-04 - val_loss: 7.0307e-04\n",
      "Epoch 2601/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.1380e-04 - val_loss: 8.5816e-04\n",
      "Epoch 2602/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.0640e-04 - val_loss: 8.1365e-04\n",
      "Epoch 2603/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.6854e-04 - val_loss: 9.4800e-04\n",
      "Epoch 2604/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.6603e-04 - val_loss: 0.0011\n",
      "Epoch 2605/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 8.2209e-04\n",
      "Epoch 2606/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.3527e-04 - val_loss: 8.7160e-04\n",
      "Epoch 2607/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.8570e-04 - val_loss: 0.0012\n",
      "Epoch 2608/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 2609/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 9.4106e-04\n",
      "Epoch 2610/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.3664e-04 - val_loss: 9.0803e-04\n",
      "Epoch 2611/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.3592e-04 - val_loss: 7.8629e-04\n",
      "Epoch 2612/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.6964e-04 - val_loss: 7.5266e-04\n",
      "Epoch 2613/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.7053e-04 - val_loss: 7.0253e-04\n",
      "Epoch 2614/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.5782e-04 - val_loss: 7.7478e-04\n",
      "Epoch 2615/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.8249e-04 - val_loss: 7.4206e-04\n",
      "Epoch 2616/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.4841e-04 - val_loss: 6.7549e-04\n",
      "Epoch 2617/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.3718e-04 - val_loss: 0.0013\n",
      "Epoch 2618/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.5711e-04 - val_loss: 7.5307e-04\n",
      "Epoch 2619/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.4227e-04 - val_loss: 6.6418e-04\n",
      "Epoch 2620/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.4203e-04 - val_loss: 7.9083e-04\n",
      "Epoch 2621/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.8434e-04 - val_loss: 7.9026e-04\n",
      "Epoch 2622/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 2623/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.1340e-04 - val_loss: 7.1080e-04\n",
      "Epoch 2624/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.7450e-04 - val_loss: 8.6250e-04\n",
      "Epoch 2625/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.5706e-04 - val_loss: 8.0352e-04\n",
      "Epoch 2626/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.8798e-04 - val_loss: 6.6411e-04\n",
      "Epoch 2627/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.5745e-04 - val_loss: 8.4882e-04\n",
      "Epoch 2628/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.8864e-04 - val_loss: 7.8369e-04\n",
      "Epoch 2629/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.5043e-04 - val_loss: 7.5154e-04\n",
      "Epoch 2630/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.7297e-04 - val_loss: 7.3305e-04\n",
      "Epoch 2631/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.7430e-04 - val_loss: 8.2271e-04\n",
      "Epoch 2632/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.8455e-04 - val_loss: 7.1092e-04\n",
      "Epoch 2633/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.7049e-04 - val_loss: 7.3451e-04\n",
      "Epoch 2634/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.7583e-04 - val_loss: 7.1021e-04\n",
      "Epoch 2635/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.2425e-04 - val_loss: 7.6742e-04\n",
      "Epoch 2636/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.1225e-04 - val_loss: 9.3037e-04\n",
      "Epoch 2637/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.6794e-04 - val_loss: 9.2845e-04\n",
      "Epoch 2638/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 2639/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 7.6868e-04\n",
      "Epoch 2640/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 8.9820e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2641/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.8010e-04 - val_loss: 6.8736e-04\n",
      "Epoch 2642/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.6754e-04 - val_loss: 7.3428e-04\n",
      "Epoch 2643/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.7045e-04 - val_loss: 8.0432e-04\n",
      "Epoch 2644/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.8828e-04 - val_loss: 7.4404e-04\n",
      "Epoch 2645/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.1903e-04 - val_loss: 8.8964e-04\n",
      "Epoch 2646/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.9774e-04 - val_loss: 9.2591e-04\n",
      "Epoch 2647/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 7.5797e-04\n",
      "Epoch 2648/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.5081e-04 - val_loss: 0.0012\n",
      "Epoch 2649/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 2650/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 8.1697e-04\n",
      "Epoch 2651/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.5832e-04 - val_loss: 6.6471e-04\n",
      "Epoch 2652/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.6727e-04 - val_loss: 6.6508e-04\n",
      "Epoch 2653/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.6576e-04 - val_loss: 8.1293e-04\n",
      "Epoch 2654/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.5510e-04 - val_loss: 6.3774e-04\n",
      "Epoch 2655/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.0699e-04 - val_loss: 8.3397e-04\n",
      "Epoch 2656/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.3240e-04 - val_loss: 8.5112e-04\n",
      "Epoch 2657/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.2076e-04 - val_loss: 8.8071e-04\n",
      "Epoch 2658/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.6785e-04 - val_loss: 8.0534e-04\n",
      "Epoch 2659/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.3114e-04 - val_loss: 7.0854e-04\n",
      "Epoch 2660/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.6702e-04 - val_loss: 9.6028e-04\n",
      "Epoch 2661/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.8135e-04 - val_loss: 6.8346e-04\n",
      "Epoch 2662/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.5252e-04 - val_loss: 6.8227e-04\n",
      "Epoch 2663/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.5131e-04 - val_loss: 7.7462e-04\n",
      "Epoch 2664/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.8297e-04 - val_loss: 8.4130e-04\n",
      "Epoch 2665/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.4385e-04 - val_loss: 6.8887e-04\n",
      "Epoch 2666/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.4083e-04 - val_loss: 6.6231e-04\n",
      "Epoch 2667/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.3895e-04 - val_loss: 7.4231e-04\n",
      "Epoch 2668/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.1632e-04 - val_loss: 7.3263e-04\n",
      "Epoch 2669/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.5471e-04 - val_loss: 8.8666e-04\n",
      "Epoch 2670/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.2396e-04 - val_loss: 8.8363e-04\n",
      "Epoch 2671/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.6065e-04 - val_loss: 7.0065e-04\n",
      "Epoch 2672/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.4078e-04 - val_loss: 7.2983e-04\n",
      "Epoch 2673/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.5303e-04 - val_loss: 8.0275e-04\n",
      "Epoch 2674/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.7130e-04 - val_loss: 9.5152e-04\n",
      "Epoch 2675/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 8.9213e-04 - val_loss: 6.9415e-04\n",
      "Epoch 2676/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.6760e-04 - val_loss: 8.4131e-04\n",
      "Epoch 2677/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.8314e-04 - val_loss: 7.5357e-04\n",
      "Epoch 2678/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.4877e-04 - val_loss: 9.4739e-04\n",
      "Epoch 2679/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.3906e-04 - val_loss: 7.6470e-04\n",
      "Epoch 2680/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.6974e-04 - val_loss: 6.7657e-04\n",
      "Epoch 2681/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.5750e-04 - val_loss: 0.0011\n",
      "Epoch 2682/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 8.7280e-04\n",
      "Epoch 2683/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.8342e-04 - val_loss: 0.0011\n",
      "Epoch 2684/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.8283e-04 - val_loss: 9.3028e-04\n",
      "Epoch 2685/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.4697e-04 - val_loss: 7.9869e-04\n",
      "Epoch 2686/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.2104e-04 - val_loss: 0.0010\n",
      "Epoch 2687/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.1594e-04 - val_loss: 0.0010\n",
      "Epoch 2688/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.2899e-04 - val_loss: 7.5922e-04\n",
      "Epoch 2689/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.9071e-04 - val_loss: 9.0544e-04\n",
      "Epoch 2690/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 2691/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.6952e-04 - val_loss: 0.0011\n",
      "Epoch 2692/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.9843e-04 - val_loss: 8.0782e-04\n",
      "Epoch 2693/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.9137e-04 - val_loss: 8.5817e-04\n",
      "Epoch 2694/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.7658e-04 - val_loss: 9.2892e-04\n",
      "Epoch 2695/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.7024e-04 - val_loss: 7.3208e-04\n",
      "Epoch 2696/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.2848e-04 - val_loss: 7.7640e-04\n",
      "Epoch 2697/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.4140e-04 - val_loss: 9.6786e-04\n",
      "Epoch 2698/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.3346e-04 - val_loss: 0.0012\n",
      "Epoch 2699/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.5766e-04 - val_loss: 8.0715e-04\n",
      "Epoch 2700/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.9949e-04 - val_loss: 9.9914e-04\n",
      "Epoch 2701/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.5321e-04 - val_loss: 8.7037e-04\n",
      "Epoch 2702/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.9869e-04 - val_loss: 6.4955e-04\n",
      "Epoch 2703/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.5872e-04 - val_loss: 8.7714e-04\n",
      "Epoch 2704/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.1309e-04 - val_loss: 7.2455e-04\n",
      "Epoch 2705/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.5412e-04 - val_loss: 7.6016e-04\n",
      "Epoch 2706/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.9183e-04 - val_loss: 8.4385e-04\n",
      "Epoch 2707/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9.4481e-04 - val_loss: 8.1886e-04\n",
      "Epoch 2708/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.0990e-04 - val_loss: 8.5103e-04\n",
      "Epoch 2709/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.3258e-04 - val_loss: 8.3224e-04\n",
      "Epoch 2710/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.7642e-04 - val_loss: 9.0847e-04\n",
      "Epoch 2711/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 8.6200e-04 - val_loss: 0.0010\n",
      "Epoch 2712/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.6922e-04 - val_loss: 6.2898e-04\n",
      "Epoch 2713/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.9181e-04 - val_loss: 9.3936e-04\n",
      "Epoch 2714/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.5335e-04 - val_loss: 6.5595e-04\n",
      "Epoch 2715/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 6ms/step - loss: 8.4404e-04 - val_loss: 7.5464e-04\n",
      "Epoch 2716/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.2484e-04 - val_loss: 7.9706e-04\n",
      "Epoch 2717/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.8790e-04 - val_loss: 9.8423e-04\n",
      "Epoch 2718/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.4356e-04 - val_loss: 8.6567e-04\n",
      "Epoch 2719/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.3345e-04 - val_loss: 9.0076e-04\n",
      "Epoch 2720/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.9147e-04 - val_loss: 6.5037e-04\n",
      "Epoch 2721/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.8027e-04 - val_loss: 7.5232e-04\n",
      "Epoch 2722/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.4625e-04 - val_loss: 7.8241e-04\n",
      "Epoch 2723/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.2041e-04 - val_loss: 9.2839e-04\n",
      "Epoch 2724/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.6425e-04 - val_loss: 0.0010\n",
      "Epoch 2725/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.6584e-04 - val_loss: 0.0010\n",
      "Epoch 2726/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 9.1350e-04\n",
      "Epoch 2727/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 8.0026e-04\n",
      "Epoch 2728/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 2729/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 8.8571e-04\n",
      "Epoch 2730/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.1669e-04 - val_loss: 7.0724e-04\n",
      "Epoch 2731/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.5951e-04 - val_loss: 7.3703e-04\n",
      "Epoch 2732/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.8259e-04 - val_loss: 8.0494e-04\n",
      "Epoch 2733/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.3983e-04 - val_loss: 7.0605e-04\n",
      "Epoch 2734/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.5425e-04 - val_loss: 8.9674e-04\n",
      "Epoch 2735/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.9800e-04 - val_loss: 8.7246e-04\n",
      "Epoch 2736/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 9.3598e-04\n",
      "Epoch 2737/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 7.6409e-04\n",
      "Epoch 2738/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.1337e-04 - val_loss: 8.1173e-04\n",
      "Epoch 2739/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.6466e-04 - val_loss: 8.8144e-04\n",
      "Epoch 2740/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.0356e-04 - val_loss: 8.5477e-04\n",
      "Epoch 2741/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 2742/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.0090e-04 - val_loss: 6.9303e-04\n",
      "Epoch 2743/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 2744/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 2745/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 7.6951e-04\n",
      "Epoch 2746/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.3110e-04 - val_loss: 9.0636e-04\n",
      "Epoch 2747/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.8210e-04 - val_loss: 9.3280e-04\n",
      "Epoch 2748/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.5654e-04 - val_loss: 6.9727e-04\n",
      "Epoch 2749/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.1100e-04 - val_loss: 0.0010\n",
      "Epoch 2750/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.4378e-04 - val_loss: 8.8100e-04\n",
      "Epoch 2751/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.8576e-04 - val_loss: 8.8376e-04\n",
      "Epoch 2752/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.8993e-04 - val_loss: 7.9786e-04\n",
      "Epoch 2753/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.5052e-04 - val_loss: 6.5895e-04\n",
      "Epoch 2754/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.6940e-04 - val_loss: 8.1664e-04\n",
      "Epoch 2755/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.6201e-04 - val_loss: 8.1391e-04\n",
      "Epoch 2756/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.0324e-04 - val_loss: 0.0010\n",
      "Epoch 2757/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.5333e-04 - val_loss: 8.8378e-04\n",
      "Epoch 2758/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.2424e-04 - val_loss: 7.7722e-04\n",
      "Epoch 2759/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.4989e-04 - val_loss: 6.8159e-04\n",
      "Epoch 2760/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.1660e-04 - val_loss: 6.5091e-04\n",
      "Epoch 2761/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.9879e-04 - val_loss: 9.3465e-04\n",
      "Epoch 2762/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.4507e-04 - val_loss: 7.3344e-04\n",
      "Epoch 2763/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.1962e-04 - val_loss: 7.7037e-04\n",
      "Epoch 2764/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.5515e-04 - val_loss: 7.3526e-04\n",
      "Epoch 2765/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.3138e-04 - val_loss: 7.0281e-04\n",
      "Epoch 2766/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.4503e-04 - val_loss: 0.0012\n",
      "Epoch 2767/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.1719e-04 - val_loss: 7.6601e-04\n",
      "Epoch 2768/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.8764e-04 - val_loss: 7.9933e-04\n",
      "Epoch 2769/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.1195e-04 - val_loss: 7.7508e-04\n",
      "Epoch 2770/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.9361e-04 - val_loss: 9.9206e-04\n",
      "Epoch 2771/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 8.0641e-04\n",
      "Epoch 2772/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.4591e-04 - val_loss: 9.6758e-04\n",
      "Epoch 2773/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.9917e-04 - val_loss: 6.3119e-04\n",
      "Epoch 2774/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.9887e-04 - val_loss: 5.8108e-04\n",
      "Epoch 2775/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.4155e-04 - val_loss: 6.9763e-04\n",
      "Epoch 2776/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.1780e-04 - val_loss: 8.7097e-04\n",
      "Epoch 2777/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 9.5622e-04\n",
      "Epoch 2778/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.4868e-04 - val_loss: 6.9995e-04\n",
      "Epoch 2779/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.2896e-04 - val_loss: 7.0078e-04\n",
      "Epoch 2780/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.5725e-04 - val_loss: 7.6445e-04\n",
      "Epoch 2781/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.8840e-04 - val_loss: 7.9642e-04\n",
      "Epoch 2782/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 2783/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.8154e-04 - val_loss: 9.0775e-04\n",
      "Epoch 2784/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.9463e-04 - val_loss: 7.1623e-04\n",
      "Epoch 2785/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.3115e-04 - val_loss: 8.3742e-04\n",
      "Epoch 2786/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.5900e-04 - val_loss: 8.5827e-04\n",
      "Epoch 2787/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.2408e-04 - val_loss: 7.4997e-04\n",
      "Epoch 2788/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.6946e-04 - val_loss: 6.8513e-04\n",
      "Epoch 2789/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.4506e-04 - val_loss: 7.6080e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2790/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.8918e-04 - val_loss: 0.0010\n",
      "Epoch 2791/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9.4825e-04 - val_loss: 8.3733e-04\n",
      "Epoch 2792/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.4634e-04 - val_loss: 8.8011e-04\n",
      "Epoch 2793/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.5528e-04 - val_loss: 7.1827e-04\n",
      "Epoch 2794/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.7155e-04 - val_loss: 8.8053e-04\n",
      "Epoch 2795/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.4204e-04 - val_loss: 6.9434e-04\n",
      "Epoch 2796/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.2371e-04 - val_loss: 7.4446e-04\n",
      "Epoch 2797/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.6730e-04 - val_loss: 6.6268e-04\n",
      "Epoch 2798/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.0505e-04 - val_loss: 7.6754e-04\n",
      "Epoch 2799/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.9017e-04 - val_loss: 7.9039e-04\n",
      "Epoch 2800/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.0335e-04 - val_loss: 6.8576e-04\n",
      "Epoch 2801/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.8666e-04 - val_loss: 8.6736e-04\n",
      "Epoch 2802/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 2803/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 8.8572e-04\n",
      "Epoch 2804/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.3115e-04 - val_loss: 8.7996e-04\n",
      "Epoch 2805/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.2249e-04 - val_loss: 8.9180e-04\n",
      "Epoch 2806/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.3663e-04 - val_loss: 0.0011\n",
      "Epoch 2807/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 7.0869e-04\n",
      "Epoch 2808/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.1446e-04 - val_loss: 7.1780e-04\n",
      "Epoch 2809/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.1934e-04 - val_loss: 7.8275e-04\n",
      "Epoch 2810/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.5390e-04 - val_loss: 8.0133e-04\n",
      "Epoch 2811/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.1556e-04 - val_loss: 7.6800e-04\n",
      "Epoch 2812/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.4563e-04 - val_loss: 7.9427e-04\n",
      "Epoch 2813/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.4740e-04 - val_loss: 8.6194e-04\n",
      "Epoch 2814/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.9153e-04 - val_loss: 8.2882e-04\n",
      "Epoch 2815/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.0272e-04 - val_loss: 8.7511e-04\n",
      "Epoch 2816/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.1452e-04 - val_loss: 8.0423e-04\n",
      "Epoch 2817/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.9677e-04 - val_loss: 0.0014\n",
      "Epoch 2818/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 8.8310e-04\n",
      "Epoch 2819/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.7989e-04 - val_loss: 9.8253e-04\n",
      "Epoch 2820/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.5163e-04 - val_loss: 7.8083e-04\n",
      "Epoch 2821/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.3414e-04 - val_loss: 7.9556e-04\n",
      "Epoch 2822/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.8318e-04 - val_loss: 7.8098e-04\n",
      "Epoch 2823/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.3452e-04 - val_loss: 7.1475e-04\n",
      "Epoch 2824/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.8541e-04 - val_loss: 0.0010\n",
      "Epoch 2825/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.5999e-04 - val_loss: 0.0011\n",
      "Epoch 2826/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.8471e-04 - val_loss: 7.8857e-04\n",
      "Epoch 2827/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 9.2693e-04\n",
      "Epoch 2828/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.2387e-04 - val_loss: 0.0011\n",
      "Epoch 2829/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.6765e-04 - val_loss: 8.4783e-04\n",
      "Epoch 2830/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.8773e-04 - val_loss: 7.4287e-04\n",
      "Epoch 2831/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.5616e-04 - val_loss: 7.8416e-04\n",
      "Epoch 2832/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.8131e-04 - val_loss: 7.7042e-04\n",
      "Epoch 2833/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.4043e-04 - val_loss: 7.5852e-04\n",
      "Epoch 2834/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.9705e-04 - val_loss: 7.4557e-04\n",
      "Epoch 2835/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.1006e-04 - val_loss: 0.0017\n",
      "Epoch 2836/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 7.1326e-04\n",
      "Epoch 2837/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.4678e-04 - val_loss: 6.9984e-04\n",
      "Epoch 2838/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.2351e-04 - val_loss: 9.6668e-04\n",
      "Epoch 2839/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.7724e-04 - val_loss: 8.6801e-04\n",
      "Epoch 2840/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.8154e-04 - val_loss: 9.9957e-04\n",
      "Epoch 2841/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.6465e-04 - val_loss: 8.0830e-04\n",
      "Epoch 2842/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.3958e-04 - val_loss: 8.4234e-04\n",
      "Epoch 2843/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.2489e-04 - val_loss: 8.1631e-04\n",
      "Epoch 2844/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.7170e-04 - val_loss: 0.0011\n",
      "Epoch 2845/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 2846/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.3429e-04 - val_loss: 7.1991e-04\n",
      "Epoch 2847/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.0713e-04 - val_loss: 0.0014\n",
      "Epoch 2848/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 9.8589e-04\n",
      "Epoch 2849/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.8412e-04 - val_loss: 7.9339e-04\n",
      "Epoch 2850/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.7286e-04 - val_loss: 8.0263e-04\n",
      "Epoch 2851/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.2795e-04 - val_loss: 9.8335e-04\n",
      "Epoch 2852/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.8172e-04 - val_loss: 7.1064e-04\n",
      "Epoch 2853/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.4577e-04 - val_loss: 0.0010\n",
      "Epoch 2854/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.6204e-04 - val_loss: 9.1479e-04\n",
      "Epoch 2855/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.0515e-04 - val_loss: 7.5765e-04\n",
      "Epoch 2856/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.7241e-04 - val_loss: 8.8456e-04\n",
      "Epoch 2857/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.5822e-04 - val_loss: 8.6541e-04\n",
      "Epoch 2858/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.6522e-04 - val_loss: 8.1600e-04\n",
      "Epoch 2859/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.4878e-04 - val_loss: 0.0012\n",
      "Epoch 2860/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.6839e-04 - val_loss: 9.8144e-04\n",
      "Epoch 2861/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.4316e-04 - val_loss: 9.9465e-04\n",
      "Epoch 2862/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 8.8831e-04 - val_loss: 8.4645e-04\n",
      "Epoch 2863/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.5843e-04 - val_loss: 6.7738e-04\n",
      "Epoch 2864/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 7ms/step - loss: 8.0947e-04 - val_loss: 9.6225e-04\n",
      "Epoch 2865/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.3899e-04 - val_loss: 7.6531e-04\n",
      "Epoch 2866/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.8239e-04 - val_loss: 8.0578e-04\n",
      "Epoch 2867/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.1798e-04 - val_loss: 8.4201e-04\n",
      "Epoch 2868/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.7986e-04 - val_loss: 7.2259e-04\n",
      "Epoch 2869/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.7143e-04 - val_loss: 9.0222e-04\n",
      "Epoch 2870/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.0224e-04 - val_loss: 6.2130e-04\n",
      "Epoch 2871/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.4788e-04 - val_loss: 8.7249e-04\n",
      "Epoch 2872/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.4719e-04 - val_loss: 8.5341e-04\n",
      "Epoch 2873/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.0427e-04 - val_loss: 9.3811e-04\n",
      "Epoch 2874/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.2732e-04 - val_loss: 8.2866e-04\n",
      "Epoch 2875/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.5988e-04 - val_loss: 0.0012\n",
      "Epoch 2876/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 9.2866e-04\n",
      "Epoch 2877/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.5797e-04 - val_loss: 7.6947e-04\n",
      "Epoch 2878/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.6732e-04 - val_loss: 7.7463e-04\n",
      "Epoch 2879/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.1258e-04 - val_loss: 8.2443e-04\n",
      "Epoch 2880/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.7483e-04 - val_loss: 7.0894e-04\n",
      "Epoch 2881/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 7.8127e-04\n",
      "Epoch 2882/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.2241e-04 - val_loss: 0.0010\n",
      "Epoch 2883/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.7438e-04 - val_loss: 6.6149e-04\n",
      "Epoch 2884/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.7273e-04 - val_loss: 7.8547e-04\n",
      "Epoch 2885/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.7345e-04 - val_loss: 9.9377e-04\n",
      "Epoch 2886/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.6928e-04 - val_loss: 7.2225e-04\n",
      "Epoch 2887/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.9119e-04 - val_loss: 0.0010\n",
      "Epoch 2888/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.9498e-04 - val_loss: 7.5878e-04\n",
      "Epoch 2889/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.0953e-04 - val_loss: 7.9180e-04\n",
      "Epoch 2890/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.0977e-04 - val_loss: 7.2910e-04\n",
      "Epoch 2891/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.3612e-04 - val_loss: 0.0012\n",
      "Epoch 2892/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.9084e-04 - val_loss: 0.0011\n",
      "Epoch 2893/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.8044e-04 - val_loss: 9.0683e-04\n",
      "Epoch 2894/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.9236e-04 - val_loss: 7.5978e-04\n",
      "Epoch 2895/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.3088e-04 - val_loss: 7.3041e-04\n",
      "Epoch 2896/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.9984e-04 - val_loss: 7.0201e-04\n",
      "Epoch 2897/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.6949e-04 - val_loss: 8.4885e-04\n",
      "Epoch 2898/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.5588e-04 - val_loss: 7.6224e-04\n",
      "Epoch 2899/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.8450e-04 - val_loss: 7.5276e-04\n",
      "Epoch 2900/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.2841e-04 - val_loss: 8.5034e-04\n",
      "Epoch 2901/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.7670e-04 - val_loss: 8.4279e-04\n",
      "Epoch 2902/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.3430e-04 - val_loss: 7.4153e-04\n",
      "Epoch 2903/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.6354e-04 - val_loss: 9.7046e-04\n",
      "Epoch 2904/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.5523e-04 - val_loss: 8.8648e-04\n",
      "Epoch 2905/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.6007e-04 - val_loss: 0.0010\n",
      "Epoch 2906/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.9307e-04 - val_loss: 7.9521e-04\n",
      "Epoch 2907/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.0520e-04 - val_loss: 0.0010\n",
      "Epoch 2908/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.6897e-04 - val_loss: 9.2166e-04\n",
      "Epoch 2909/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 8.2669e-04\n",
      "Epoch 2910/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.6276e-04 - val_loss: 0.0013\n",
      "Epoch 2911/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.9344e-04 - val_loss: 8.1038e-04\n",
      "Epoch 2912/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.5206e-04 - val_loss: 0.0011\n",
      "Epoch 2913/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 2914/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 2915/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.9193e-04 - val_loss: 9.0061e-04\n",
      "Epoch 2916/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.6176e-04 - val_loss: 8.1897e-04\n",
      "Epoch 2917/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.6728e-04 - val_loss: 0.0012\n",
      "Epoch 2918/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 8.2371e-04\n",
      "Epoch 2919/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.0193e-04 - val_loss: 9.1297e-04\n",
      "Epoch 2920/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.8501e-04 - val_loss: 0.0011\n",
      "Epoch 2921/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.1483e-04 - val_loss: 6.7282e-04\n",
      "Epoch 2922/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.1135e-04 - val_loss: 8.0626e-04\n",
      "Epoch 2923/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.8194e-04 - val_loss: 6.5218e-04\n",
      "Epoch 2924/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.6102e-04 - val_loss: 6.7343e-04\n",
      "Epoch 2925/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.8403e-04 - val_loss: 9.1378e-04\n",
      "Epoch 2926/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.7677e-04 - val_loss: 6.7521e-04\n",
      "Epoch 2927/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.8015e-04 - val_loss: 8.1473e-04\n",
      "Epoch 2928/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.0919e-04 - val_loss: 7.1879e-04\n",
      "Epoch 2929/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.9264e-04 - val_loss: 0.0011\n",
      "Epoch 2930/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 8.2696e-04\n",
      "Epoch 2931/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.5658e-04 - val_loss: 9.1119e-04\n",
      "Epoch 2932/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.5015e-04 - val_loss: 7.7052e-04\n",
      "Epoch 2933/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.7721e-04 - val_loss: 7.2055e-04\n",
      "Epoch 2934/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.6750e-04 - val_loss: 7.8123e-04\n",
      "Epoch 2935/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.3814e-04 - val_loss: 7.9415e-04\n",
      "Epoch 2936/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.2203e-04 - val_loss: 9.2951e-04\n",
      "Epoch 2937/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.1936e-04 - val_loss: 6.3562e-04\n",
      "Epoch 2938/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 5ms/step - loss: 6.9576e-04 - val_loss: 6.7962e-04\n",
      "Epoch 2939/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.7366e-04 - val_loss: 8.5846e-04\n",
      "Epoch 2940/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.8750e-04 - val_loss: 7.9453e-04\n",
      "Epoch 2941/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.8771e-04 - val_loss: 7.6347e-04\n",
      "Epoch 2942/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.4040e-04 - val_loss: 8.3401e-04\n",
      "Epoch 2943/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.6604e-04 - val_loss: 9.9988e-04\n",
      "Epoch 2944/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.7251e-04 - val_loss: 8.3497e-04\n",
      "Epoch 2945/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.3829e-04 - val_loss: 8.2486e-04\n",
      "Epoch 2946/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.2793e-04 - val_loss: 9.6525e-04\n",
      "Epoch 2947/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.8239e-04 - val_loss: 0.0011\n",
      "Epoch 2948/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.3955e-04 - val_loss: 8.3798e-04\n",
      "Epoch 2949/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.0362e-04 - val_loss: 6.8981e-04\n",
      "Epoch 2950/4000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 8.0422e-04 - val_loss: 8.6235e-04\n",
      "Epoch 2951/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.1710e-04 - val_loss: 8.6858e-04\n",
      "Epoch 2952/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.6025e-04 - val_loss: 8.0255e-04\n",
      "Epoch 2953/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.2136e-04 - val_loss: 8.0255e-04\n",
      "Epoch 2954/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.4476e-04 - val_loss: 9.3192e-04\n",
      "Epoch 2955/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 9.7643e-04\n",
      "Epoch 2956/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.3921e-04 - val_loss: 8.3528e-04\n",
      "Epoch 2957/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.9608e-04 - val_loss: 7.2165e-04\n",
      "Epoch 2958/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.7912e-04 - val_loss: 7.5936e-04\n",
      "Epoch 2959/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.4154e-04 - val_loss: 9.2532e-04\n",
      "Epoch 2960/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.2277e-04 - val_loss: 6.9808e-04\n",
      "Epoch 2961/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.9745e-04 - val_loss: 9.9240e-04\n",
      "Epoch 2962/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 2963/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.7272e-04 - val_loss: 6.9590e-04\n",
      "Epoch 2964/4000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9.2896e-04 - val_loss: 7.7134e-04\n",
      "Epoch 2965/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.8837e-04 - val_loss: 0.0011\n",
      "Epoch 2966/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 8.3038e-04\n",
      "Epoch 2967/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.8098e-04 - val_loss: 7.2708e-04\n",
      "Epoch 2968/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.0091e-04 - val_loss: 6.9064e-04\n",
      "Epoch 2969/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.4458e-04 - val_loss: 6.6925e-04\n",
      "Epoch 2970/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.4613e-04 - val_loss: 0.0011\n",
      "Epoch 2971/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9.5626e-04 - val_loss: 8.5128e-04\n",
      "Epoch 2972/4000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 9.4796e-04\n",
      "Epoch 2973/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 8.2188e-04 - val_loss: 6.5504e-04\n",
      "Epoch 2974/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9.1909e-04 - val_loss: 8.3364e-04\n",
      "Epoch 2975/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9.0713e-04 - val_loss: 7.5404e-04\n",
      "Epoch 2976/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.6458e-04 - val_loss: 8.0192e-04\n",
      "Epoch 2977/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.7488e-04 - val_loss: 0.0013\n",
      "Epoch 2978/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.3432e-04 - val_loss: 7.3176e-04\n",
      "Epoch 2979/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.3388e-04 - val_loss: 7.4167e-04\n",
      "Epoch 2980/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.1701e-04 - val_loss: 7.2182e-04\n",
      "Epoch 2981/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.7185e-04 - val_loss: 8.2629e-04\n",
      "Epoch 2982/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 8.9237e-04 - val_loss: 0.0012\n",
      "Epoch 2983/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9.2214e-04 - val_loss: 8.6615e-04\n",
      "Epoch 2984/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.2822e-04 - val_loss: 0.0011\n",
      "Epoch 2985/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9.4659e-04 - val_loss: 7.2324e-04\n",
      "Epoch 2986/4000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 8.2826e-04 - val_loss: 7.4601e-04\n",
      "Epoch 2987/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.1618e-04 - val_loss: 7.8369e-04\n",
      "Epoch 2988/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.1645e-04 - val_loss: 0.0012\n",
      "Epoch 2989/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 9.5036e-04\n",
      "Epoch 2990/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.4695e-04 - val_loss: 8.0993e-04\n",
      "Epoch 2991/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9.1718e-04 - val_loss: 9.3938e-04\n",
      "Epoch 2992/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.1818e-04 - val_loss: 7.5108e-04\n",
      "Epoch 2993/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.9613e-04 - val_loss: 0.0011\n",
      "Epoch 2994/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 9.1990e-04\n",
      "Epoch 2995/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 8.1252e-04 - val_loss: 7.8554e-04\n",
      "Epoch 2996/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 6.9787e-04 - val_loss: 6.3610e-04\n",
      "Epoch 2997/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.3251e-04 - val_loss: 7.2490e-04\n",
      "Epoch 2998/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.6570e-04 - val_loss: 7.4486e-04\n",
      "Epoch 2999/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.6495e-04 - val_loss: 6.6205e-04\n",
      "Epoch 3000/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.8041e-04 - val_loss: 8.4031e-04\n",
      "Epoch 3001/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.8986e-04 - val_loss: 6.4747e-04\n",
      "Epoch 3002/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.9030e-04 - val_loss: 7.0606e-04\n",
      "Epoch 3003/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.7096e-04 - val_loss: 8.2243e-04\n",
      "Epoch 3004/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.8863e-04 - val_loss: 6.9747e-04\n",
      "Epoch 3005/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.0280e-04 - val_loss: 9.7126e-04\n",
      "Epoch 3006/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.0670e-04 - val_loss: 7.8908e-04\n",
      "Epoch 3007/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.6452e-04 - val_loss: 7.5994e-04\n",
      "Epoch 3008/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.7459e-04 - val_loss: 7.2454e-04\n",
      "Epoch 3009/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.4255e-04 - val_loss: 0.0012\n",
      "Epoch 3010/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.6572e-04 - val_loss: 7.1798e-04\n",
      "Epoch 3011/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.3152e-04 - val_loss: 9.0703e-04\n",
      "Epoch 3012/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 6ms/step - loss: 8.7521e-04 - val_loss: 7.9974e-04\n",
      "Epoch 3013/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.8041e-04 - val_loss: 7.5496e-04\n",
      "Epoch 3014/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.0048e-04 - val_loss: 7.4915e-04\n",
      "Epoch 3015/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.9914e-04 - val_loss: 7.9027e-04\n",
      "Epoch 3016/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.8118e-04 - val_loss: 7.7782e-04\n",
      "Epoch 3017/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.3097e-04 - val_loss: 7.8082e-04\n",
      "Epoch 3018/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.0747e-04 - val_loss: 0.0010\n",
      "Epoch 3019/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.4885e-04 - val_loss: 8.7299e-04\n",
      "Epoch 3020/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.8545e-04 - val_loss: 7.9051e-04\n",
      "Epoch 3021/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.2663e-04 - val_loss: 8.8353e-04\n",
      "Epoch 3022/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.7586e-04 - val_loss: 6.5551e-04\n",
      "Epoch 3023/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.4153e-04 - val_loss: 8.0437e-04\n",
      "Epoch 3024/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.4273e-04 - val_loss: 9.2514e-04\n",
      "Epoch 3025/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.2390e-04 - val_loss: 0.0011\n",
      "Epoch 3026/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 3027/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.7019e-04 - val_loss: 8.1478e-04\n",
      "Epoch 3028/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.3591e-04 - val_loss: 8.0737e-04\n",
      "Epoch 3029/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.3451e-04 - val_loss: 8.3508e-04\n",
      "Epoch 3030/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 9.9789e-04\n",
      "Epoch 3031/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.1072e-04 - val_loss: 7.3604e-04\n",
      "Epoch 3032/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.9336e-04 - val_loss: 7.1223e-04\n",
      "Epoch 3033/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.1406e-04 - val_loss: 9.2270e-04\n",
      "Epoch 3034/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.2390e-04 - val_loss: 6.6520e-04\n",
      "Epoch 3035/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.8893e-04 - val_loss: 9.6431e-04\n",
      "Epoch 3036/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.6208e-04 - val_loss: 0.0011\n",
      "Epoch 3037/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.6170e-04 - val_loss: 7.8725e-04\n",
      "Epoch 3038/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.5349e-04 - val_loss: 9.3506e-04\n",
      "Epoch 3039/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.9577e-04 - val_loss: 7.8189e-04\n",
      "Epoch 3040/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.6745e-04 - val_loss: 6.5828e-04\n",
      "Epoch 3041/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.8359e-04 - val_loss: 7.7223e-04\n",
      "Epoch 3042/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.6939e-04 - val_loss: 7.4578e-04\n",
      "Epoch 3043/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.8243e-04 - val_loss: 0.0011\n",
      "Epoch 3044/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 8.4625e-04\n",
      "Epoch 3045/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.6706e-04 - val_loss: 8.1460e-04\n",
      "Epoch 3046/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.8086e-04 - val_loss: 7.6325e-04\n",
      "Epoch 3047/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.3807e-04 - val_loss: 8.4420e-04\n",
      "Epoch 3048/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.9460e-04 - val_loss: 0.0011\n",
      "Epoch 3049/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.6089e-04 - val_loss: 7.8823e-04\n",
      "Epoch 3050/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.1173e-04 - val_loss: 7.8804e-04\n",
      "Epoch 3051/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.3052e-04 - val_loss: 8.0373e-04\n",
      "Epoch 3052/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.0740e-04 - val_loss: 0.0011\n",
      "Epoch 3053/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.0993e-04 - val_loss: 7.1917e-04\n",
      "Epoch 3054/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.7358e-04 - val_loss: 7.9609e-04\n",
      "Epoch 3055/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.2411e-04 - val_loss: 8.1416e-04\n",
      "Epoch 3056/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.6606e-04 - val_loss: 6.7050e-04\n",
      "Epoch 3057/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.2741e-04 - val_loss: 7.6905e-04\n",
      "Epoch 3058/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.5930e-04 - val_loss: 8.9366e-04\n",
      "Epoch 3059/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.4176e-04 - val_loss: 7.6025e-04\n",
      "Epoch 3060/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.6458e-04 - val_loss: 7.9650e-04\n",
      "Epoch 3061/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.0006e-04 - val_loss: 7.3330e-04\n",
      "Epoch 3062/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 8.1281e-04 - val_loss: 7.3608e-04\n",
      "Epoch 3063/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.3570e-04 - val_loss: 7.7588e-04\n",
      "Epoch 3064/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.3183e-04 - val_loss: 8.2652e-04\n",
      "Epoch 3065/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.7010e-04 - val_loss: 8.6253e-04\n",
      "Epoch 3066/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.6950e-04 - val_loss: 8.1486e-04\n",
      "Epoch 3067/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.9084e-04 - val_loss: 8.3666e-04\n",
      "Epoch 3068/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.3715e-04 - val_loss: 6.0518e-04\n",
      "Epoch 3069/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.1905e-04 - val_loss: 7.7703e-04\n",
      "Epoch 3070/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.9727e-04 - val_loss: 8.3483e-04\n",
      "Epoch 3071/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.6978e-04 - val_loss: 8.6344e-04\n",
      "Epoch 3072/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.0023e-04 - val_loss: 9.2290e-04\n",
      "Epoch 3073/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.9031e-04 - val_loss: 7.6373e-04\n",
      "Epoch 3074/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.3238e-04 - val_loss: 6.0604e-04\n",
      "Epoch 3075/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.5878e-04 - val_loss: 6.9294e-04\n",
      "Epoch 3076/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.3050e-04 - val_loss: 7.8967e-04\n",
      "Epoch 3077/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.0443e-04 - val_loss: 9.7894e-04\n",
      "Epoch 3078/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.7750e-04 - val_loss: 8.6226e-04\n",
      "Epoch 3079/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.7590e-04 - val_loss: 8.9617e-04\n",
      "Epoch 3080/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 3081/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 8.3318e-04\n",
      "Epoch 3082/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.5402e-04 - val_loss: 6.6887e-04\n",
      "Epoch 3083/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.2544e-04 - val_loss: 7.0287e-04\n",
      "Epoch 3084/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.9313e-04 - val_loss: 0.0013\n",
      "Epoch 3085/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 7.2390e-04\n",
      "Epoch 3086/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 5ms/step - loss: 7.6497e-04 - val_loss: 9.8567e-04\n",
      "Epoch 3087/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.2740e-04 - val_loss: 0.0013\n",
      "Epoch 3088/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 3089/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.4281e-04 - val_loss: 0.0012\n",
      "Epoch 3090/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.5854e-04 - val_loss: 8.8825e-04\n",
      "Epoch 3091/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.9152e-04 - val_loss: 6.8120e-04\n",
      "Epoch 3092/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.3867e-04 - val_loss: 0.0010\n",
      "Epoch 3093/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.0636e-04 - val_loss: 7.6318e-04\n",
      "Epoch 3094/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.2938e-04 - val_loss: 8.2851e-04\n",
      "Epoch 3095/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 3096/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 7.3300e-04\n",
      "Epoch 3097/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.2616e-04 - val_loss: 8.4314e-04\n",
      "Epoch 3098/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.0162e-04 - val_loss: 7.2397e-04\n",
      "Epoch 3099/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.3438e-04 - val_loss: 0.0011\n",
      "Epoch 3100/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.2331e-04 - val_loss: 8.5418e-04\n",
      "Epoch 3101/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.6549e-04 - val_loss: 7.4632e-04\n",
      "Epoch 3102/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.6327e-04 - val_loss: 9.0851e-04\n",
      "Epoch 3103/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.6728e-04 - val_loss: 0.0017\n",
      "Epoch 3104/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 9.8926e-04\n",
      "Epoch 3105/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.7573e-04 - val_loss: 8.2327e-04\n",
      "Epoch 3106/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.6971e-04 - val_loss: 0.0011\n",
      "Epoch 3107/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.7164e-04 - val_loss: 9.8726e-04\n",
      "Epoch 3108/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.3870e-04 - val_loss: 9.6478e-04\n",
      "Epoch 3109/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.0121e-04 - val_loss: 8.0978e-04\n",
      "Epoch 3110/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.8883e-04 - val_loss: 8.7680e-04\n",
      "Epoch 3111/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.5736e-04 - val_loss: 7.8030e-04\n",
      "Epoch 3112/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.4492e-04 - val_loss: 6.5349e-04\n",
      "Epoch 3113/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.3406e-04 - val_loss: 7.5622e-04\n",
      "Epoch 3114/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.7722e-04 - val_loss: 7.1234e-04\n",
      "Epoch 3115/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.5471e-04 - val_loss: 7.5773e-04\n",
      "Epoch 3116/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.1521e-04 - val_loss: 7.1617e-04\n",
      "Epoch 3117/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.1747e-04 - val_loss: 8.3185e-04\n",
      "Epoch 3118/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.7724e-04 - val_loss: 6.9553e-04\n",
      "Epoch 3119/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.1916e-04 - val_loss: 7.7304e-04\n",
      "Epoch 3120/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.9147e-04 - val_loss: 0.0015\n",
      "Epoch 3121/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 9.1185e-04\n",
      "Epoch 3122/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 9.9870e-04\n",
      "Epoch 3123/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.8607e-04 - val_loss: 8.2446e-04\n",
      "Epoch 3124/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.0277e-04 - val_loss: 6.8557e-04\n",
      "Epoch 3125/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.2598e-04 - val_loss: 7.6577e-04\n",
      "Epoch 3126/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.5294e-04 - val_loss: 8.4522e-04\n",
      "Epoch 3127/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.5463e-04 - val_loss: 8.2142e-04\n",
      "Epoch 3128/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.2355e-04 - val_loss: 7.0091e-04\n",
      "Epoch 3129/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.7378e-04 - val_loss: 9.4972e-04\n",
      "Epoch 3130/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 9.4218e-04\n",
      "Epoch 3131/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.8112e-04 - val_loss: 8.2837e-04\n",
      "Epoch 3132/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.0189e-04 - val_loss: 6.9655e-04\n",
      "Epoch 3133/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.5261e-04 - val_loss: 6.5333e-04\n",
      "Epoch 3134/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.1178e-04 - val_loss: 0.0010\n",
      "Epoch 3135/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 3136/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.5309e-04 - val_loss: 9.2597e-04\n",
      "Epoch 3137/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.8525e-04 - val_loss: 8.8889e-04\n",
      "Epoch 3138/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.2569e-04 - val_loss: 0.0010\n",
      "Epoch 3139/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.7713e-04 - val_loss: 8.3843e-04\n",
      "Epoch 3140/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.4955e-04 - val_loss: 6.3195e-04\n",
      "Epoch 3141/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.1644e-04 - val_loss: 7.9582e-04\n",
      "Epoch 3142/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.9420e-04 - val_loss: 0.0010\n",
      "Epoch 3143/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.0631e-04 - val_loss: 9.2311e-04\n",
      "Epoch 3144/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.8297e-04 - val_loss: 8.0871e-04\n",
      "Epoch 3145/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.5381e-04 - val_loss: 8.7313e-04\n",
      "Epoch 3146/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.5973e-04 - val_loss: 7.7634e-04\n",
      "Epoch 3147/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.3723e-04 - val_loss: 7.5473e-04\n",
      "Epoch 3148/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 7.8050e-04 - val_loss: 6.5198e-04\n",
      "Epoch 3149/4000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 9.0133e-04 - val_loss: 0.0011\n",
      "Epoch 3150/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 9.7124e-04\n",
      "Epoch 3151/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.7107e-04 - val_loss: 8.4154e-04\n",
      "Epoch 3152/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.4240e-04 - val_loss: 8.4298e-04\n",
      "Epoch 3153/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.3283e-04 - val_loss: 0.0011\n",
      "Epoch 3154/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 9.9557e-04\n",
      "Epoch 3155/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.0259e-04 - val_loss: 9.4089e-04\n",
      "Epoch 3156/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.0802e-04 - val_loss: 9.8837e-04\n",
      "Epoch 3157/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.7652e-04 - val_loss: 8.0697e-04\n",
      "Epoch 3158/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.1985e-04 - val_loss: 0.0011\n",
      "Epoch 3159/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 3160/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.7293e-04 - val_loss: 9.2949e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3161/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.1148e-04 - val_loss: 8.7425e-04\n",
      "Epoch 3162/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 3163/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.3702e-04 - val_loss: 6.7437e-04\n",
      "Epoch 3164/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.1139e-04 - val_loss: 6.4000e-04\n",
      "Epoch 3165/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.3354e-04 - val_loss: 7.2835e-04\n",
      "Epoch 3166/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.6027e-04 - val_loss: 9.4925e-04\n",
      "Epoch 3167/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.0664e-04 - val_loss: 0.0011\n",
      "Epoch 3168/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.3533e-04 - val_loss: 9.4428e-04\n",
      "Epoch 3169/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.1494e-04 - val_loss: 8.6326e-04\n",
      "Epoch 3170/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.8430e-04 - val_loss: 7.1080e-04\n",
      "Epoch 3171/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 8.5817e-04 - val_loss: 7.7509e-04\n",
      "Epoch 3172/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.8432e-04 - val_loss: 6.4844e-04\n",
      "Epoch 3173/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.0182e-04 - val_loss: 9.6614e-04\n",
      "Epoch 3174/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.9634e-04 - val_loss: 6.7960e-04\n",
      "Epoch 3175/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.7806e-04 - val_loss: 6.8745e-04\n",
      "Epoch 3176/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.6501e-04 - val_loss: 6.9069e-04\n",
      "Epoch 3177/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.9831e-04 - val_loss: 7.7114e-04\n",
      "Epoch 3178/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.3254e-04 - val_loss: 8.6941e-04\n",
      "Epoch 3179/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.9482e-04 - val_loss: 8.5341e-04\n",
      "Epoch 3180/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.5296e-04 - val_loss: 7.1810e-04\n",
      "Epoch 3181/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.8150e-04 - val_loss: 8.4105e-04\n",
      "Epoch 3182/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.0294e-04 - val_loss: 7.7403e-04\n",
      "Epoch 3183/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.9117e-04 - val_loss: 8.2987e-04\n",
      "Epoch 3184/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.8737e-04 - val_loss: 8.7436e-04\n",
      "Epoch 3185/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.0905e-04 - val_loss: 8.7046e-04\n",
      "Epoch 3186/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.0917e-04 - val_loss: 7.2740e-04\n",
      "Epoch 3187/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.7615e-04 - val_loss: 8.4460e-04\n",
      "Epoch 3188/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9.2885e-04 - val_loss: 8.1284e-04\n",
      "Epoch 3189/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.8138e-04 - val_loss: 6.5984e-04\n",
      "Epoch 3190/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.6621e-04 - val_loss: 9.8108e-04\n",
      "Epoch 3191/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.4582e-04 - val_loss: 7.9639e-04\n",
      "Epoch 3192/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.8589e-04 - val_loss: 0.0015\n",
      "Epoch 3193/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 9.2717e-04\n",
      "Epoch 3194/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 8.3804e-04\n",
      "Epoch 3195/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.1735e-04 - val_loss: 7.0524e-04\n",
      "Epoch 3196/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.9391e-04 - val_loss: 7.6087e-04\n",
      "Epoch 3197/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.3615e-04 - val_loss: 0.0012\n",
      "Epoch 3198/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.4349e-04 - val_loss: 8.1631e-04\n",
      "Epoch 3199/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.3391e-04 - val_loss: 6.9538e-04\n",
      "Epoch 3200/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.9770e-04 - val_loss: 6.9085e-04\n",
      "Epoch 3201/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.0711e-04 - val_loss: 8.4518e-04\n",
      "Epoch 3202/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.3977e-04 - val_loss: 0.0010\n",
      "Epoch 3203/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 3204/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.6138e-04 - val_loss: 7.4975e-04\n",
      "Epoch 3205/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.8753e-04 - val_loss: 8.1045e-04\n",
      "Epoch 3206/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.6622e-04 - val_loss: 9.4772e-04\n",
      "Epoch 3207/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.8137e-04 - val_loss: 0.0011\n",
      "Epoch 3208/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.6801e-04 - val_loss: 7.5943e-04\n",
      "Epoch 3209/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.8123e-04 - val_loss: 7.7225e-04\n",
      "Epoch 3210/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.8730e-04 - val_loss: 7.2296e-04\n",
      "Epoch 3211/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.2312e-04 - val_loss: 6.6338e-04\n",
      "Epoch 3212/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 3213/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.3229e-04 - val_loss: 0.0010\n",
      "Epoch 3214/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.5488e-04 - val_loss: 8.9138e-04\n",
      "Epoch 3215/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.3508e-04 - val_loss: 8.2873e-04\n",
      "Epoch 3216/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.6791e-04 - val_loss: 7.3045e-04\n",
      "Epoch 3217/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.2995e-04 - val_loss: 8.9305e-04\n",
      "Epoch 3218/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.5193e-04 - val_loss: 9.9847e-04\n",
      "Epoch 3219/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.2406e-04 - val_loss: 7.0733e-04\n",
      "Epoch 3220/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.6087e-04 - val_loss: 8.3617e-04\n",
      "Epoch 3221/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.4472e-04 - val_loss: 7.3388e-04\n",
      "Epoch 3222/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.1829e-04 - val_loss: 0.0010\n",
      "Epoch 3223/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.1903e-04 - val_loss: 8.5145e-04\n",
      "Epoch 3224/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.6733e-04 - val_loss: 9.2578e-04\n",
      "Epoch 3225/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.5105e-04 - val_loss: 8.1082e-04\n",
      "Epoch 3226/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.9799e-04 - val_loss: 8.0187e-04\n",
      "Epoch 3227/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.5918e-04 - val_loss: 7.0116e-04\n",
      "Epoch 3228/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.0549e-04 - val_loss: 8.4373e-04\n",
      "Epoch 3229/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.6156e-04 - val_loss: 8.8178e-04\n",
      "Epoch 3230/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.6600e-04 - val_loss: 7.1726e-04\n",
      "Epoch 3231/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.5717e-04 - val_loss: 7.3328e-04\n",
      "Epoch 3232/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.9987e-04 - val_loss: 0.0011\n",
      "Epoch 3233/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.5917e-04 - val_loss: 9.6435e-04\n",
      "Epoch 3234/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 3235/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 5ms/step - loss: 9.3298e-04 - val_loss: 7.8129e-04\n",
      "Epoch 3236/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.0604e-04 - val_loss: 8.5522e-04\n",
      "Epoch 3237/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.8652e-04 - val_loss: 0.0012\n",
      "Epoch 3238/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 9.7643e-04\n",
      "Epoch 3239/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.8197e-04 - val_loss: 6.8788e-04\n",
      "Epoch 3240/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.4051e-04 - val_loss: 7.4738e-04\n",
      "Epoch 3241/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.8234e-04 - val_loss: 7.1170e-04\n",
      "Epoch 3242/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.6201e-04 - val_loss: 6.7708e-04\n",
      "Epoch 3243/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.3393e-04 - val_loss: 6.5903e-04\n",
      "Epoch 3244/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.6871e-04 - val_loss: 7.3816e-04\n",
      "Epoch 3245/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.2681e-04 - val_loss: 0.0011\n",
      "Epoch 3246/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.5167e-04 - val_loss: 7.5521e-04\n",
      "Epoch 3247/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.0864e-04 - val_loss: 7.9282e-04\n",
      "Epoch 3248/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.7222e-04 - val_loss: 6.3758e-04\n",
      "Epoch 3249/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.4523e-04 - val_loss: 8.5574e-04\n",
      "Epoch 3250/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.4320e-04 - val_loss: 7.7617e-04\n",
      "Epoch 3251/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.0051e-04 - val_loss: 9.9395e-04\n",
      "Epoch 3252/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.9252e-04 - val_loss: 6.8885e-04\n",
      "Epoch 3253/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 6.8761e-04 - val_loss: 0.0012\n",
      "Epoch 3254/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.0162e-04 - val_loss: 8.2795e-04\n",
      "Epoch 3255/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.5909e-04 - val_loss: 6.5009e-04\n",
      "Epoch 3256/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 7.7679e-04 - val_loss: 6.7361e-04\n",
      "Epoch 3257/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.5796e-04 - val_loss: 8.4154e-04\n",
      "Epoch 3258/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.2121e-04 - val_loss: 8.4735e-04\n",
      "Epoch 3259/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.5277e-04 - val_loss: 8.1936e-04\n",
      "Epoch 3260/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.6412e-04 - val_loss: 8.1170e-04\n",
      "Epoch 3261/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.9241e-04 - val_loss: 7.7916e-04\n",
      "Epoch 3262/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.6095e-04 - val_loss: 0.0011\n",
      "Epoch 3263/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.6827e-04 - val_loss: 7.2330e-04\n",
      "Epoch 3264/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.4051e-04 - val_loss: 8.7779e-04\n",
      "Epoch 3265/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 8.7747e-04 - val_loss: 6.6815e-04\n",
      "Epoch 3266/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.1587e-04 - val_loss: 8.2190e-04\n",
      "Epoch 3267/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.9900e-04 - val_loss: 7.7237e-04\n",
      "Epoch 3268/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.6862e-04 - val_loss: 6.9118e-04\n",
      "Epoch 3269/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.2316e-04 - val_loss: 8.2716e-04\n",
      "Epoch 3270/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.8119e-04 - val_loss: 7.4537e-04\n",
      "Epoch 3271/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.7798e-04 - val_loss: 7.3407e-04\n",
      "Epoch 3272/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.5604e-04 - val_loss: 7.3663e-04\n",
      "Epoch 3273/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.5341e-04 - val_loss: 7.7619e-04\n",
      "Epoch 3274/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.2346e-04 - val_loss: 7.1984e-04\n",
      "Epoch 3275/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.4424e-04 - val_loss: 9.6068e-04\n",
      "Epoch 3276/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.3627e-04 - val_loss: 8.1337e-04\n",
      "Epoch 3277/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 6.9596e-04 - val_loss: 7.1401e-04\n",
      "Epoch 3278/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.4519e-04 - val_loss: 9.1583e-04\n",
      "Epoch 3279/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.8682e-04 - val_loss: 7.5766e-04\n",
      "Epoch 3280/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.0611e-04 - val_loss: 6.4904e-04\n",
      "Epoch 3281/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.4917e-04 - val_loss: 9.9794e-04\n",
      "Epoch 3282/4000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 8.7964e-04\n",
      "Epoch 3283/4000\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 9.1000e-04 - val_loss: 8.2666e-04\n",
      "Epoch 3284/4000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 9.3935e-04 - val_loss: 8.7870e-04\n",
      "Epoch 3285/4000\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 8.8053e-04 - val_loss: 7.7095e-04\n",
      "Epoch 3286/4000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 8.0537e-04 - val_loss: 7.2436e-04\n",
      "Epoch 3287/4000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 8.5095e-04 - val_loss: 8.8172e-04\n",
      "Epoch 3288/4000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 8.8484e-04 - val_loss: 0.0012\n",
      "Epoch 3289/4000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 8.5316e-04 - val_loss: 6.9086e-04\n",
      "Epoch 3290/4000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 7.5317e-04 - val_loss: 7.6624e-04\n",
      "Epoch 3291/4000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 8.0668e-04 - val_loss: 7.2798e-04\n",
      "Epoch 3292/4000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 8.0729e-04 - val_loss: 5.8384e-04\n",
      "Epoch 3293/4000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 6.6204e-04 - val_loss: 6.6160e-04\n",
      "Epoch 3294/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 7.4497e-04 - val_loss: 7.5066e-04\n",
      "Epoch 3295/4000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 7.6673e-04 - val_loss: 6.4950e-04\n",
      "Epoch 3296/4000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 8.8098e-04 - val_loss: 0.0013\n",
      "Epoch 3297/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9.2324e-04 - val_loss: 8.0217e-04\n",
      "Epoch 3298/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 7.7782e-04 - val_loss: 6.3832e-04\n",
      "Epoch 3299/4000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 7.3918e-04 - val_loss: 7.3487e-04\n",
      "Epoch 3300/4000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 7.2110e-04 - val_loss: 6.5057e-04\n",
      "Epoch 3301/4000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 7.2540e-04 - val_loss: 7.3253e-04\n",
      "Epoch 3302/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 7.6451e-04 - val_loss: 7.3957e-04\n",
      "Epoch 3303/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 7.0833e-04 - val_loss: 7.3524e-04\n",
      "Epoch 3304/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 8.2404e-04\n",
      "Epoch 3305/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9.7108e-04 - val_loss: 8.7313e-04\n",
      "Epoch 3306/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 8.0878e-04 - val_loss: 8.0190e-04\n",
      "Epoch 3307/4000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9.4468e-04 - val_loss: 0.0010\n",
      "Epoch 3308/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.4448e-04 - val_loss: 8.3115e-04\n",
      "Epoch 3309/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 7ms/step - loss: 8.1204e-04 - val_loss: 6.9176e-04\n",
      "Epoch 3310/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.6925e-04 - val_loss: 8.2249e-04\n",
      "Epoch 3311/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.0790e-04 - val_loss: 8.0611e-04\n",
      "Epoch 3312/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.6452e-04 - val_loss: 6.8334e-04\n",
      "Epoch 3313/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.1642e-04 - val_loss: 6.6281e-04\n",
      "Epoch 3314/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.0482e-04 - val_loss: 7.2853e-04\n",
      "Epoch 3315/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.1064e-04 - val_loss: 7.1948e-04\n",
      "Epoch 3316/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.6582e-04 - val_loss: 0.0013\n",
      "Epoch 3317/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 3318/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 9.6973e-04\n",
      "Epoch 3319/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.2057e-04 - val_loss: 9.1822e-04\n",
      "Epoch 3320/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.7686e-04 - val_loss: 6.9130e-04\n",
      "Epoch 3321/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.8301e-04 - val_loss: 6.8355e-04\n",
      "Epoch 3322/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.7861e-04 - val_loss: 0.0010\n",
      "Epoch 3323/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.6339e-04 - val_loss: 8.5308e-04\n",
      "Epoch 3324/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.4851e-04 - val_loss: 8.7777e-04\n",
      "Epoch 3325/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.0218e-04 - val_loss: 9.2674e-04\n",
      "Epoch 3326/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.4894e-04 - val_loss: 6.7923e-04\n",
      "Epoch 3327/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.2781e-04 - val_loss: 6.6120e-04\n",
      "Epoch 3328/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.5786e-04 - val_loss: 0.0015\n",
      "Epoch 3329/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 3330/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.5241e-04 - val_loss: 7.2790e-04\n",
      "Epoch 3331/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.7652e-04 - val_loss: 9.2191e-04\n",
      "Epoch 3332/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 3333/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9.6120e-04 - val_loss: 6.0642e-04\n",
      "Epoch 3334/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.0509e-04 - val_loss: 7.7859e-04\n",
      "Epoch 3335/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.6591e-04 - val_loss: 7.7550e-04\n",
      "Epoch 3336/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.5923e-04 - val_loss: 7.6856e-04\n",
      "Epoch 3337/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.8870e-04 - val_loss: 7.2283e-04\n",
      "Epoch 3338/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.4922e-04 - val_loss: 9.3585e-04\n",
      "Epoch 3339/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.4882e-04 - val_loss: 0.0013\n",
      "Epoch 3340/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 8.1315e-04\n",
      "Epoch 3341/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.8296e-04 - val_loss: 7.4185e-04\n",
      "Epoch 3342/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.8096e-04 - val_loss: 8.1727e-04\n",
      "Epoch 3343/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.5412e-04 - val_loss: 7.6715e-04\n",
      "Epoch 3344/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.9828e-04 - val_loss: 0.0010\n",
      "Epoch 3345/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.8921e-04 - val_loss: 0.0010\n",
      "Epoch 3346/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.9518e-04 - val_loss: 0.0011\n",
      "Epoch 3347/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 3348/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.5498e-04 - val_loss: 8.2197e-04\n",
      "Epoch 3349/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.0871e-04 - val_loss: 8.7488e-04\n",
      "Epoch 3350/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.6573e-04 - val_loss: 8.4963e-04\n",
      "Epoch 3351/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 8.1170e-04\n",
      "Epoch 3352/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.7874e-04 - val_loss: 7.0426e-04\n",
      "Epoch 3353/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.9571e-04 - val_loss: 6.8890e-04\n",
      "Epoch 3354/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.2485e-04 - val_loss: 8.8504e-04\n",
      "Epoch 3355/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.2430e-04 - val_loss: 7.7712e-04\n",
      "Epoch 3356/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.6858e-04 - val_loss: 6.4106e-04\n",
      "Epoch 3357/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.9995e-04 - val_loss: 7.2370e-04\n",
      "Epoch 3358/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.8882e-04 - val_loss: 9.6347e-04\n",
      "Epoch 3359/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.6098e-04 - val_loss: 7.2670e-04\n",
      "Epoch 3360/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.9819e-04 - val_loss: 7.6324e-04\n",
      "Epoch 3361/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.7963e-04 - val_loss: 9.7833e-04\n",
      "Epoch 3362/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.3178e-04 - val_loss: 9.1336e-04\n",
      "Epoch 3363/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.8614e-04 - val_loss: 8.0913e-04\n",
      "Epoch 3364/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.1371e-04 - val_loss: 7.9438e-04\n",
      "Epoch 3365/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.3539e-04 - val_loss: 9.2921e-04\n",
      "Epoch 3366/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.8205e-04 - val_loss: 7.0824e-04\n",
      "Epoch 3367/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.0783e-04 - val_loss: 8.4159e-04\n",
      "Epoch 3368/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.6805e-04 - val_loss: 7.3661e-04\n",
      "Epoch 3369/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.4239e-04 - val_loss: 7.6768e-04\n",
      "Epoch 3370/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 6.9696e-04 - val_loss: 7.6288e-04\n",
      "Epoch 3371/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.7685e-04 - val_loss: 6.6893e-04\n",
      "Epoch 3372/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.1641e-04 - val_loss: 7.8112e-04\n",
      "Epoch 3373/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.1370e-04 - val_loss: 9.6667e-04\n",
      "Epoch 3374/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.1193e-04 - val_loss: 0.0012\n",
      "Epoch 3375/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.4525e-04 - val_loss: 7.5138e-04\n",
      "Epoch 3376/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.3354e-04 - val_loss: 8.7784e-04\n",
      "Epoch 3377/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.7702e-04 - val_loss: 0.0010\n",
      "Epoch 3378/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.4023e-04 - val_loss: 7.4354e-04\n",
      "Epoch 3379/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.6741e-04 - val_loss: 8.7024e-04\n",
      "Epoch 3380/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.6669e-04 - val_loss: 8.1605e-04\n",
      "Epoch 3381/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.5444e-04 - val_loss: 0.0012\n",
      "Epoch 3382/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 3383/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.4665e-04 - val_loss: 8.8841e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3384/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.4616e-04 - val_loss: 8.2360e-04\n",
      "Epoch 3385/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.8432e-04 - val_loss: 7.2018e-04\n",
      "Epoch 3386/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.4944e-04 - val_loss: 7.9708e-04\n",
      "Epoch 3387/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.3396e-04 - val_loss: 6.9379e-04\n",
      "Epoch 3388/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.4805e-04 - val_loss: 7.1302e-04\n",
      "Epoch 3389/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.7960e-04 - val_loss: 6.3896e-04\n",
      "Epoch 3390/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.3586e-04 - val_loss: 7.8677e-04\n",
      "Epoch 3391/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.7127e-04 - val_loss: 7.1924e-04\n",
      "Epoch 3392/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.7235e-04 - val_loss: 9.3078e-04\n",
      "Epoch 3393/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.8786e-04 - val_loss: 6.4444e-04\n",
      "Epoch 3394/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.1100e-04 - val_loss: 7.9666e-04\n",
      "Epoch 3395/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.3712e-04 - val_loss: 6.3967e-04\n",
      "Epoch 3396/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.1232e-04 - val_loss: 6.5022e-04\n",
      "Epoch 3397/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.7596e-04 - val_loss: 6.7833e-04\n",
      "Epoch 3398/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.3697e-04 - val_loss: 9.2492e-04\n",
      "Epoch 3399/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.8075e-04 - val_loss: 6.1400e-04\n",
      "Epoch 3400/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.3193e-04 - val_loss: 7.5043e-04\n",
      "Epoch 3401/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.5982e-04 - val_loss: 8.0328e-04\n",
      "Epoch 3402/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.8955e-04 - val_loss: 0.0012\n",
      "Epoch 3403/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 3404/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 8.7381e-04\n",
      "Epoch 3405/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.0801e-04 - val_loss: 8.0003e-04\n",
      "Epoch 3406/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.1741e-04 - val_loss: 7.5643e-04\n",
      "Epoch 3407/4000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 7.7030e-04 - val_loss: 6.5213e-04\n",
      "Epoch 3408/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.1983e-04 - val_loss: 7.0859e-04\n",
      "Epoch 3409/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.4896e-04 - val_loss: 9.5972e-04\n",
      "Epoch 3410/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.5854e-04 - val_loss: 0.0011\n",
      "Epoch 3411/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.3328e-04 - val_loss: 7.4571e-04\n",
      "Epoch 3412/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.2927e-04 - val_loss: 7.1513e-04\n",
      "Epoch 3413/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.8692e-04 - val_loss: 8.3655e-04\n",
      "Epoch 3414/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.6870e-04 - val_loss: 6.9979e-04\n",
      "Epoch 3415/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.9727e-04 - val_loss: 9.8265e-04\n",
      "Epoch 3416/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.9582e-04 - val_loss: 7.3016e-04\n",
      "Epoch 3417/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.9679e-04 - val_loss: 6.3582e-04\n",
      "Epoch 3418/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.4700e-04 - val_loss: 6.8242e-04\n",
      "Epoch 3419/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.8692e-04 - val_loss: 7.2597e-04\n",
      "Epoch 3420/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 6.8821e-04 - val_loss: 9.9417e-04\n",
      "Epoch 3421/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.5984e-04 - val_loss: 7.9552e-04\n",
      "Epoch 3422/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.4996e-04 - val_loss: 6.9431e-04\n",
      "Epoch 3423/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.0366e-04 - val_loss: 7.0081e-04\n",
      "Epoch 3424/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.5211e-04 - val_loss: 9.5674e-04\n",
      "Epoch 3425/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.9149e-04 - val_loss: 7.1875e-04\n",
      "Epoch 3426/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.3422e-04 - val_loss: 8.8283e-04\n",
      "Epoch 3427/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.3071e-04 - val_loss: 0.0010\n",
      "Epoch 3428/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.8044e-04 - val_loss: 7.4647e-04\n",
      "Epoch 3429/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.3018e-04 - val_loss: 6.4391e-04\n",
      "Epoch 3430/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.2660e-04 - val_loss: 7.8398e-04\n",
      "Epoch 3431/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 9.4181e-04\n",
      "Epoch 3432/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.0420e-04 - val_loss: 8.2942e-04\n",
      "Epoch 3433/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.1723e-04 - val_loss: 9.0120e-04\n",
      "Epoch 3434/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.0103e-04 - val_loss: 8.1216e-04\n",
      "Epoch 3435/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.6899e-04 - val_loss: 7.6614e-04\n",
      "Epoch 3436/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.1958e-04 - val_loss: 8.1721e-04\n",
      "Epoch 3437/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.5691e-04 - val_loss: 0.0012\n",
      "Epoch 3438/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.9332e-04 - val_loss: 9.3260e-04\n",
      "Epoch 3439/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.5438e-04 - val_loss: 6.2823e-04\n",
      "Epoch 3440/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.1833e-04 - val_loss: 8.4932e-04\n",
      "Epoch 3441/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.5442e-04 - val_loss: 8.7297e-04\n",
      "Epoch 3442/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.4360e-04 - val_loss: 8.8280e-04\n",
      "Epoch 3443/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.8589e-04 - val_loss: 9.7167e-04\n",
      "Epoch 3444/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 7.7419e-04\n",
      "Epoch 3445/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.7517e-04 - val_loss: 8.0524e-04\n",
      "Epoch 3446/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.2175e-04 - val_loss: 9.6778e-04\n",
      "Epoch 3447/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 7.9415e-04 - val_loss: 6.9665e-04\n",
      "Epoch 3448/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.9819e-04 - val_loss: 8.5996e-04\n",
      "Epoch 3449/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.3684e-04 - val_loss: 8.2993e-04\n",
      "Epoch 3450/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.3890e-04 - val_loss: 8.2263e-04\n",
      "Epoch 3451/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.6239e-04 - val_loss: 9.9319e-04\n",
      "Epoch 3452/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 7.5011e-04\n",
      "Epoch 3453/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.1580e-04 - val_loss: 6.6289e-04\n",
      "Epoch 3454/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 7.4362e-04 - val_loss: 7.3644e-04\n",
      "Epoch 3455/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.7205e-04 - val_loss: 0.0010\n",
      "Epoch 3456/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.7945e-04 - val_loss: 6.7445e-04\n",
      "Epoch 3457/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.1131e-04 - val_loss: 8.5007e-04\n",
      "Epoch 3458/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 6ms/step - loss: 8.0130e-04 - val_loss: 7.4814e-04\n",
      "Epoch 3459/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.0395e-04 - val_loss: 6.5468e-04\n",
      "Epoch 3460/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.0931e-04 - val_loss: 7.5087e-04\n",
      "Epoch 3461/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.3576e-04 - val_loss: 6.4958e-04\n",
      "Epoch 3462/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.8620e-04 - val_loss: 0.0014\n",
      "Epoch 3463/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 3464/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 7.7267e-04\n",
      "Epoch 3465/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.5553e-04 - val_loss: 8.9205e-04\n",
      "Epoch 3466/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.8919e-04 - val_loss: 7.8839e-04\n",
      "Epoch 3467/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.8162e-04 - val_loss: 6.7251e-04\n",
      "Epoch 3468/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.7535e-04 - val_loss: 8.2048e-04\n",
      "Epoch 3469/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.5591e-04 - val_loss: 6.3992e-04\n",
      "Epoch 3470/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.0894e-04 - val_loss: 7.8494e-04\n",
      "Epoch 3471/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.1703e-04 - val_loss: 0.0012\n",
      "Epoch 3472/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 9.6739e-04\n",
      "Epoch 3473/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 9.4222e-04\n",
      "Epoch 3474/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.5120e-04 - val_loss: 8.9885e-04\n",
      "Epoch 3475/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.5625e-04 - val_loss: 0.0011\n",
      "Epoch 3476/4000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 9.8485e-04 - val_loss: 7.7930e-04\n",
      "Epoch 3477/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.6336e-04 - val_loss: 7.1928e-04\n",
      "Epoch 3478/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.0830e-04 - val_loss: 6.7154e-04\n",
      "Epoch 3479/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.0961e-04 - val_loss: 7.7220e-04\n",
      "Epoch 3480/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.6328e-04 - val_loss: 8.2467e-04\n",
      "Epoch 3481/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.4968e-04 - val_loss: 8.2230e-04\n",
      "Epoch 3482/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 7.7539e-04 - val_loss: 6.8904e-04\n",
      "Epoch 3483/4000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 6.7520e-04 - val_loss: 6.4470e-04\n",
      "Epoch 3484/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 7.3961e-04 - val_loss: 7.2627e-04\n",
      "Epoch 3485/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.2277e-04 - val_loss: 0.0011\n",
      "Epoch 3486/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 8.9647e-04 - val_loss: 7.2458e-04\n",
      "Epoch 3487/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.2954e-04 - val_loss: 0.0011\n",
      "Epoch 3488/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.7174e-04 - val_loss: 9.0980e-04\n",
      "Epoch 3489/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.4237e-04 - val_loss: 6.6509e-04\n",
      "Epoch 3490/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.1015e-04 - val_loss: 6.2794e-04\n",
      "Epoch 3491/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 7.7075e-04 - val_loss: 7.4591e-04\n",
      "Epoch 3492/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9.3723e-04 - val_loss: 8.0134e-04\n",
      "Epoch 3493/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.1189e-04 - val_loss: 8.1729e-04\n",
      "Epoch 3494/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9.0719e-04 - val_loss: 9.1395e-04\n",
      "Epoch 3495/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.4263e-04 - val_loss: 6.3701e-04\n",
      "Epoch 3496/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.2993e-04 - val_loss: 6.5746e-04\n",
      "Epoch 3497/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.7552e-04 - val_loss: 6.7762e-04\n",
      "Epoch 3498/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.0857e-04 - val_loss: 5.8415e-04\n",
      "Epoch 3499/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.9753e-04 - val_loss: 9.3172e-04\n",
      "Epoch 3500/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.2991e-04 - val_loss: 0.0011\n",
      "Epoch 3501/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9.4057e-04 - val_loss: 7.4411e-04\n",
      "Epoch 3502/4000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 7.2229e-04 - val_loss: 6.2717e-04\n",
      "Epoch 3503/4000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 7.9595e-04 - val_loss: 7.6586e-04\n",
      "Epoch 3504/4000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 8.1253e-04 - val_loss: 6.7982e-04\n",
      "Epoch 3505/4000\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 6.8826e-04 - val_loss: 5.8143e-04\n",
      "Epoch 3506/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 6.9000e-04 - val_loss: 7.1748e-04\n",
      "Epoch 3507/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.4679e-04 - val_loss: 9.8665e-04\n",
      "Epoch 3508/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.3431e-04 - val_loss: 6.7674e-04\n",
      "Epoch 3509/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.2706e-04 - val_loss: 7.8597e-04\n",
      "Epoch 3510/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.8381e-04 - val_loss: 6.3465e-04\n",
      "Epoch 3511/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.9192e-04 - val_loss: 0.0011\n",
      "Epoch 3512/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9.4441e-04 - val_loss: 8.7183e-04\n",
      "Epoch 3513/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.5367e-04 - val_loss: 6.6755e-04\n",
      "Epoch 3514/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.1692e-04 - val_loss: 7.7962e-04\n",
      "Epoch 3515/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.2843e-04 - val_loss: 6.1806e-04\n",
      "Epoch 3516/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.6411e-04 - val_loss: 7.4823e-04\n",
      "Epoch 3517/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.5696e-04 - val_loss: 7.5390e-04\n",
      "Epoch 3518/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.6660e-04 - val_loss: 7.2440e-04\n",
      "Epoch 3519/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.7025e-04 - val_loss: 9.2496e-04\n",
      "Epoch 3520/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.2363e-04 - val_loss: 8.0998e-04\n",
      "Epoch 3521/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.6219e-04 - val_loss: 7.6250e-04\n",
      "Epoch 3522/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.3517e-04 - val_loss: 7.1281e-04\n",
      "Epoch 3523/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.4080e-04 - val_loss: 6.9209e-04\n",
      "Epoch 3524/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.7721e-04 - val_loss: 7.6996e-04\n",
      "Epoch 3525/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 8.2897e-04 - val_loss: 0.0016\n",
      "Epoch 3526/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 7.7712e-04\n",
      "Epoch 3527/4000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 8.4474e-04 - val_loss: 8.6002e-04\n",
      "Epoch 3528/4000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 7.8945e-04 - val_loss: 7.9380e-04\n",
      "Epoch 3529/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.4544e-04 - val_loss: 5.9831e-04\n",
      "Epoch 3530/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.1204e-04 - val_loss: 6.1666e-04\n",
      "Epoch 3531/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 8.2357e-04 - val_loss: 7.3092e-04\n",
      "Epoch 3532/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 5ms/step - loss: 8.2488e-04 - val_loss: 7.4824e-04\n",
      "Epoch 3533/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.5407e-04 - val_loss: 6.4766e-04\n",
      "Epoch 3534/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.4849e-04 - val_loss: 7.2815e-04\n",
      "Epoch 3535/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9.5670e-04 - val_loss: 7.8030e-04\n",
      "Epoch 3536/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.9995e-04 - val_loss: 6.2327e-04\n",
      "Epoch 3537/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.3430e-04 - val_loss: 6.4703e-04\n",
      "Epoch 3538/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.0976e-04 - val_loss: 6.8838e-04\n",
      "Epoch 3539/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.7014e-04 - val_loss: 9.6809e-04\n",
      "Epoch 3540/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.9421e-04 - val_loss: 8.2897e-04\n",
      "Epoch 3541/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.4390e-04 - val_loss: 8.2284e-04\n",
      "Epoch 3542/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.4177e-04 - val_loss: 7.7422e-04\n",
      "Epoch 3543/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.7689e-04 - val_loss: 7.3051e-04\n",
      "Epoch 3544/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.9821e-04 - val_loss: 7.7364e-04\n",
      "Epoch 3545/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.7755e-04 - val_loss: 0.0011\n",
      "Epoch 3546/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 3547/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 7.6312e-04\n",
      "Epoch 3548/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 8.7595e-04 - val_loss: 8.1314e-04\n",
      "Epoch 3549/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.9922e-04 - val_loss: 9.4349e-04\n",
      "Epoch 3550/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 6.6551e-04\n",
      "Epoch 3551/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 9.9302e-04\n",
      "Epoch 3552/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.7385e-04 - val_loss: 9.1288e-04\n",
      "Epoch 3553/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.5544e-04 - val_loss: 6.6105e-04\n",
      "Epoch 3554/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.9767e-04 - val_loss: 9.8183e-04\n",
      "Epoch 3555/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.3634e-04 - val_loss: 6.9713e-04\n",
      "Epoch 3556/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.3715e-04 - val_loss: 9.1712e-04\n",
      "Epoch 3557/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.8021e-04 - val_loss: 7.6698e-04\n",
      "Epoch 3558/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.0288e-04 - val_loss: 7.3887e-04\n",
      "Epoch 3559/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.9998e-04 - val_loss: 8.1586e-04\n",
      "Epoch 3560/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.8080e-04 - val_loss: 7.1800e-04\n",
      "Epoch 3561/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 8.0066e-04 - val_loss: 9.4534e-04\n",
      "Epoch 3562/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 8.0914e-04 - val_loss: 7.5416e-04\n",
      "Epoch 3563/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.8787e-04 - val_loss: 9.5644e-04\n",
      "Epoch 3564/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 3565/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.9176e-04 - val_loss: 8.9720e-04\n",
      "Epoch 3566/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.8074e-04 - val_loss: 0.0015\n",
      "Epoch 3567/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 8.0172e-04\n",
      "Epoch 3568/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.8528e-04 - val_loss: 7.7037e-04\n",
      "Epoch 3569/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 8.4015e-04 - val_loss: 6.5055e-04\n",
      "Epoch 3570/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.6229e-04 - val_loss: 7.8783e-04\n",
      "Epoch 3571/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.3684e-04 - val_loss: 9.6578e-04\n",
      "Epoch 3572/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 9.8236e-04\n",
      "Epoch 3573/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.7978e-04 - val_loss: 9.8496e-04\n",
      "Epoch 3574/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.4976e-04 - val_loss: 7.6991e-04\n",
      "Epoch 3575/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.6169e-04 - val_loss: 7.3785e-04\n",
      "Epoch 3576/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.5470e-04 - val_loss: 8.6451e-04\n",
      "Epoch 3577/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 9.6274e-04\n",
      "Epoch 3578/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.9102e-04 - val_loss: 6.5950e-04\n",
      "Epoch 3579/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.4723e-04 - val_loss: 6.3146e-04\n",
      "Epoch 3580/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.5229e-04 - val_loss: 8.9241e-04\n",
      "Epoch 3581/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 7.0020e-04\n",
      "Epoch 3582/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 8.2443e-04 - val_loss: 8.0099e-04\n",
      "Epoch 3583/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 8.5340e-04 - val_loss: 8.1483e-04\n",
      "Epoch 3584/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.3267e-04 - val_loss: 6.5853e-04\n",
      "Epoch 3585/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.8706e-04 - val_loss: 0.0015\n",
      "Epoch 3586/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 9.4771e-04\n",
      "Epoch 3587/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.5811e-04 - val_loss: 8.5601e-04\n",
      "Epoch 3588/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.9059e-04 - val_loss: 7.3902e-04\n",
      "Epoch 3589/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.1965e-04 - val_loss: 6.2104e-04\n",
      "Epoch 3590/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.2477e-04 - val_loss: 7.9232e-04\n",
      "Epoch 3591/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.3032e-04 - val_loss: 8.1254e-04\n",
      "Epoch 3592/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.3757e-04 - val_loss: 0.0011\n",
      "Epoch 3593/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 8.9082e-04\n",
      "Epoch 3594/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9.2083e-04 - val_loss: 9.9303e-04\n",
      "Epoch 3595/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.6299e-04 - val_loss: 7.8229e-04\n",
      "Epoch 3596/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.1507e-04 - val_loss: 8.2092e-04\n",
      "Epoch 3597/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.8079e-04 - val_loss: 0.0010\n",
      "Epoch 3598/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 8.9133e-04 - val_loss: 6.8346e-04\n",
      "Epoch 3599/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.7240e-04 - val_loss: 8.3712e-04\n",
      "Epoch 3600/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.8296e-04 - val_loss: 6.9857e-04\n",
      "Epoch 3601/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.1412e-04 - val_loss: 6.8093e-04\n",
      "Epoch 3602/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.6677e-04 - val_loss: 0.0011\n",
      "Epoch 3603/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.8814e-04 - val_loss: 9.6171e-04\n",
      "Epoch 3604/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.3255e-04 - val_loss: 6.5166e-04\n",
      "Epoch 3605/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 6.8459e-04 - val_loss: 6.6341e-04\n",
      "Epoch 3606/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 5ms/step - loss: 7.0558e-04 - val_loss: 9.5375e-04\n",
      "Epoch 3607/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.7514e-04 - val_loss: 6.8068e-04\n",
      "Epoch 3608/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.7782e-04 - val_loss: 7.6644e-04\n",
      "Epoch 3609/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.0374e-04 - val_loss: 6.0706e-04\n",
      "Epoch 3610/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.9338e-04 - val_loss: 6.9501e-04\n",
      "Epoch 3611/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.7434e-04 - val_loss: 6.2639e-04\n",
      "Epoch 3612/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.4779e-04 - val_loss: 8.7121e-04\n",
      "Epoch 3613/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.1055e-04 - val_loss: 8.3854e-04\n",
      "Epoch 3614/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.7899e-04 - val_loss: 6.2360e-04\n",
      "Epoch 3615/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.9294e-04 - val_loss: 0.0011\n",
      "Epoch 3616/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.3351e-04 - val_loss: 9.2186e-04\n",
      "Epoch 3617/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.3337e-04 - val_loss: 7.1753e-04\n",
      "Epoch 3618/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.3584e-04 - val_loss: 6.5681e-04\n",
      "Epoch 3619/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.2143e-04 - val_loss: 0.0015\n",
      "Epoch 3620/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 3621/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 8.7107e-04\n",
      "Epoch 3622/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.5634e-04 - val_loss: 6.6539e-04\n",
      "Epoch 3623/4000\n",
      "18/18 [==============================] - ETA: 0s - loss: 6.4263e-0 - 0s 4ms/step - loss: 6.7939e-04 - val_loss: 7.4508e-04\n",
      "Epoch 3624/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.4907e-04 - val_loss: 7.5740e-04\n",
      "Epoch 3625/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.5952e-04 - val_loss: 6.9339e-04\n",
      "Epoch 3626/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.0423e-04 - val_loss: 7.9512e-04\n",
      "Epoch 3627/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.8871e-04 - val_loss: 7.3732e-04\n",
      "Epoch 3628/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.1015e-04 - val_loss: 9.8373e-04\n",
      "Epoch 3629/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.7145e-04 - val_loss: 8.2640e-04\n",
      "Epoch 3630/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.9350e-04 - val_loss: 7.6050e-04\n",
      "Epoch 3631/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.4244e-04 - val_loss: 7.4747e-04\n",
      "Epoch 3632/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.8522e-04 - val_loss: 8.5809e-04\n",
      "Epoch 3633/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.2140e-04 - val_loss: 9.4337e-04\n",
      "Epoch 3634/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 7.6771e-04\n",
      "Epoch 3635/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 3636/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 8.6950e-04\n",
      "Epoch 3637/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.4349e-04 - val_loss: 6.6367e-04\n",
      "Epoch 3638/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.5962e-04 - val_loss: 0.0011\n",
      "Epoch 3639/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 3640/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 8.1655e-04 - val_loss: 7.4144e-04\n",
      "Epoch 3641/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.3326e-04 - val_loss: 6.9422e-04\n",
      "Epoch 3642/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.8593e-04 - val_loss: 8.0421e-04\n",
      "Epoch 3643/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.9844e-04 - val_loss: 7.4827e-04\n",
      "Epoch 3644/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.0489e-04 - val_loss: 6.6101e-04\n",
      "Epoch 3645/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.9438e-04 - val_loss: 6.1351e-04\n",
      "Epoch 3646/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.2304e-04 - val_loss: 7.1299e-04\n",
      "Epoch 3647/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.5731e-04 - val_loss: 6.2087e-04\n",
      "Epoch 3648/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.0573e-04 - val_loss: 7.6854e-04\n",
      "Epoch 3649/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.6310e-04 - val_loss: 9.8546e-04\n",
      "Epoch 3650/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.5345e-04 - val_loss: 9.5979e-04\n",
      "Epoch 3651/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.9546e-04 - val_loss: 8.2665e-04\n",
      "Epoch 3652/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.6585e-04 - val_loss: 7.8561e-04\n",
      "Epoch 3653/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 8.8875e-04 - val_loss: 0.0014\n",
      "Epoch 3654/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 3655/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 7.9196e-04\n",
      "Epoch 3656/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.2728e-04 - val_loss: 0.0012\n",
      "Epoch 3657/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 7.2900e-04\n",
      "Epoch 3658/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.5241e-04 - val_loss: 8.3764e-04\n",
      "Epoch 3659/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.5388e-04 - val_loss: 6.4047e-04\n",
      "Epoch 3660/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.9392e-04 - val_loss: 8.1202e-04\n",
      "Epoch 3661/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.8503e-04 - val_loss: 5.8653e-04\n",
      "Epoch 3662/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.8974e-04 - val_loss: 8.7362e-04\n",
      "Epoch 3663/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.2662e-04 - val_loss: 6.4539e-04\n",
      "Epoch 3664/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.9809e-04 - val_loss: 9.6975e-04\n",
      "Epoch 3665/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.2908e-04 - val_loss: 7.1335e-04\n",
      "Epoch 3666/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.9731e-04 - val_loss: 5.7964e-04\n",
      "Epoch 3667/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.2714e-04 - val_loss: 6.5351e-04\n",
      "Epoch 3668/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.3681e-04 - val_loss: 7.3663e-04\n",
      "Epoch 3669/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.5852e-04 - val_loss: 6.5772e-04\n",
      "Epoch 3670/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.9863e-04 - val_loss: 7.1974e-04\n",
      "Epoch 3671/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.0945e-04 - val_loss: 7.2428e-04\n",
      "Epoch 3672/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.7282e-04 - val_loss: 8.2685e-04\n",
      "Epoch 3673/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.6652e-04 - val_loss: 6.7741e-04\n",
      "Epoch 3674/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.3425e-04 - val_loss: 0.0013\n",
      "Epoch 3675/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 7.6811e-04\n",
      "Epoch 3676/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.8373e-04 - val_loss: 7.0781e-04\n",
      "Epoch 3677/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.9046e-04 - val_loss: 6.8139e-04\n",
      "Epoch 3678/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.9948e-04 - val_loss: 7.3031e-04\n",
      "Epoch 3679/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9.2833e-04 - val_loss: 0.0012\n",
      "Epoch 3680/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 5ms/step - loss: 8.5209e-04 - val_loss: 7.1331e-04\n",
      "Epoch 3681/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.1032e-04 - val_loss: 9.4922e-04\n",
      "Epoch 3682/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.4210e-04 - val_loss: 6.6483e-04\n",
      "Epoch 3683/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.2328e-04 - val_loss: 5.5927e-04\n",
      "Epoch 3684/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.2002e-04 - val_loss: 8.8571e-04\n",
      "Epoch 3685/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.2413e-04 - val_loss: 6.3463e-04\n",
      "Epoch 3686/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.0726e-04 - val_loss: 6.2993e-04\n",
      "Epoch 3687/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.5244e-04 - val_loss: 7.1928e-04\n",
      "Epoch 3688/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.8262e-04 - val_loss: 6.8660e-04\n",
      "Epoch 3689/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.6674e-04 - val_loss: 6.9031e-04\n",
      "Epoch 3690/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 7.7049e-04 - val_loss: 6.9713e-04\n",
      "Epoch 3691/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 6.7032e-04 - val_loss: 6.0465e-04\n",
      "Epoch 3692/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.7484e-04 - val_loss: 6.3416e-04\n",
      "Epoch 3693/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.3637e-04 - val_loss: 6.9875e-04\n",
      "Epoch 3694/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.0302e-04 - val_loss: 7.5362e-04\n",
      "Epoch 3695/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.5787e-04 - val_loss: 7.0257e-04\n",
      "Epoch 3696/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.6647e-04 - val_loss: 6.1933e-04\n",
      "Epoch 3697/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.1630e-04 - val_loss: 0.0010\n",
      "Epoch 3698/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.2333e-04 - val_loss: 7.0407e-04\n",
      "Epoch 3699/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.1876e-04 - val_loss: 8.2762e-04\n",
      "Epoch 3700/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.9431e-04 - val_loss: 0.0011\n",
      "Epoch 3701/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.9892e-04 - val_loss: 9.7601e-04\n",
      "Epoch 3702/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.6914e-04 - val_loss: 9.7266e-04\n",
      "Epoch 3703/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.6636e-04 - val_loss: 0.0013\n",
      "Epoch 3704/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 8.6834e-04\n",
      "Epoch 3705/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.2516e-04 - val_loss: 9.1122e-04\n",
      "Epoch 3706/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 8.6893e-04\n",
      "Epoch 3707/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.1440e-04 - val_loss: 7.1849e-04\n",
      "Epoch 3708/4000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 7.2612e-04 - val_loss: 7.1948e-04\n",
      "Epoch 3709/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.9389e-04 - val_loss: 9.3295e-04\n",
      "Epoch 3710/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.5587e-04 - val_loss: 8.7843e-04\n",
      "Epoch 3711/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.5055e-04 - val_loss: 9.4013e-04\n",
      "Epoch 3712/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.9649e-04 - val_loss: 8.2153e-04\n",
      "Epoch 3713/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.4422e-04 - val_loss: 6.7141e-04\n",
      "Epoch 3714/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.6935e-04 - val_loss: 7.0918e-04\n",
      "Epoch 3715/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.2934e-04 - val_loss: 0.0011\n",
      "Epoch 3716/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.2803e-04 - val_loss: 7.5016e-04\n",
      "Epoch 3717/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.1270e-04 - val_loss: 6.4875e-04\n",
      "Epoch 3718/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.0917e-04 - val_loss: 6.5186e-04\n",
      "Epoch 3719/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.3983e-04 - val_loss: 9.4759e-04\n",
      "Epoch 3720/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.5342e-04 - val_loss: 7.2289e-04\n",
      "Epoch 3721/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.9409e-04 - val_loss: 6.5692e-04\n",
      "Epoch 3722/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.6448e-04 - val_loss: 7.4228e-04\n",
      "Epoch 3723/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.1276e-04 - val_loss: 9.7593e-04\n",
      "Epoch 3724/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.4143e-04 - val_loss: 8.0791e-04\n",
      "Epoch 3725/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.4377e-04 - val_loss: 7.6628e-04\n",
      "Epoch 3726/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.4626e-04 - val_loss: 9.6608e-04\n",
      "Epoch 3727/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.8552e-04 - val_loss: 7.5231e-04\n",
      "Epoch 3728/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.7877e-04 - val_loss: 0.0012\n",
      "Epoch 3729/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 8.8940e-04\n",
      "Epoch 3730/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.9918e-04 - val_loss: 8.6087e-04\n",
      "Epoch 3731/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 8.9826e-04 - val_loss: 6.6665e-04\n",
      "Epoch 3732/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.4975e-04 - val_loss: 0.0011\n",
      "Epoch 3733/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.9280e-04 - val_loss: 7.9731e-04\n",
      "Epoch 3734/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 8.4950e-04 - val_loss: 0.0011\n",
      "Epoch 3735/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 3736/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.3952e-04 - val_loss: 8.6182e-04\n",
      "Epoch 3737/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.6088e-04 - val_loss: 6.6869e-04\n",
      "Epoch 3738/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.9407e-04 - val_loss: 6.5655e-04\n",
      "Epoch 3739/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.1915e-04 - val_loss: 9.2682e-04\n",
      "Epoch 3740/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.1488e-04 - val_loss: 6.7111e-04\n",
      "Epoch 3741/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.7576e-04 - val_loss: 7.7082e-04\n",
      "Epoch 3742/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.4554e-04 - val_loss: 7.5605e-04\n",
      "Epoch 3743/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.3647e-04 - val_loss: 9.2275e-04\n",
      "Epoch 3744/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.6071e-04 - val_loss: 8.4075e-04\n",
      "Epoch 3745/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.0649e-04 - val_loss: 6.6792e-04\n",
      "Epoch 3746/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 6.5863e-04 - val_loss: 5.2887e-04\n",
      "Epoch 3747/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.9530e-04 - val_loss: 9.1534e-04\n",
      "Epoch 3748/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.3228e-04 - val_loss: 7.1823e-04\n",
      "Epoch 3749/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.4810e-04 - val_loss: 6.3917e-04\n",
      "Epoch 3750/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.4932e-04 - val_loss: 6.4867e-04\n",
      "Epoch 3751/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.7192e-04 - val_loss: 6.0724e-04\n",
      "Epoch 3752/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.6439e-04 - val_loss: 6.8273e-04\n",
      "Epoch 3753/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.1927e-04 - val_loss: 7.1735e-04\n",
      "Epoch 3754/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 6ms/step - loss: 7.5069e-04 - val_loss: 8.5469e-04\n",
      "Epoch 3755/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.4228e-04 - val_loss: 7.3503e-04\n",
      "Epoch 3756/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 6.7965e-04 - val_loss: 6.6742e-04\n",
      "Epoch 3757/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.7978e-04 - val_loss: 6.8261e-04\n",
      "Epoch 3758/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.0914e-04 - val_loss: 6.2047e-04\n",
      "Epoch 3759/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.1709e-04 - val_loss: 7.7100e-04\n",
      "Epoch 3760/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.2750e-04 - val_loss: 7.5937e-04\n",
      "Epoch 3761/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.6434e-04 - val_loss: 7.4817e-04\n",
      "Epoch 3762/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.0793e-04 - val_loss: 0.0011\n",
      "Epoch 3763/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.6450e-04 - val_loss: 8.2364e-04\n",
      "Epoch 3764/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.6446e-04 - val_loss: 6.4277e-04\n",
      "Epoch 3765/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.9875e-04 - val_loss: 9.6478e-04\n",
      "Epoch 3766/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.2488e-04 - val_loss: 7.7688e-04\n",
      "Epoch 3767/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.3501e-04 - val_loss: 7.5215e-04\n",
      "Epoch 3768/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.0487e-04 - val_loss: 0.0011\n",
      "Epoch 3769/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.8301e-04 - val_loss: 6.3385e-04\n",
      "Epoch 3770/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 6.7673e-04 - val_loss: 7.8829e-04\n",
      "Epoch 3771/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9.9078e-04 - val_loss: 0.0015\n",
      "Epoch 3772/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 6.9974e-04\n",
      "Epoch 3773/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 8.0838e-04 - val_loss: 9.1438e-04\n",
      "Epoch 3774/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.6263e-04 - val_loss: 0.0012\n",
      "Epoch 3775/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 3776/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.5872e-04 - val_loss: 6.3985e-04\n",
      "Epoch 3777/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.6087e-04 - val_loss: 6.2475e-04\n",
      "Epoch 3778/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.5826e-04 - val_loss: 0.0012\n",
      "Epoch 3779/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 8.7116e-04\n",
      "Epoch 3780/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.7442e-04 - val_loss: 8.0102e-04\n",
      "Epoch 3781/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.1192e-04 - val_loss: 6.5468e-04\n",
      "Epoch 3782/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 6.4244e-04 - val_loss: 6.1582e-04\n",
      "Epoch 3783/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.0521e-04 - val_loss: 6.7486e-04\n",
      "Epoch 3784/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.1192e-04 - val_loss: 8.2830e-04\n",
      "Epoch 3785/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.1346e-04 - val_loss: 7.2734e-04\n",
      "Epoch 3786/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.8609e-04 - val_loss: 0.0012\n",
      "Epoch 3787/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 9.7206e-04\n",
      "Epoch 3788/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.4670e-04 - val_loss: 7.9174e-04\n",
      "Epoch 3789/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.0448e-04 - val_loss: 0.0011\n",
      "Epoch 3790/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.9484e-04 - val_loss: 9.9148e-04\n",
      "Epoch 3791/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.4572e-04 - val_loss: 8.1956e-04\n",
      "Epoch 3792/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.4394e-04 - val_loss: 6.7337e-04\n",
      "Epoch 3793/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.1297e-04 - val_loss: 6.7503e-04\n",
      "Epoch 3794/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.2429e-04 - val_loss: 5.9290e-04\n",
      "Epoch 3795/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.5826e-04 - val_loss: 7.0677e-04\n",
      "Epoch 3796/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9.8091e-04 - val_loss: 0.0012\n",
      "Epoch 3797/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.7555e-04 - val_loss: 7.5865e-04\n",
      "Epoch 3798/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.1879e-04 - val_loss: 9.0480e-04\n",
      "Epoch 3799/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.3408e-04 - val_loss: 9.2442e-04\n",
      "Epoch 3800/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 9.2429e-04\n",
      "Epoch 3801/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.9030e-04 - val_loss: 8.2724e-04\n",
      "Epoch 3802/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.1795e-04 - val_loss: 8.5801e-04\n",
      "Epoch 3803/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.8546e-04 - val_loss: 0.0017\n",
      "Epoch 3804/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 3805/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 7.9877e-04\n",
      "Epoch 3806/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.6749e-04 - val_loss: 8.1242e-04\n",
      "Epoch 3807/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.4211e-04 - val_loss: 7.8472e-04\n",
      "Epoch 3808/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.2194e-04 - val_loss: 6.4968e-04\n",
      "Epoch 3809/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.1384e-04 - val_loss: 8.2379e-04\n",
      "Epoch 3810/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.7721e-04 - val_loss: 7.1598e-04\n",
      "Epoch 3811/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.2602e-04 - val_loss: 6.6071e-04\n",
      "Epoch 3812/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.7272e-04 - val_loss: 6.5417e-04\n",
      "Epoch 3813/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.7492e-04 - val_loss: 5.9929e-04\n",
      "Epoch 3814/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.1038e-04 - val_loss: 7.3242e-04\n",
      "Epoch 3815/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.2421e-04 - val_loss: 8.1107e-04\n",
      "Epoch 3816/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.7079e-04 - val_loss: 7.2864e-04\n",
      "Epoch 3817/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.9969e-04 - val_loss: 7.3815e-04\n",
      "Epoch 3818/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.7766e-04 - val_loss: 8.8414e-04\n",
      "Epoch 3819/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.7673e-04 - val_loss: 0.0012\n",
      "Epoch 3820/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 9.3876e-04\n",
      "Epoch 3821/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.6700e-04 - val_loss: 8.9409e-04\n",
      "Epoch 3822/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.0839e-04 - val_loss: 7.7954e-04\n",
      "Epoch 3823/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.3955e-04 - val_loss: 8.6529e-04\n",
      "Epoch 3824/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.3040e-04 - val_loss: 6.9358e-04\n",
      "Epoch 3825/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.5468e-04 - val_loss: 6.5207e-04\n",
      "Epoch 3826/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.7243e-04 - val_loss: 7.6607e-04\n",
      "Epoch 3827/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.0761e-04 - val_loss: 5.7314e-04\n",
      "Epoch 3828/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 5ms/step - loss: 7.7107e-04 - val_loss: 8.0531e-04\n",
      "Epoch 3829/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.9110e-04 - val_loss: 7.9995e-04\n",
      "Epoch 3830/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.6430e-04 - val_loss: 7.2108e-04\n",
      "Epoch 3831/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.2147e-04 - val_loss: 6.9967e-04\n",
      "Epoch 3832/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.7518e-04 - val_loss: 6.2392e-04\n",
      "Epoch 3833/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.8112e-04 - val_loss: 7.5199e-04\n",
      "Epoch 3834/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.7124e-04 - val_loss: 8.4033e-04\n",
      "Epoch 3835/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.8010e-04 - val_loss: 6.8447e-04\n",
      "Epoch 3836/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.4356e-04 - val_loss: 7.6675e-04\n",
      "Epoch 3837/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.2981e-04 - val_loss: 6.5100e-04\n",
      "Epoch 3838/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.0519e-04 - val_loss: 6.9055e-04\n",
      "Epoch 3839/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.4276e-04 - val_loss: 7.7374e-04\n",
      "Epoch 3840/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.1674e-04 - val_loss: 9.0880e-04\n",
      "Epoch 3841/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.6445e-04 - val_loss: 7.3465e-04\n",
      "Epoch 3842/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.9912e-04 - val_loss: 7.5988e-04\n",
      "Epoch 3843/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.4783e-04 - val_loss: 0.0011\n",
      "Epoch 3844/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 7.5083e-04\n",
      "Epoch 3845/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.6984e-04 - val_loss: 6.3320e-04\n",
      "Epoch 3846/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.2728e-04 - val_loss: 6.1792e-04\n",
      "Epoch 3847/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.7797e-04 - val_loss: 7.9242e-04\n",
      "Epoch 3848/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.0956e-04 - val_loss: 6.6643e-04\n",
      "Epoch 3849/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.2687e-04 - val_loss: 7.2273e-04\n",
      "Epoch 3850/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.5683e-04 - val_loss: 8.0905e-04\n",
      "Epoch 3851/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.7590e-04 - val_loss: 5.6534e-04\n",
      "Epoch 3852/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.7983e-04 - val_loss: 6.3771e-04\n",
      "Epoch 3853/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.0403e-04 - val_loss: 7.7934e-04\n",
      "Epoch 3854/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.0028e-04 - val_loss: 6.9792e-04\n",
      "Epoch 3855/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.1623e-04 - val_loss: 7.6201e-04\n",
      "Epoch 3856/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.4285e-04 - val_loss: 6.1745e-04\n",
      "Epoch 3857/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.6062e-04 - val_loss: 7.8099e-04\n",
      "Epoch 3858/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.1023e-04 - val_loss: 0.0010\n",
      "Epoch 3859/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.2427e-04 - val_loss: 6.1318e-04\n",
      "Epoch 3860/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.3425e-04 - val_loss: 8.0125e-04\n",
      "Epoch 3861/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.3581e-04 - val_loss: 6.7063e-04\n",
      "Epoch 3862/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.9201e-04 - val_loss: 6.9039e-04\n",
      "Epoch 3863/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.4092e-04 - val_loss: 6.8219e-04\n",
      "Epoch 3864/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.3453e-04 - val_loss: 5.6732e-04\n",
      "Epoch 3865/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.5524e-04 - val_loss: 7.3090e-04\n",
      "Epoch 3866/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.4548e-04 - val_loss: 6.4011e-04\n",
      "Epoch 3867/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.0869e-04 - val_loss: 8.4456e-04\n",
      "Epoch 3868/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.2477e-04 - val_loss: 7.0151e-04\n",
      "Epoch 3869/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.4840e-04 - val_loss: 5.7033e-04\n",
      "Epoch 3870/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.2009e-04 - val_loss: 6.1234e-04\n",
      "Epoch 3871/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.0500e-04 - val_loss: 7.4575e-04\n",
      "Epoch 3872/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.2145e-04 - val_loss: 6.6738e-04\n",
      "Epoch 3873/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.3843e-04 - val_loss: 7.3699e-04\n",
      "Epoch 3874/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.5433e-04 - val_loss: 7.8537e-04\n",
      "Epoch 3875/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.3103e-04 - val_loss: 6.3486e-04\n",
      "Epoch 3876/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.9020e-04 - val_loss: 6.3376e-04\n",
      "Epoch 3877/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.1919e-04 - val_loss: 8.7659e-04\n",
      "Epoch 3878/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.2422e-04 - val_loss: 6.7611e-04\n",
      "Epoch 3879/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.2318e-04 - val_loss: 8.1032e-04\n",
      "Epoch 3880/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.3725e-04 - val_loss: 7.7750e-04\n",
      "Epoch 3881/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.4128e-04 - val_loss: 7.8201e-04\n",
      "Epoch 3882/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.9890e-04 - val_loss: 9.8208e-04\n",
      "Epoch 3883/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 3884/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9.6324e-04 - val_loss: 0.0011\n",
      "Epoch 3885/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.1888e-04 - val_loss: 6.3198e-04\n",
      "Epoch 3886/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.3863e-04 - val_loss: 7.1377e-04\n",
      "Epoch 3887/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.5981e-04 - val_loss: 6.9385e-04\n",
      "Epoch 3888/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.3109e-04 - val_loss: 6.5541e-04\n",
      "Epoch 3889/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.0882e-04 - val_loss: 0.0012\n",
      "Epoch 3890/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.0065e-04 - val_loss: 7.2918e-04\n",
      "Epoch 3891/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.5651e-04 - val_loss: 8.9573e-04\n",
      "Epoch 3892/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 3893/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 9.0495e-04\n",
      "Epoch 3894/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.2225e-04 - val_loss: 7.7936e-04\n",
      "Epoch 3895/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.8364e-04 - val_loss: 8.2637e-04\n",
      "Epoch 3896/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.2874e-04 - val_loss: 7.2577e-04\n",
      "Epoch 3897/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.5161e-04 - val_loss: 8.4476e-04\n",
      "Epoch 3898/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.3787e-04 - val_loss: 7.5149e-04\n",
      "Epoch 3899/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.0810e-04 - val_loss: 7.3550e-04\n",
      "Epoch 3900/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.6635e-04 - val_loss: 7.5586e-04\n",
      "Epoch 3901/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.2937e-04 - val_loss: 7.2386e-04\n",
      "Epoch 3902/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 5ms/step - loss: 6.7037e-04 - val_loss: 6.5537e-04\n",
      "Epoch 3903/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.5070e-04 - val_loss: 6.1640e-04\n",
      "Epoch 3904/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.0286e-04 - val_loss: 6.5531e-04\n",
      "Epoch 3905/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.5395e-04 - val_loss: 7.4543e-04\n",
      "Epoch 3906/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.1046e-04 - val_loss: 7.0455e-04\n",
      "Epoch 3907/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.6680e-04 - val_loss: 6.7036e-04\n",
      "Epoch 3908/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.8951e-04 - val_loss: 8.0968e-04\n",
      "Epoch 3909/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.1928e-04 - val_loss: 7.5690e-04\n",
      "Epoch 3910/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.0028e-04 - val_loss: 6.6628e-04\n",
      "Epoch 3911/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.6658e-04 - val_loss: 9.6512e-04\n",
      "Epoch 3912/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.8650e-04 - val_loss: 7.4042e-04\n",
      "Epoch 3913/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.7723e-04 - val_loss: 0.0011\n",
      "Epoch 3914/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.5995e-04 - val_loss: 7.8924e-04\n",
      "Epoch 3915/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.0819e-04 - val_loss: 7.0827e-04\n",
      "Epoch 3916/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 8.6450e-04 - val_loss: 6.3062e-04\n",
      "Epoch 3917/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.0692e-04 - val_loss: 6.5737e-04\n",
      "Epoch 3918/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.6192e-04 - val_loss: 6.7917e-04\n",
      "Epoch 3919/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.9981e-04 - val_loss: 0.0010\n",
      "Epoch 3920/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 7.4733e-04\n",
      "Epoch 3921/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.1312e-04 - val_loss: 8.8838e-04\n",
      "Epoch 3922/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.9449e-04 - val_loss: 6.2575e-04\n",
      "Epoch 3923/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.0398e-04 - val_loss: 6.1657e-04\n",
      "Epoch 3924/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.2163e-04 - val_loss: 7.1386e-04\n",
      "Epoch 3925/4000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.8671e-04 - val_loss: 6.3033e-04\n",
      "Epoch 3926/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.8049e-04 - val_loss: 7.6059e-04\n",
      "Epoch 3927/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.9760e-04 - val_loss: 7.0113e-04\n",
      "Epoch 3928/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.5363e-04 - val_loss: 5.7763e-04\n",
      "Epoch 3929/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.0662e-04 - val_loss: 5.9678e-04\n",
      "Epoch 3930/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.9466e-04 - val_loss: 8.5375e-04\n",
      "Epoch 3931/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.9669e-04 - val_loss: 7.0962e-04\n",
      "Epoch 3932/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.3380e-04 - val_loss: 5.8615e-04\n",
      "Epoch 3933/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.7132e-04 - val_loss: 7.7384e-04\n",
      "Epoch 3934/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.1718e-04 - val_loss: 6.8570e-04\n",
      "Epoch 3935/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.0001e-04 - val_loss: 6.5466e-04\n",
      "Epoch 3936/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.2865e-04 - val_loss: 6.3160e-04\n",
      "Epoch 3937/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.8280e-04 - val_loss: 7.8263e-04\n",
      "Epoch 3938/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.1122e-04 - val_loss: 5.8465e-04\n",
      "Epoch 3939/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 6.2512e-04 - val_loss: 6.4388e-04\n",
      "Epoch 3940/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 6.7393e-04 - val_loss: 6.1507e-04\n",
      "Epoch 3941/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 6.5139e-04 - val_loss: 6.3268e-04\n",
      "Epoch 3942/4000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 6.6285e-04 - val_loss: 5.9812e-04\n",
      "Epoch 3943/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 6.7703e-04 - val_loss: 6.0407e-04\n",
      "Epoch 3944/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.1892e-04 - val_loss: 6.7217e-04\n",
      "Epoch 3945/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.9744e-04 - val_loss: 8.0808e-04\n",
      "Epoch 3946/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.4159e-04 - val_loss: 6.2971e-04\n",
      "Epoch 3947/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.5785e-04 - val_loss: 6.9843e-04\n",
      "Epoch 3948/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.8506e-04 - val_loss: 6.5226e-04\n",
      "Epoch 3949/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.4385e-04 - val_loss: 8.6087e-04\n",
      "Epoch 3950/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.3995e-04 - val_loss: 7.6035e-04\n",
      "Epoch 3951/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.4423e-04 - val_loss: 7.7141e-04\n",
      "Epoch 3952/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.3925e-04 - val_loss: 7.5754e-04\n",
      "Epoch 3953/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.7029e-04 - val_loss: 5.4903e-04\n",
      "Epoch 3954/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.2858e-04 - val_loss: 7.6480e-04\n",
      "Epoch 3955/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.6662e-04 - val_loss: 5.8795e-04\n",
      "Epoch 3956/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.9691e-04 - val_loss: 7.6757e-04\n",
      "Epoch 3957/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.0564e-04 - val_loss: 8.2776e-04\n",
      "Epoch 3958/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.9678e-04 - val_loss: 7.7901e-04\n",
      "Epoch 3959/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.7997e-04 - val_loss: 7.8225e-04\n",
      "Epoch 3960/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.9855e-04 - val_loss: 7.9969e-04\n",
      "Epoch 3961/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.5566e-04 - val_loss: 6.3560e-04\n",
      "Epoch 3962/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.8791e-04 - val_loss: 6.6507e-04\n",
      "Epoch 3963/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.1681e-04 - val_loss: 7.5581e-04\n",
      "Epoch 3964/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.9022e-04 - val_loss: 6.2047e-04\n",
      "Epoch 3965/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.9577e-04 - val_loss: 6.9710e-04\n",
      "Epoch 3966/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.3584e-04 - val_loss: 8.3756e-04\n",
      "Epoch 3967/4000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.0827e-04 - val_loss: 7.2991e-04\n",
      "Epoch 3968/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.3410e-04 - val_loss: 6.4295e-04\n",
      "Epoch 3969/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.1462e-04 - val_loss: 6.1727e-04\n",
      "Epoch 3970/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.4097e-04 - val_loss: 8.2849e-04\n",
      "Epoch 3971/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.7386e-04 - val_loss: 7.9125e-04\n",
      "Epoch 3972/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.0912e-04 - val_loss: 0.0010\n",
      "Epoch 3973/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.0113e-04 - val_loss: 7.3469e-04\n",
      "Epoch 3974/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.3912e-04 - val_loss: 7.1653e-04\n",
      "Epoch 3975/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.4943e-04 - val_loss: 7.7774e-04\n",
      "Epoch 3976/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 5ms/step - loss: 9.6940e-04 - val_loss: 8.5450e-04\n",
      "Epoch 3977/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.1136e-04 - val_loss: 6.6440e-04\n",
      "Epoch 3978/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.5644e-04 - val_loss: 5.8980e-04\n",
      "Epoch 3979/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.6814e-04 - val_loss: 9.7164e-04\n",
      "Epoch 3980/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.4745e-04 - val_loss: 6.7555e-04\n",
      "Epoch 3981/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.5877e-04 - val_loss: 0.0010\n",
      "Epoch 3982/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.2986e-04 - val_loss: 9.0320e-04\n",
      "Epoch 3983/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.5220e-04 - val_loss: 7.0923e-04\n",
      "Epoch 3984/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.1242e-04 - val_loss: 6.3326e-04\n",
      "Epoch 3985/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.6720e-04 - val_loss: 9.7616e-04\n",
      "Epoch 3986/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.3960e-04 - val_loss: 7.5833e-04\n",
      "Epoch 3987/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.2419e-04 - val_loss: 6.1645e-04\n",
      "Epoch 3988/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.4275e-04 - val_loss: 7.6715e-04\n",
      "Epoch 3989/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.1495e-04 - val_loss: 9.1010e-04\n",
      "Epoch 3990/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.3006e-04 - val_loss: 7.8547e-04\n",
      "Epoch 3991/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.3326e-04 - val_loss: 7.1035e-04\n",
      "Epoch 3992/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.1938e-04 - val_loss: 9.0143e-04\n",
      "Epoch 3993/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.0515e-04 - val_loss: 8.0342e-04\n",
      "Epoch 3994/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.3462e-04 - val_loss: 7.9074e-04\n",
      "Epoch 3995/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.8613e-04 - val_loss: 7.4563e-04\n",
      "Epoch 3996/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.6985e-04 - val_loss: 7.4748e-04\n",
      "Epoch 3997/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.2791e-04 - val_loss: 9.0878e-04\n",
      "Epoch 3998/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.6747e-04 - val_loss: 0.0010\n",
      "Epoch 3999/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.9612e-04 - val_loss: 6.9565e-04\n",
      "Epoch 4000/4000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.0630e-04 - val_loss: 6.7846e-04\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(420, activation=\"relu\",input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.Dense(150, activation=\"relu\"),\n",
    "    keras.layers.Dense(60, activation=\"relu\"),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss=\"mean_absolute_error\", optimizer=keras.optimizers.Adam(lr=3e-4))\n",
    "history = model.fit(X_train, y_train_norm, epochs=4000, validation_data=(X_valid, y_valid_norm),batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f013e9cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202789.428981238"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_adam=model.predict(X_valid)\n",
    "\n",
    "mean_squared_error(y_valid,normalizer.inverse_transform(predict_adam))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c136572f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72530d5",
   "metadata": {},
   "source": [
    "## Notes:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796d4e2f",
   "metadata": {},
   "source": [
    "Actually there is function called `KerasRegressor()` which I didn't use here but it can be used for implementing neural networks for regression problem. You can find very good examples about that function by clicking the [link](https://machinelearningmastery.com/regression-tutorial-keras-deep-learning-library-python/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3adfbaf2",
   "metadata": {},
   "source": [
    "I found a discussion about setting `clipnorm=00.1` while using Adam optimization and tried it. This didn't yield a much better performance but actually improved the covid model a bit. I also add the link about this discussion here [link](https://github.com/fizyr/keras-retinanet/issues/942)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
